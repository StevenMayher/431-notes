[{"path":"index.html","id":"working-with-these-notes","chapter":"Working with These Notes","heading":"Working with These Notes","text":"document broken multiple chapters. Use table contents left side screen navigate chapters, use right side navigate within current chapter.can also search document, using automated index.code provided document can copied clipboard using Copy icon top right code block.document updated (unpredictably) throughout semester.","code":""},{"path":"index.html","id":"the-431-course-online","chapter":"Working with These Notes","heading":"The 431 Course online","text":"main web page 431 course Fall 2021 https://thomaselove.github.io/431/. Go information related course.","code":""},{"path":"index.html","id":"what-youll-find-here","chapter":"Working with These Notes","heading":"What You’ll Find Here","text":"Notes provide series examples using R work issues likely come PQHS/CRSP/MPHP 431. mostly find brief explanations key idea summary, accompanied (time) R code demonstration results applying code.Notes share features textbook, neither comprehensive completely original. main purpose give 431 students set common materials draw course. class, sometimes:reiterate points made document,amplify ,simplify presentation things done ,use new examples show techniques,refer issues mentioned document,don’t follow notes precisely. assume instead read materials try learn , just attend classes try learn . welcome feedback kinds document anything else.Everything see available HTML. also access R Markdown files, contain code generates everything document, including R results. demonstrate use R Markdown (document generated additional help R package called bookdown) RStudio (“program” use interface R language) class.data R code related notes also available .","code":""},{"path":"index.html","id":"setting-up-r","chapter":"Working with These Notes","heading":"Setting Up R","text":"Notes make extensive use ofthe statistical software language R, andthe development environment R Studio,free, ’ll need install machine. Instructions found course syllabus.need even gentler introduction, ’re just new R RStudio need learn , encourage take look http://moderndive.com/, provides introduction statistical data sciences via R Chester Ismay Albert Y. Kim.1These notes written using R Markdown. R Markdown, like R R Studio, free open source.R Markdown described authoring framework data science, lets yousave execute R codegenerate high-quality reports can shared audienceThis description comes http://rmarkdown.rstudio.com/lesson-1.html can visit get overview quick tour ’s possible R Markdown.Another excellent resource learn R Markdown tools Communicate section (especially R Markdown chapter) Garrett Grolemund Hadley Wickham.2","code":""},{"path":"index.html","id":"initial-setup-of-r-packages","chapter":"Working with These Notes","heading":"Initial Setup of R Packages","text":"start, ’ll present series commands run (silently) beginning chapter Notes. particular commands set R use several packages (libraries) functions expand capabilities, make specific change want R output displayed (’s comment = NA piece) sets theme graphs build one called theme_bw(). chunk code like occur near top R Markdown work.deliberately set list loaded packages relatively small. need install package , need reload every time start new session.","code":"\nknitr::opts_chunk$set(comment = NA)\n\nlibrary(knitr)\nlibrary(magrittr)\nlibrary(janitor)\nlibrary(NHANES)\nlibrary(palmerpenguins)\nlibrary(patchwork)\nlibrary(rms)\nlibrary(mosaic)\nlibrary(Epi)\nlibrary(naniar)\nlibrary(simputation)\nlibrary(broom) # note: tidymodels includes the broom package\nlibrary(tidyverse) # note: tidyverse includes the dplyr and ggplot2 packages\n\ntheme_set(theme_bw())"},{"path":"index.html","id":"the-love-boost.r-script","chapter":"Working with These Notes","heading":"The Love-boost.R script","text":"Starting October, ’ll make use scripts ’ve gathered . necessary, ’ll source code using following command…","code":"\nsource(\"data/Love-boost.R\")"},{"path":"index.html","id":"additional-r-packages-installed-for-this-book","chapter":"Working with These Notes","heading":"Additional R Packages installed for this book","text":"packages need installed user’s system, need loaded R order run code presented notes except specific settings. additional packages include following.","code":"boot\ncar\nequatiomatic\nGGally\nggridges\ngt\npsych\nmodelsummary\nvisdat"},{"path":"data-science.html","id":"data-science","chapter":"1 Data Science","heading":"1 Data Science","text":"definition data science can little slippery. One current view data science, exemplified Steven Geringer’s 2014 Venn diagram.\nFigure 1.1: Data Science Venn Diagram Steven Geringer\nfield encompasses ideas mathematics statistics computer science, heavy reliance subject-matter knowledge. case, includes clinical, health-related, medical biological knowledge.Andrew Gelman Deborah Nolan3 suggest, experience intuition necessary good statistical practice hard obtain, teaching data science provides excellent opportunity reinforce statistical thinking skills across full cycle data analysis project.principal form computer science (coding/programming) play role course provide form communication. ’ll need learn express ideas just orally writing, also code.Data Science team activity. Everyone working data science brings part necessary skill set, one person can cover three areas alone excellent projects.[individual truly expert three key areas (mathematics/statistics, computer science subject-matter knowledge) ] mythical beast magical powers ’s rumored exist never actually seen wild.http://www.kdnuggets.com/2016/10/battle-data-science-venn-diagrams.html","code":""},{"path":"data-science.html","id":"data-science-project-cycle","chapter":"1 Data Science","heading":"1.1 Data Science Project Cycle","text":"typical data science project can modeled follows, comes introduction amazing book R Data Science, Garrett Grolemund Hadley Wickham, key text course.4\nFigure 1.2: Source: R Data Science: Introduction\ndiagram sometimes referred Krebs Cycle Data Science. steps data science project, encourage read Introduction Grolemund Wickham.5","code":""},{"path":"data-science.html","id":"data-science-and-the-431-course","chapter":"1 Data Science","heading":"1.2 Data Science and the 431 Course","text":"’ll discuss elements 431 course, focusing start understanding data transformation, modeling (especially early stages) visualization. 431, learn get things done.get people working R R Studio R Markdown, even completely new coding. gentle introduction provided Ismay Kim6We learn use tidyverse (http://www.tidyverse.org/), array tools R (mostly developed Hadley Wickham colleagues R Studio) share underlying philosophy make data science faster, easier, reproducible fun. critical text understanding tidyverse Grolemund Wickham.7 Tidyverse tools facilitate:\nimporting data R, can source intense pain things, really quite easy 95% time right tool.\ntidying data, , storing format includes one row per observation one column per variable. harder, important, might think.\ntransforming data, perhaps identifying specific subgroups interest, creating new variables based existing ones, calculating summaries.\nvisualizing data generate actual knowledge identify questions data - area R really shines, ’ll start class.\nmodeling data, taking approach modeling complementary visualization, allows us answer questions visualization helps us identify.\nlast, definitely least, communicating results, models visualizations others, way reproducible effective.\nimporting data R, can source intense pain things, really quite easy 95% time right tool.tidying data, , storing format includes one row per observation one column per variable. harder, important, might think.transforming data, perhaps identifying specific subgroups interest, creating new variables based existing ones, calculating summaries.visualizing data generate actual knowledge identify questions data - area R really shines, ’ll start class.modeling data, taking approach modeling complementary visualization, allows us answer questions visualization helps us identify.last, definitely least, communicating results, models visualizations others, way reproducible effective.programming/coding inevitable requirement accomplish aims. leery coding, ’ll need get past , help course stellar teaching assistants. Getting started always challenging part, experience pain developing new skills evaporates early October.","code":""},{"path":"data-science.html","id":"what-the-course-is-and-isnt","chapter":"1 Data Science","heading":"1.3 What The Course Is and Isn’t","text":"431 course getting things done. developing course, adopt modern approach places data center work. goal teach truly reproducible research modern tools. want able collect use data effectively address questions interest.curriculum includes several topics might expect standard graduate introduction biostatistics.data gatheringdata wranglingexploratory data analysis visualizationmultivariate modelingcommunicationIt also nearly completely avoids formalism extremely applied - absolutely course theoretical mathematical statistics, Notes reflect approach.’s little mathematical underpinnings :\\[\nf(x) = \\frac{e^{-(x - \\mu)^{2}/(2\\sigma^{2})}}{\\sigma{\\sqrt{2 \\pi }}} \n\\]Instead, notes (course) focus get R things want , interpret results work. next Chapter provides first example.","code":""},{"path":"the-palmer-penguins.html","id":"the-palmer-penguins","chapter":"2 The Palmer Penguins","heading":"2 The Palmer Penguins","text":"data palmerpenguins package R include size measurements, clutch observations, blood isotope ratios adult foraging Adelie, Chinstrap, Gentoo penguins observed islands Palmer Archipelago near Palmer Station, Antarctica8. data collected made available Dr. Kristen Gorman Palmer Station Long Term Ecological Research (LTER) Program.palmerpenguins package, visit https://allisonhorst.github.io/palmerpenguins/.","code":""},{"path":"the-palmer-penguins.html","id":"package-loading-then-dealing-with-missing-data","chapter":"2 The Palmer Penguins","heading":"2.1 Package Loading, then Dealing with Missing Data","text":"start, let’s load necessary R packages manage data summarize small table, plot. ’ve actually done previously, ’ll repeat steps , ’s worth seeing R .case, ’ll load five packages.’s worth remembering everything # line just comment reader, ignored R. ’ll see later loading single package (called tidyverse) gives us dplyr ggplot2 packages, well several useful things.Next, let’s take penguins data palmerpenguins package, identify observations complete data (, missing values) four variables interest. ’ll store result new data frame (think data set) called new_penguins take look result using following code.","code":"\nlibrary(palmerpenguins)  # source for the data set\nlibrary(janitor)         # some utilities for cleanup and simple tables\nlibrary(magrittr)        # provides us with the pipe %>% for code management\nlibrary(dplyr)           # part of the tidyverse: data management tools\nlibrary(ggplot2)         # part of the tidyverse: tools for plotting data\nnew_penguins <- penguins %>%\n    filter(complete.cases(flipper_length_mm, body_mass_g, species, sex))\n\nnew_penguins# A tibble: 333 x 8\n   species island    bill_length_mm bill_depth_mm\n   <fct>   <fct>              <dbl>         <dbl>\n 1 Adelie  Torgersen           39.1          18.7\n 2 Adelie  Torgersen           39.5          17.4\n 3 Adelie  Torgersen           40.3          18  \n 4 Adelie  Torgersen           36.7          19.3\n 5 Adelie  Torgersen           39.3          20.6\n 6 Adelie  Torgersen           38.9          17.8\n 7 Adelie  Torgersen           39.2          19.6\n 8 Adelie  Torgersen           41.1          17.6\n 9 Adelie  Torgersen           38.6          21.2\n10 Adelie  Torgersen           34.6          21.1\n# ... with 323 more rows, and 4 more variables:\n#   flipper_length_mm <int>, body_mass_g <int>, sex <fct>,\n#   year <int>"},{"path":"the-palmer-penguins.html","id":"counting-things-and-making-tables","chapter":"2 The Palmer Penguins","heading":"2.2 Counting Things and Making Tables","text":", many penguins new_penguins data? printed result, got answer, (many things R) many ways get result.new_penguins data break sex species?Note strange spelling tabyl . output reasonably clear, make table little prettier, ’re , can add row column totals ?","code":"\nnrow(new_penguins)[1] 333\nnew_penguins %>% \n    tabyl(sex, species) # tabyl comes from the janitor package    sex Adelie Chinstrap Gentoo\n female     73        34     58\n   male     73        34     61\nnew_penguins %>% \n    tabyl(sex, species) %>%\n    adorn_totals(where = c(\"row\", \"col\")) %>% # add row, column totals\n    kable  # one convenient way to make the table prettier"},{"path":"the-palmer-penguins.html","id":"visualizing-the-data-in-a-graph-or-a-few","chapter":"2 The Palmer Penguins","heading":"2.3 Visualizing the Data in a Graph (or a few…)","text":"Now, let’s look two variables interest. Let’s create graph showing association body mass flipper length across complete set 333 penguins.may want include straight-line model (fit classical linear regression) plot. One way R involves addition single line code, like :Whenever build graph , default choices may sufficient. ’d like see prettier version going show someone else. , might use different color species, might neaten theme (get rid default grey background) add title, like .","code":"\nggplot(new_penguins, aes(x = body_mass_g, y = flipper_length_mm)) +\n    geom_point() \nggplot(new_penguins, aes(x = body_mass_g, y = flipper_length_mm)) +\n    geom_point() +\n    geom_smooth(method = \"lm\", formula = y ~ x,\n                col = \"red\", se = FALSE)\nggplot(new_penguins, aes(x = body_mass_g, y = flipper_length_mm, col = species)) +\n    geom_point() + \n    theme_bw() + \n    labs(title = \"Flipper Length and Body Mass for 333 of the Palmer Penguins\")"},{"path":"the-palmer-penguins.html","id":"six-ways-to-improve-this-graph","chapter":"2 The Palmer Penguins","heading":"2.4 Six Ways To “Improve” This Graph","text":"Now, let’s build new graph. , want :plot relationship body mass flipper length light Sex Speciesincrease size points add little transparency can see points overlap,add smooth curves summarize relationships two quantities (body mass flipper length) within combination species sex,split graph two “facets” (one sex),improve axis labels,improve titles adding subtitle, also adding code count penguins (rather hard-coding total number.)","code":"\nggplot(new_penguins, aes(x = body_mass_g, y = flipper_length_mm, \n                         col = species)) +\n    geom_point(size = 2, alpha = 0.5) + \n    geom_smooth(method = \"loess\", formula = y ~ x, \n                se = FALSE, size = 1.5) +\n    facet_grid(~ sex) +\n    theme_bw() + \n    labs(title = \"Flipper Length and Body Mass, by Sex & Species\",\n         subtitle = paste0(nrow(new_penguins), \" of the Palmer Penguins\"),\n         x = \"Body Mass (g)\", \n         y = \"Flipper Length (mm)\")"},{"path":"the-palmer-penguins.html","id":"a-little-reflection","chapter":"2 The Palmer Penguins","heading":"2.5 A Little Reflection","text":"can learn plots construction? particular,plots suggest center distribution quantity (body mass flipper length) overall, within combination Sex Species?final plot suggest spread distribution quantities combination Sex Species?plots suggest association body mass flipper length across complete set penguins?shape nature body mass - flipper length relationship change based Sex Species?think helpful plot straight-line relationship (rather smooth curve) within combination Sex Species final plot? ? (Also, code accomplish ?)R code plot revised accomplish six “wants” specified ?","code":""},{"path":"nhanes1.html","id":"nhanes1","chapter":"3 NHANES: A First Look","heading":"3 NHANES: A First Look","text":"Next, ’ll explore data US National Health Nutrition Examination Survey, NHANES.’ll display R code go, ’ll return key coding ideas involved later Notes.","code":""},{"path":"nhanes1.html","id":"the-nhanes-data-a-first-sample","chapter":"3 NHANES: A First Look","heading":"3.1 The NHANES data: A First Sample","text":"NHANES package provides sample 10,000 NHANES responses 2009-10 2011-12 administrations, data frame also called NHANES. can obtain dimensions data frame (think rectangle data) dim() function.see 10000 rows 76 columns NHANES data frame.moment, let’s gather random sample 1,000 responses 10000 rows listed NHANES data frame, look three variables (labeled Gender, Age Height) describe subjects9. motivation example came Figure Benjamin S. Baumer, Daniel T. Kaplan, Nicholas J. Horton.10We 1000 rows (observations) 5 columns (variables) describe responses listed rows.","code":"\ndim(NHANES)[1] 10000    76\n# library(NHANES) # already loaded NHANES package/library of functions, data\n\nset.seed(431001) \n# use set.seed to ensure that we all get the same random sample \n# of 1,000 NHANES subjects in our nh_1 collection\n\nnh_1 <- \n    slice_sample(NHANES, n = 1000, replace = FALSE) %>%\n    select(ID, SurveyYr, Gender, Age, Height)\n\nnh_1# A tibble: 1,000 x 5\n      ID SurveyYr Gender   Age Height\n   <int> <fct>    <fct>  <int>  <dbl>\n 1 69638 2011_12  female     5   106.\n 2 70782 2011_12  male      64   176.\n 3 52408 2009_10  female    54   162.\n 4 59031 2009_10  female    15   155.\n 5 64530 2011_12  male      53   185.\n 6 71040 2011_12  male      63   169.\n 7 55186 2009_10  female    30   168.\n 8 60211 2009_10  male       5   103.\n 9 55730 2009_10  male      66   161.\n10 68229 2011_12  female    36   170.\n# ... with 990 more rows"},{"path":"nhanes1.html","id":"a-quick-numerical-summary","chapter":"3 NHANES: A First Look","heading":"3.2 A Quick Numerical Summary","text":"two variables R recognizes describing categories, SurveyYr Gender, numeric summary provides small table counts. Age Height variables, see minimum, mean, maximum summary statistics.","code":"\nsummary(nh_1)       ID           SurveyYr      Gender         Age       \n Min.   :51624   2009_10:512   female:504   Min.   : 0.00  \n 1st Qu.:57011   2011_12:488   male  :496   1st Qu.:18.00  \n Median :61979                              Median :36.00  \n Mean   :61903                              Mean   :37.42  \n 3rd Qu.:67178                              3rd Qu.:56.00  \n Max.   :71875                              Max.   :80.00  \n                                                           \n     Height     \n Min.   : 85.0  \n 1st Qu.:156.2  \n Median :165.0  \n Mean   :162.3  \n 3rd Qu.:174.5  \n Max.   :195.9  \n NA's   :37     "},{"path":"nhanes1.html","id":"plotting-age-vs.-height","chapter":"3 NHANES: A First Look","heading":"3.3 Plotting Age vs. Height","text":"Suppose want visualize relationship Height Age 1,000 NHANES observations. best choice likely scatterplot.note several interesting results .warning, R tells us “Removed 37 rows containing missing values (geom_point).” 963 subjects plotted , remaining 37 people missing (NA) values either Height, Age .Unsurprisingly, measured Heights subjects grow Age 0 Age 20 , see typical Height increases rapidly across Ages. middle distribution later Ages pretty consistent Height somewhere 150 175. units aren’t specified, expect must centimeters. Ages clearly reported Years.Age reported 80, appears large cluster Ages 80. may due requirement Ages 80 reported 80 help mask identity individuals.11As case, ’re going build visualizations using tools ggplot2 package, part tidyverse series packages. ’ll see similar coding structures throughout Chapter, covered well Chapter 3 Grolemund Wickham.12","code":"\nggplot(data = nh_1, aes(x = Age, y = Height)) +\n    geom_point()Warning: Removed 37 rows containing missing values\n(geom_point)."},{"path":"nhanes1.html","id":"restriction-to-complete-cases","chapter":"3 NHANES: A First Look","heading":"3.4 Restriction to Complete Cases","text":"move , let’s manipulate data frame bit, focus subjects complete data Age Height. help us avoid warning message.Note units explanations variables contained NHANES help file, available via typing ?NHANES Console R Studio, typing NHANES Search bar R Studio’s Help window.","code":"\nnh_1cc <- nh_1 %>%\n    filter(complete.cases(Age, Height)) \n\nsummary(nh_1cc)       ID           SurveyYr      Gender         Age       \n Min.   :51624   2009_10:487   female:484   Min.   : 2.00  \n 1st Qu.:57034   2011_12:476   male  :479   1st Qu.:19.00  \n Median :62056                              Median :37.00  \n Mean   :61967                              Mean   :38.29  \n 3rd Qu.:67269                              3rd Qu.:56.00  \n Max.   :71875                              Max.   :80.00  \n     Height     \n Min.   : 85.0  \n 1st Qu.:156.2  \n Median :165.0  \n Mean   :162.3  \n 3rd Qu.:174.5  \n Max.   :195.9  "},{"path":"nhanes1.html","id":"the-distinction-between-gender-and-sex","chapter":"3 NHANES: A First Look","heading":"3.5 The Distinction between Gender and Sex","text":"Gender variable mis-named. data refer biological status subjects, Sex, social construct Gender can quite different. effort avoid confusion, ’ll rename variable Gender Sex accurately describe actually measured ., can use approach…’s better. many observations now? use dim find number rows columns new data frame., simply list data frame read result.","code":"\nnh_1cc <- nh_1 %>%\n    rename(Sex = Gender) %>%\n    filter(complete.cases(Age, Height)) \n\nsummary(nh_1cc)       ID           SurveyYr       Sex           Age       \n Min.   :51624   2009_10:487   female:484   Min.   : 2.00  \n 1st Qu.:57034   2011_12:476   male  :479   1st Qu.:19.00  \n Median :62056                              Median :37.00  \n Mean   :61967                              Mean   :38.29  \n 3rd Qu.:67269                              3rd Qu.:56.00  \n Max.   :71875                              Max.   :80.00  \n     Height     \n Min.   : 85.0  \n 1st Qu.:156.2  \n Median :165.0  \n Mean   :162.3  \n 3rd Qu.:174.5  \n Max.   :195.9  \ndim(nh_1cc)[1] 963   5\nnh_1cc# A tibble: 963 x 5\n      ID SurveyYr Sex      Age Height\n   <int> <fct>    <fct>  <int>  <dbl>\n 1 69638 2011_12  female     5   106.\n 2 70782 2011_12  male      64   176.\n 3 52408 2009_10  female    54   162.\n 4 59031 2009_10  female    15   155.\n 5 64530 2011_12  male      53   185.\n 6 71040 2011_12  male      63   169.\n 7 55186 2009_10  female    30   168.\n 8 60211 2009_10  male       5   103.\n 9 55730 2009_10  male      66   161.\n10 68229 2011_12  female    36   170.\n# ... with 953 more rows"},{"path":"nhanes1.html","id":"age-height-by-sex","chapter":"3 NHANES: A First Look","heading":"3.6 Age-Height by Sex?","text":"Let’s add Sex plot using color, also adjust y axis label incorporate units measurement.","code":"\nggplot(data = nh_1cc, aes(x = Age, y = Height, color = Sex)) +\n    geom_point() +\n    labs(title = \"Height-Age Relationship in NHANES sample\", \n         y = \"Height in cm.\")"},{"path":"nhanes1.html","id":"can-we-show-the-female-and-male-relationships-in-separate-panels","chapter":"3 NHANES: A First Look","heading":"3.6.1 Can we show the Female and Male relationships in separate panels?","text":"Sure.","code":"\nggplot(data = nh_1cc, aes(x = Age, y = Height, color = Sex)) +\n    geom_point() + \n    labs(title = \"Height-Age Relationship in NHANES sample\", \n         y = \"Height in cm.\") +\n    facet_wrap(~ Sex)"},{"path":"nhanes1.html","id":"can-we-add-a-smooth-curve-to-show-the-relationship-in-each-plot","chapter":"3 NHANES: A First Look","heading":"3.6.2 Can we add a smooth curve to show the relationship in each plot?","text":"Yes, adding call geom_smooth() function.","code":"\nggplot(data = nh_1cc, aes(x = Age, y = Height, color = Sex)) +\n    geom_point() + \n    geom_smooth(method = \"loess\", formula = y ~ x) +\n    labs(title = \"Height-Age Relationship in NHANES sample\", \n         y = \"Height in cm.\") +\n    facet_wrap(~ Sex)"},{"path":"nhanes1.html","id":"what-if-we-want-to-assume-straight-line-relationships","chapter":"3 NHANES: A First Look","heading":"3.6.3 What if we want to assume straight line relationships?","text":"look linear model part plot instead. make sense ?seems like complex relationship Height Age isn’t well described straight line model.","code":"\nggplot(data = nh_1cc, aes(x = Age, y = Height, color = Sex)) +\n    geom_point() + \n    geom_smooth(method = \"lm\", formula = y ~ x) +\n    labs(title = \"Height-Age Relationship in NHANES sample\", \n         y = \"Height in cm.\") +\n    facet_wrap(~ Sex)"},{"path":"nhanes1.html","id":"combining-plots-with-patchwork","chapter":"3 NHANES: A First Look","heading":"3.7 Combining Plots with patchwork","text":"patchwork package R allows us use simple commands put two plots together.Suppose create plots called p1 p2, follows.Now, suppose want put together single figure. Thanks patchwork, can simply type following.can place images next , add annotation, like :patchwork package website provides lots great examples guides make easy combine separate ggplots graphic. packages (gridExtra cowplot nice, instance) task, think patchwork user-friendly, ’s focus notes.","code":"\np1 <- ggplot(data = nh_1cc, aes(x = Age, y = Height)) +\n    geom_point() + \n    labs(title = \"Height and Age\")\n\np2 <- ggplot(data = nh_1cc, aes(x = Sex, y = Height)) +\n    geom_point() +\n    labs(title = \"Height, by Sex\")\np1 / p2\np1 + p2 +\n    plot_annotation(title = \"Our Combined Plots\")"},{"path":"nhanes1.html","id":"coming-up","chapter":"3 NHANES: A First Look","heading":"3.8 Coming Up","text":"Next, ’ll select new sample NHANES respondents bit carefully, introduce new ways thinking data variables, ’ll study subjects greater detail.","code":""},{"path":"data-structures-variable-types-sampling-nhanes.html","id":"data-structures-variable-types-sampling-nhanes","chapter":"4 Data Structures, Variable Types & Sampling NHANES","heading":"4 Data Structures, Variable Types & Sampling NHANES","text":"","code":""},{"path":"data-structures-variable-types-sampling-nhanes.html","id":"data-require-structure-and-context","chapter":"4 Data Structures, Variable Types & Sampling NHANES","heading":"4.1 Data require structure and context","text":"Descriptive statistics concerned presentation, organization summary data, suggested Geoffrey R. Norman David L. Streiner.13 includes various methods organizing graphing data get idea data can tell us.Eric Vittinghoff et al.14 suggest, nature measurement determines best describe statistically, main distinction numerical categorical variables. Even little tricky - plenty data can values look like numerical values, just numerals serving labels.David E. Bock, Paul F. Velleman, Richard D. De Veaux15 point , truly critical notion, course, data values, matter kind, useless without contexts. Five W’s (, [units], , , , often ) just useful establishing context data journalism. can’t answer , particular, don’t useful information.general, row data frame corresponds individual (respondent, experimental unit, record, observation) characteristics gathered columns (characteristics may called variables, factors data elements.) Every column / variable name indicates measuring, every row / observation name indicates measured.","code":""},{"path":"data-structures-variable-types-sampling-nhanes.html","id":"newNHANES","chapter":"4 Data Structures, Variable Types & Sampling NHANES","heading":"4.2 Sampling Adults in NHANES","text":"Chapter 3, spent time sample National Health Nutrition Examination. Now, changing value set.seed function determines starting place random sampling, changing specifications, ’ll generate new sample describing 750 unique (distinct) adult subjects completed 2011-12 version survey ages 21 64.","code":""},{"path":"data-structures-variable-types-sampling-nhanes.html","id":"creating-a-temporary-cleaner-data-frame","chapter":"4 Data Structures, Variable Types & Sampling NHANES","heading":"4.2.1 Creating a Temporary, Cleaner Data Frame","text":"’ll start describing plan use create new data frame called nh_temp eventually build final sample. particular, let lay steps use create nh_temp frame original NHANES data frame available R package called NHANES.’ll filter original NHANES data frame include responses 2011-12 administration survey. cut sample half, 10,000 rows 5,000.’ll filter original NHANES data frame include responses 2011-12 administration survey. cut sample half, 10,000 rows 5,000.’ll filter restrict sample adults whose age least 21 also less 65. ’ll want avoid problems including children adults sample, also want focus population people US usually covered private insurance job, Medicaid insurance government, rather covered Medicare.’ll filter restrict sample adults whose age least 21 also less 65. ’ll want avoid problems including children adults sample, also want focus population people US usually covered private insurance job, Medicaid insurance government, rather covered Medicare.discussed previously, listed NHANES data frame Gender correctly referred Sex. Sex biological feature individual, Gender social construct. important distinction, ’ll change name variable.discussed previously, listed NHANES data frame Gender correctly referred Sex. Sex biological feature individual, Gender social construct. important distinction, ’ll change name variable.’ll also rename three variables, specifically ’ll use Race describe Race3 variable original NHANES data frame, well SBP refer average systolic blood pressure, specified BPSysAve, DBP refer average diastolic blood pressure, specified BPDiaAve.’ll also rename three variables, specifically ’ll use Race describe Race3 variable original NHANES data frame, well SBP refer average systolic blood pressure, specified BPSysAve, DBP refer average diastolic blood pressure, specified BPDiaAve.accomplished previous four steps, ’ll select variables want keep sample. (use select choosing variables columns data frame, filter selecting subjects rows.) sixteen variables select : ID, Sex, Age, Height, Weight, Race, Education, BMI, SBP, DBP, Pulse, PhysActive, Smoke100, SleepTrouble, MaritalStatus HealthGen.accomplished previous four steps, ’ll select variables want keep sample. (use select choosing variables columns data frame, filter selecting subjects rows.) sixteen variables select : ID, Sex, Age, Height, Weight, Race, Education, BMI, SBP, DBP, Pulse, PhysActive, Smoke100, SleepTrouble, MaritalStatus HealthGen.original NHANES data frame includes subjects (rows) multiple times effort incorporate sampling weights used NHANES analyses. purposes, though, ’d like include subject one time. use distinct() function limit data frame completely unique subjects (, example, don’t wind two rows ID number.)original NHANES data frame includes subjects (rows) multiple times effort incorporate sampling weights used NHANES analyses. purposes, though, ’d like include subject one time. use distinct() function limit data frame completely unique subjects (, example, don’t wind two rows ID number.)code used complete six steps listed create nh_temp data frame.resulting nh_temp data frame 1700 rows 16 columns.","code":"\nnh_temp <- NHANES %>%\n    filter(SurveyYr == \"2011_12\") %>%\n    filter(Age >= 21 & Age < 65) %>%\n    rename(Sex = Gender, Race = Race3, SBP = BPSysAve, DBP = BPDiaAve) %>%\n    select(ID, Sex, Age, Height, Weight, Race, Education, BMI, SBP, DBP, \n           Pulse, PhysActive, Smoke100, SleepTrouble, \n           MaritalStatus, HealthGen) %>%\n   distinct()\nnh_temp# A tibble: 1,700 x 16\n      ID Sex      Age Height Weight Race     Education   BMI\n   <int> <fct>  <int>  <dbl>  <dbl> <fct>    <fct>     <dbl>\n 1 62172 female    43   172    98.6 Black    High Sch~  33.3\n 2 62176 female    34   172.   68.7 White    College ~  23.3\n 3 62180 male      35   179.   89   White    College ~  27.9\n 4 62199 male      57   186    96.9 White    College ~  28  \n 5 62205 male      28   171.   84.8 White    College ~  28.9\n 6 62206 female    35   167.   81.5 White    Some Col~  29.1\n 7 62208 male      38   169.   63.2 Hispanic Some Col~  22.2\n 8 62209 female    62   143.   53.5 Mexican  8th Grade  26  \n 9 62220 female    31   167.  113.  Black    College ~  40.4\n10 62222 male      32   179    80.1 White    College ~  25  \n# ... with 1,690 more rows, and 8 more variables:\n#   SBP <int>, DBP <int>, Pulse <int>, PhysActive <fct>,\n#   Smoke100 <fct>, SleepTrouble <fct>,\n#   MaritalStatus <fct>, HealthGen <fct>"},{"path":"data-structures-variable-types-sampling-nhanes.html","id":"sampling-nh_temp-to-obtain-our-nh_adult750-sample","chapter":"4 Data Structures, Variable Types & Sampling NHANES","heading":"4.2.2 Sampling nh_temp to obtain our nh_adult750 sample","text":"established nh_temp sampling frame, now select random sample 750 adults 1700 available responses.use set.seed() function R set random numerical seed ensure redo work, obtain sample.\nSetting seed important part able replicate work later sampling involved.\nSetting seed important part able replicate work later sampling involved.use slice_sample() function actually draw random sample, without replacement.\n“Without replacement” means ’ve selected particular subject, won’t select .\n“Without replacement” means ’ve selected particular subject, won’t select .nh_adult750 data frame now includes 750 rows (observations) 16 variables (columns). Essentially, 16 pieces information 750 adult NHANES subjects included 2011-12 panel.","code":"\nset.seed(431002) \n# use set.seed to ensure that we all get the same random sample \n\nnh_adult750 <- slice_sample(nh_temp, n = 750, replace = F) \n\nnh_adult750# A tibble: 750 x 16\n      ID Sex      Age Height Weight Race     Education   BMI\n   <int> <fct>  <int>  <dbl>  <dbl> <fct>    <fct>     <dbl>\n 1 68648 female    30   181.   67.1 White    College ~  20.4\n 2 67200 male      30   180.   86.6 White    College ~  26.7\n 3 66404 female    35   160.   71.1 White    College ~  27.8\n 4 70535 male      40   177.   82   White    College ~  26.3\n 5 65308 female    54   151.   60.6 Mexican  8th Grade  26.6\n 6 67392 male      41   171.   90.7 Hispanic College ~  31.2\n 7 63218 male      35   163.   81   Mexican  8th Grade  30.3\n 8 65879 female    32   160.   66.4 Mexican  College ~  25.9\n 9 63617 male      29   189.   83.3 White    College ~  23.2\n10 64720 male      29   174.   62.3 Black    College ~  20.6\n# ... with 740 more rows, and 8 more variables: SBP <int>,\n#   DBP <int>, Pulse <int>, PhysActive <fct>,\n#   Smoke100 <fct>, SleepTrouble <fct>,\n#   MaritalStatus <fct>, HealthGen <fct>"},{"path":"data-structures-variable-types-sampling-nhanes.html","id":"summarizing-the-datas-structure","chapter":"4 Data Structures, Variable Types & Sampling NHANES","heading":"4.2.3 Summarizing the Data’s Structure","text":"can identify number rows columns data frame tibble dim function.str function provides lot information structure data frame tibble.see first observations, use head, see last , try tail…","code":"\ndim(nh_adult750)[1] 750  16\nstr(nh_adult750)tibble [750 x 16] (S3: tbl_df/tbl/data.frame)\n $ ID           : int [1:750] 68648 67200 66404 70535 65308 67392 63218 65879 63617 64720 ...\n $ Sex          : Factor w/ 2 levels \"female\",\"male\": 1 2 1 2 1 2 2 1 2 2 ...\n $ Age          : int [1:750] 30 30 35 40 54 41 35 32 29 29 ...\n $ Height       : num [1:750] 181 180 160 177 151 ...\n $ Weight       : num [1:750] 67.1 86.6 71.1 82 60.6 90.7 81 66.4 83.3 62.3 ...\n $ Race         : Factor w/ 6 levels \"Asian\",\"Black\",..: 5 5 5 5 4 3 4 4 5 2 ...\n $ Education    : Factor w/ 5 levels \"8th Grade\",\"9 - 11th Grade\",..: 5 5 5 5 1 5 1 5 5 5 ...\n $ BMI          : num [1:750] 20.4 26.7 27.8 26.3 26.6 31.2 30.3 25.9 23.2 20.6 ...\n $ SBP          : int [1:750] 103 113 116 130 130 124 128 104 105 127 ...\n $ DBP          : int [1:750] 59 68 80 79 64 82 96 70 72 60 ...\n $ Pulse        : int [1:750] 78 70 68 68 48 68 82 78 76 84 ...\n $ PhysActive   : Factor w/ 2 levels \"No\",\"Yes\": 1 2 2 1 1 2 1 2 2 2 ...\n $ Smoke100     : Factor w/ 2 levels \"No\",\"Yes\": 1 2 1 2 2 1 2 1 2 2 ...\n $ SleepTrouble : Factor w/ 2 levels \"No\",\"Yes\": 2 1 1 1 1 1 1 1 2 1 ...\n $ MaritalStatus: Factor w/ 6 levels \"Divorced\",\"LivePartner\",..: 3 4 3 3 2 3 3 3 3 2 ...\n $ HealthGen    : Factor w/ 5 levels \"Excellent\",\"Vgood\",..: 1 1 1 2 4 3 NA 1 2 4 ...\ntail(nh_adult750, 5) # shows the last five observations in the data set# A tibble: 5 x 16\n     ID Sex      Age Height Weight Race  Education      BMI\n  <int> <fct>  <int>  <dbl>  <dbl> <fct> <fct>        <dbl>\n1 63924 female    29   165.  113.  Black High School   41.9\n2 69825 female    43   164.   63.3 White College Grad  23.7\n3 68109 male      45   170.   78.7 Black High School   27.1\n4 64598 female    60   158    74.5 White Some College  29.8\n5 64048 female    54   161.   67.5 White Some College  26.2\n# ... with 8 more variables: SBP <int>, DBP <int>,\n#   Pulse <int>, PhysActive <fct>, Smoke100 <fct>,\n#   SleepTrouble <fct>, MaritalStatus <fct>,\n#   HealthGen <fct>"},{"path":"data-structures-variable-types-sampling-nhanes.html","id":"what-are-the-variables","chapter":"4 Data Structures, Variable Types & Sampling NHANES","heading":"4.2.4 What are the variables?","text":"can use glimpse function get short preview data.variables collected described brief table below16.levels multi-categorical variables :Race: Mexican, Hispanic, White, Black, Asian, .Education: 8th Grade, 9 - 11th Grade, High School, College, College Grad.MaritalStatus: Married, Widowed, Divorced, Separated, NeverMarried LivePartner (living partner).HealthGen: Excellent, Vgood, Good, Fair Poor.details can obtained using summary function.Note appearance NA's (indicating missing values) columns, variables summarized list (categorical) values (counts) (quantitative/numeric) variables summarized minimum, quartiles means.","code":"\nglimpse(nh_adult750)Rows: 750\nColumns: 16\n$ ID            <int> 68648, 67200, 66404, 70535, 65308, 6~\n$ Sex           <fct> female, male, female, male, female, ~\n$ Age           <int> 30, 30, 35, 40, 54, 41, 35, 32, 29, ~\n$ Height        <dbl> 181.3, 180.2, 159.8, 176.6, 150.9, 1~\n$ Weight        <dbl> 67.1, 86.6, 71.1, 82.0, 60.6, 90.7, ~\n$ Race          <fct> White, White, White, White, Mexican,~\n$ Education     <fct> College Grad, College Grad, College ~\n$ BMI           <dbl> 20.4, 26.7, 27.8, 26.3, 26.6, 31.2, ~\n$ SBP           <int> 103, 113, 116, 130, 130, 124, 128, 1~\n$ DBP           <int> 59, 68, 80, 79, 64, 82, 96, 70, 72, ~\n$ Pulse         <int> 78, 70, 68, 68, 48, 68, 82, 78, 76, ~\n$ PhysActive    <fct> No, Yes, Yes, No, No, Yes, No, Yes, ~\n$ Smoke100      <fct> No, Yes, No, Yes, Yes, No, Yes, No, ~\n$ SleepTrouble  <fct> Yes, No, No, No, No, No, No, No, Yes~\n$ MaritalStatus <fct> Married, NeverMarried, Married, Marr~\n$ HealthGen     <fct> Excellent, Excellent, Excellent, Vgo~\nsummary(nh_adult750)       ID            Sex           Age       \n Min.   :62206   female:388   Min.   :21.00  \n 1st Qu.:64277   male  :362   1st Qu.:30.00  \n Median :66925                Median :40.00  \n Mean   :66936                Mean   :40.82  \n 3rd Qu.:69414                3rd Qu.:51.00  \n Max.   :71911                Max.   :64.00  \n                                             \n     Height          Weight             Race    \n Min.   :142.4   Min.   : 39.30   Asian   : 70  \n 1st Qu.:161.8   1st Qu.: 67.40   Black   :128  \n Median :168.9   Median : 80.00   Hispanic: 63  \n Mean   :168.9   Mean   : 83.16   Mexican : 80  \n 3rd Qu.:175.7   3rd Qu.: 95.30   White   :393  \n Max.   :200.4   Max.   :198.70   Other   : 16  \n NA's   :5       NA's   :5                      \n          Education        BMI             SBP       \n 8th Grade     : 50   Min.   :16.70   Min.   : 83.0  \n 9 - 11th Grade: 76   1st Qu.:24.20   1st Qu.:108.0  \n High School   :143   Median :27.90   Median :118.0  \n Some College  :241   Mean   :29.08   Mean   :118.8  \n College Grad  :240   3rd Qu.:32.10   3rd Qu.:127.0  \n                      Max.   :80.60   Max.   :209.0  \n                      NA's   :5       NA's   :33     \n      DBP             Pulse        PhysActive Smoke100 \n Min.   :  0.00   Min.   : 40.00   No :326    No :453  \n 1st Qu.: 66.00   1st Qu.: 66.00   Yes:424    Yes:297  \n Median : 73.00   Median : 72.00                       \n Mean   : 72.69   Mean   : 73.53                       \n 3rd Qu.: 80.00   3rd Qu.: 80.00                       \n Max.   :108.00   Max.   :124.00                       \n NA's   :33       NA's   :32                           \n SleepTrouble      MaritalStatus     HealthGen  \n No :555      Divorced    : 78   Excellent: 84  \n Yes:195      LivePartner : 70   Vgood    :197  \n              Married     :388   Good     :252  \n              NeverMarried:179   Fair     :104  \n              Separated   : 19   Poor     : 14  \n              Widowed     : 16   NA's     : 99  \n                                                "},{"path":"data-structures-variable-types-sampling-nhanes.html","id":"quantitative-variables","chapter":"4 Data Structures, Variable Types & Sampling NHANES","heading":"4.3 Quantitative Variables","text":"Variables recorded numbers use numbers called quantitative. Familiar examples include incomes, heights, weights, ages, distances, times, counts. quantitative variables measurement units, tell quantitative variable measured. Without units (like miles per hour, angstroms, yen degrees Celsius) values quantitative variable meaning.little good told price something don’t know currency used.little good told price something don’t know currency used.might surprised see someone whose age 72 listed database childhood diseases find age measured months.might surprised see someone whose age 72 listed database childhood diseases find age measured months.Often just seeking units can reveal variable whose definition challenging - just measure “friendliness,” “success,” example.Often just seeking units can reveal variable whose definition challenging - just measure “friendliness,” “success,” example.Quantitative variables may also classified whether continuous can take discrete set values. Continuous data may take value, within defined range. Suppose measuring height. height really continuous, measuring stick usually lets us measure certain degree precision. measurements trustworthy nearest centimeter ruler , might describe discrete measures. always get precise ruler. measurement divisions make moving continuous concept discrete measurement usually fairly arbitrary. Another way think , enjoy music, , suggested Norman Streiner,17 piano discrete instrument, violin continuous one, enabling finer distinctions notes piano capable making. Sometimes distinction continuous discrete important, usually, ’s .\nnh_adult750 data includes several quantitative variables, specifically Age, Height, BMI,SBP,DBPandPulse`.\nknow quantitative units: Age years, Height centimeters, BMI kg/m2, BP measurements mm Hg, Pulse beats per minute.\nDepending context, likely treat discrete given measurements fairly crude (certainly true Age, measured years) although BMI probably continuous settings, even though function two measures (Height Weight) rounded integer numbers centimeters kilograms, respectively.\nQuantitative variables may also classified whether continuous can take discrete set values. Continuous data may take value, within defined range. Suppose measuring height. height really continuous, measuring stick usually lets us measure certain degree precision. measurements trustworthy nearest centimeter ruler , might describe discrete measures. always get precise ruler. measurement divisions make moving continuous concept discrete measurement usually fairly arbitrary. Another way think , enjoy music, , suggested Norman Streiner,17 piano discrete instrument, violin continuous one, enabling finer distinctions notes piano capable making. Sometimes distinction continuous discrete important, usually, ’s .nh_adult750 data includes several quantitative variables, specifically Age, Height, BMI,SBP,DBPandPulse`.know quantitative units: Age years, Height centimeters, BMI kg/m2, BP measurements mm Hg, Pulse beats per minute.Depending context, likely treat discrete given measurements fairly crude (certainly true Age, measured years) although BMI probably continuous settings, even though function two measures (Height Weight) rounded integer numbers centimeters kilograms, respectively.also possible separate quantitative variables ratio variables interval variables. interval variable equal distances values, zero point arbitrary. ratio variable equal intervals values, meaningful zero point. example, weight example ratio variable, IQ example interval variable. know zero weight . intelligence score like IQ different matter. say average IQ 100, ’s convention. just easily decided add 400 every IQ value make average 500 instead. IQ’s intervals equal, difference IQ 70 IQ 80 difference 120 130. However, IQ 100 twice high IQ 50. point zero point artificial movable, differences numbers meaningful ratios . hand, lab test values ratio variables, physical characteristics like height weight. person weighs 100 kg twice heavy one weighs 50 kg; even convert kg pounds, still true. part, can treat analyze interval ratio variables way.\nquantitative variables nh_adult750 data can thought ratio variables.\nalso possible separate quantitative variables ratio variables interval variables. interval variable equal distances values, zero point arbitrary. ratio variable equal intervals values, meaningful zero point. example, weight example ratio variable, IQ example interval variable. know zero weight . intelligence score like IQ different matter. say average IQ 100, ’s convention. just easily decided add 400 every IQ value make average 500 instead. IQ’s intervals equal, difference IQ 70 IQ 80 difference 120 130. However, IQ 100 twice high IQ 50. point zero point artificial movable, differences numbers meaningful ratios . hand, lab test values ratio variables, physical characteristics like height weight. person weighs 100 kg twice heavy one weighs 50 kg; even convert kg pounds, still true. part, can treat analyze interval ratio variables way.quantitative variables nh_adult750 data can thought ratio variables.Quantitative variables lend many summaries discuss, like means, quantiles, various measures spread, like standard deviation inter-quartile range. also least chance follow Normal distribution.Quantitative variables lend many summaries discuss, like means, quantiles, various measures spread, like standard deviation inter-quartile range. also least chance follow Normal distribution.","code":""},{"path":"data-structures-variable-types-sampling-nhanes.html","id":"a-look-at-bmi-body-mass-index","chapter":"4 Data Structures, Variable Types & Sampling NHANES","heading":"4.3.1 A look at BMI (Body-Mass Index)","text":"definition BMI (body-mass index) adult subjects (expressed units kg/m2) :\\[\n\\mbox{Body Mass Index} = \\frac{\\mbox{weight kg}}{(\\mbox{height meters})^2} = 703 \\times \\frac{\\mbox{weight pounds}}{(\\mbox{height inches})^2}\n\\][BMI essentially] … measure person’s thinness thickness… BMI designed use simple means classifying average sedentary (physically inactive) populations, average body composition. individuals, current value recommendations follow: BMI 18.5 25 may indicate optimal weight, BMI lower 18.5 suggests person underweight, number 25 30 may indicate person overweight, number 30 upwards suggests person obese.Wikipedia, https://en.wikipedia.org/wiki/Body_mass_index","code":""},{"path":"data-structures-variable-types-sampling-nhanes.html","id":"qualitative-categorical-variables","chapter":"4 Data Structures, Variable Types & Sampling NHANES","heading":"4.4 Qualitative (Categorical) Variables","text":"Qualitative categorical variables consist names categories. names may numerical, numbers (names) simply codes identify groups categories individuals divided. Categorical variables two categories, like yes , , , generally, 1 0, called binary variables. two-categories sometimes called multi-categorical variables.categories included variable merely names, come particular order, sometimes call nominal variables. important summary variable usually table frequencies, mode becomes important single summary, mean median essentially useless.\nnh_adult750 data, Race nominal variable multiple unordered categories. MaritalStatus.\ncategories included variable merely names, come particular order, sometimes call nominal variables. important summary variable usually table frequencies, mode becomes important single summary, mean median essentially useless.nh_adult750 data, Race nominal variable multiple unordered categories. MaritalStatus.alternative categorical variable (order matters) called ordinal, includes variables sometimes thought falling right quantitative qualitative variables.\nExamples ordinal multi-categorical variables nh_adult750 data include Education HealthGen variables.\nAnswers questions like “overall physical health?” available responses Excellent, Good, Good, Fair Poor, often coded 1-5, certainly provide perceived order, group people average health status 4 (Good) necessarily twice healthy group average health status 2 (Fair).\nalternative categorical variable (order matters) called ordinal, includes variables sometimes thought falling right quantitative qualitative variables.Examples ordinal multi-categorical variables nh_adult750 data include Education HealthGen variables.Answers questions like “overall physical health?” available responses Excellent, Good, Good, Fair Poor, often coded 1-5, certainly provide perceived order, group people average health status 4 (Good) necessarily twice healthy group average health status 2 (Fair).Sometimes treat values ordinal variables sufficiently scaled permit us use quantitative approaches like means, quantiles, standard deviations summarize model results, times, ’ll treat ordinal variables nominal, tables percentages primary tools.Sometimes treat values ordinal variables sufficiently scaled permit us use quantitative approaches like means, quantiles, standard deviations summarize model results, times, ’ll treat ordinal variables nominal, tables percentages primary tools.Note binary variables may treated ordinal, nominal.\nBinary variables nh_adult750 data include Sex, PhysActive, Smoke100, SleepTrouble. can thought either ordinal nominal.\nNote binary variables may treated ordinal, nominal.Binary variables nh_adult750 data include Sex, PhysActive, Smoke100, SleepTrouble. can thought either ordinal nominal.Lots variables may treated either quantitative qualitative, depending use . instance, usually think age quantitative variable, simply use age make distinction “child” “adult” using describe categorical information. Just variable’s values numbers, don’t assume information provided quantitative.","code":""},{"path":"data-structures-variable-types-sampling-nhanes.html","id":"counting-missing-values","chapter":"4 Data Structures, Variable Types & Sampling NHANES","heading":"4.5 Counting Missing Values","text":"summary() command counts number missing observations variable, sometimes want considerably information.can use functions naniar package learn useful things missing data nh_adult750 sample.miss_var_table command provides table number variables 0, 1, 2, n, missing values percentage total number variables variables make ., instance, 9 variables missing data, constitutes 56.25% 16 variables nh_adult750 data.miss_var_summary() function tabulates number, percent missing, cumulative sum missing variable data frame, order least missing values., example, rmiss_var_summary(nh_temp) %>% slice_head(n = 1) %>% select(variable)variable one missing data anything else within thenh_adult750` data frame.graph information available, well.’ll note also functions count number missing observations case (observation) rather variable. example, can use miss_case_table.Now see 636 observations, 84.8% cases missing data.can use miss_case_summary() identify cases missing data, well.","code":"\nmiss_var_table(nh_adult750)# A tibble: 5 x 3\n  n_miss_in_var n_vars pct_vars\n          <int>  <int>    <dbl>\n1             0      9    56.2 \n2             5      3    18.8 \n3            32      1     6.25\n4            33      2    12.5 \n5            99      1     6.25\nmiss_var_summary(nh_adult750)# A tibble: 16 x 3\n   variable      n_miss pct_miss\n   <chr>          <int>    <dbl>\n 1 HealthGen         99   13.2  \n 2 SBP               33    4.4  \n 3 DBP               33    4.4  \n 4 Pulse             32    4.27 \n 5 Height             5    0.667\n 6 Weight             5    0.667\n 7 BMI                5    0.667\n 8 ID                 0    0    \n 9 Sex                0    0    \n10 Age                0    0    \n11 Race               0    0    \n12 Education          0    0    \n13 PhysActive         0    0    \n14 Smoke100           0    0    \n15 SleepTrouble       0    0    \n16 MaritalStatus      0    0    \ngg_miss_var(nh_adult750)\nmiss_case_table(nh_adult750)# A tibble: 6 x 3\n  n_miss_in_case n_cases pct_cases\n           <int>   <int>     <dbl>\n1              0     636    84.8  \n2              1      78    10.4  \n3              3      15     2    \n4              4      19     2.53 \n5              6       1     0.133\n6              7       1     0.133\nmiss_case_summary(nh_adult750)# A tibble: 750 x 3\n    case n_miss pct_miss\n   <int>  <int>    <dbl>\n 1   342      7     43.8\n 2   606      6     37.5\n 3   157      4     25  \n 4   169      4     25  \n 5   204      4     25  \n 6   234      4     25  \n 7   323      4     25  \n 8   415      4     25  \n 9   478      4     25  \n10   483      4     25  \n# ... with 740 more rows"},{"path":"data-structures-variable-types-sampling-nhanes.html","id":"nh_cc","chapter":"4 Data Structures, Variable Types & Sampling NHANES","heading":"4.6 nh_adults500cc: A Sample of Complete Cases","text":"wanted sample exactly 750 subjects complete data, needed add step development nh_temp sampling frame filter complete cases.Let’s check new sampling frame missing data.OK. Now, let’s create second sample, called nh_adult500cc, now, select 500 adults complete data variables interest, using different random seed. cc stands complete cases.","code":"\nnh_temp2 <- NHANES %>%\n    filter(SurveyYr == \"2011_12\") %>%\n    filter(Age >= 21 & Age < 65) %>%\n    rename(Sex = Gender, Race = Race3, SBP = BPSysAve, DBP = BPDiaAve) %>%\n    select(ID, Sex, Age, Height, Weight, Race, Education, BMI, SBP, DBP, \n           Pulse, PhysActive, Smoke100, SleepTrouble, \n           MaritalStatus, HealthGen) %>%\n    distinct() %>%\n    filter(complete.cases(.))\nmiss_var_table(nh_temp2)# A tibble: 1 x 3\n  n_miss_in_var n_vars pct_vars\n          <int>  <int>    <dbl>\n1             0     16      100\nset.seed(431003) \n# use set.seed to ensure that we all get the same random sample \n\nnh_adult500cc <- slice_sample(nh_temp2, n = 500, replace = F) \n\nnh_adult500cc# A tibble: 500 x 16\n      ID Sex      Age Height Weight Race     Education   BMI\n   <int> <fct>  <int>  <dbl>  <dbl> <fct>    <fct>     <dbl>\n 1 64079 female    25   159.   86.2 Hispanic Some Col~  34.2\n 2 64374 female    52   169    65.5 Asian    College ~  22.9\n 3 71875 male      42   182.   94.1 Black    College ~  28.5\n 4 66396 female    46   161.  107.  Asian    8th Grade  41.2\n 5 64315 female    52   161.   64.5 White    9 - 11th~  24.9\n 6 64015 male      32   168.   82.3 Mexican  Some Col~  29  \n 7 63590 male      21   181.   98.3 Black    Some Col~  29.9\n 8 70893 female    30   171.   65.7 White    9 - 11th~  22.5\n 9 70828 male      26   178.  100.  White    Some Col~  31.5\n10 67930 male      59   172.   91.7 Mexican  College ~  31  \n# ... with 490 more rows, and 8 more variables: SBP <int>,\n#   DBP <int>, Pulse <int>, PhysActive <fct>,\n#   Smoke100 <fct>, SleepTrouble <fct>,\n#   MaritalStatus <fct>, HealthGen <fct>"},{"path":"data-structures-variable-types-sampling-nhanes.html","id":"saving-our-samples-in-.rds-files","chapter":"4 Data Structures, Variable Types & Sampling NHANES","heading":"4.7 Saving our Samples in .Rds files","text":"’ll save nh_adult750 nh_adult500cc samples use later parts notes. , ’ll save .Rds files, advantages us later .also find .Rds files part 431-data repository course.Next, ’ll load, explore learn variables two samples.","code":"\nwrite_rds(nh_adult750, file = \"data/nh_adult750.Rds\")\nwrite_rds(nh_adult500cc, file = \"data/nh_adult500cc.Rds\")"},{"path":"visualizing-nhanes-data.html","id":"visualizing-nhanes-data","chapter":"5 Visualizing NHANES Data","heading":"5 Visualizing NHANES Data","text":"","code":""},{"path":"visualizing-nhanes-data.html","id":"loading-in-the-complete-cases-sample","chapter":"5 Visualizing NHANES Data","heading":"5.1 Loading in the “Complete Cases” Sample","text":"Let’s begin loading nh_500cc data frame information nh_adult500cc.Rds file created Section @ref(nh_cc).One obvious hurdle ’ll avoid moment missing data, since nh_500cc data specifically drawn complete responses. Working complete cases can introduce bias estimates visualizations, necessary time address complete-case analysis isn’t good choice. ’ll return issue chapters.","code":"\nnh_500cc <- read_rds(\"data/nh_adult500cc.Rds\")"},{"path":"visualizing-nhanes-data.html","id":"distribution-of-heights","chapter":"5 Visualizing NHANES Data","heading":"5.2 Distribution of Heights","text":"distribution height new sample?can several things clean .’ll change color lines bar histogram.’ll change fill inside bar make stand bit .’ll add title relabel horizontal (x) axis include units measurement.’ll avoid warning selecting number bins (’ll use 25 ) ’ll group heights drawing histogram.","code":"\nggplot(data = nh_500cc, aes(x = Height)) + \n    geom_histogram() `stat_bin()` using `bins = 30`. Pick better value with\n`binwidth`.\nggplot(data = nh_500cc, aes(x = Height)) + \n    geom_histogram(bins = 25, col = \"yellow\", fill = \"blue\") + \n    labs(title = \"Height of NHANES subjects ages 21-64\",\n         x = \"Height in cm.\")"},{"path":"visualizing-nhanes-data.html","id":"changing-a-histograms-fill-and-color","chapter":"5 Visualizing NHANES Data","heading":"5.2.1 Changing a Histogram’s Fill and Color","text":"CWRU color guide (https://case.edu/umc/-brand/visual-guidelines/) lists HTML color schemes CWRU blue CWRU gray. Let’s match color scheme. also change bins histogram, gather observations groups 2 cm. , specifying width bins, rather number bins.","code":"\ncwru.blue <- '#0a304e'\ncwru.gray <- '#626262'\n\nggplot(data = nh_500cc, aes(x = Height)) + \n    geom_histogram(binwidth = 2, \n                   col = cwru.gray, fill = cwru.blue) + \n    labs(title = \"Height of NHANES subjects ages 21-64\",\n         x = \"Height in cm.\") "},{"path":"visualizing-nhanes-data.html","id":"using-a-frequency-polygon","chapter":"5 Visualizing NHANES Data","heading":"5.2.2 Using a frequency polygon","text":"frequency polygon essentially smooths top histogram, can also used show distribution Height.","code":"\nggplot(data = nh_500cc, aes(x = Height)) +\n    geom_freqpoly(bins = 20) +\n    labs(title = \"Height of NHANES subjects ages 21-64\",\n         x = \"Height in cm.\")"},{"path":"visualizing-nhanes-data.html","id":"using-a-dotplot","chapter":"5 Visualizing NHANES Data","heading":"5.2.3 Using a dotplot","text":"dotplot can also used show distribution variable like Height, produces somewhat granular histogram, depending settings binwidth dotsize.","code":"\nggplot(data = nh_500cc, aes(x = Height)) +\n    geom_dotplot(dotsize = 0.75, binwidth = 1) +\n    scale_y_continuous(NULL, breaks = NULL) + # hide y axis\n    labs(title = \"Height of NHANES subjects ages 21-64\",\n         x = \"Height in cm.\")"},{"path":"visualizing-nhanes-data.html","id":"height-and-sex","chapter":"5 Visualizing NHANES Data","heading":"5.3 Height and Sex","text":"Let’s look impact respondent’s sex height, now within sample adults.plot isn’t useful. can improve things little jittering points horizontally, overlap reduced.Perhaps might better summarise distribution different way. might consider boxplot data.","code":"\nggplot(data = nh_500cc, \n       aes(x = Sex, y = Height, color = Sex)) + \n    geom_point() + \n    labs(title = \"Height by Sex for NHANES subjects ages 21-64\",\n         y = \"Height in cm.\")\nggplot(data = nh_500cc, aes(x = Sex, y = Height, color = Sex)) + \n    geom_jitter(width = 0.2) + \n    labs(title = \"Height by Sex (jittered) for NHANES subjects ages 21-64\",\n         y = \"Height in cm.\")"},{"path":"visualizing-nhanes-data.html","id":"a-boxplot-of-height-by-sex","chapter":"5 Visualizing NHANES Data","heading":"5.3.1 A Boxplot of Height by Sex","text":"boxplot shows summary statistics based percentiles. boxes middle line show data values include middle half data sorted. 25th percentile (value exceeds 1/4 data) indicated bottom box, top box located 75th percentile. solid line inside box indicates median (also called 50th percentile) Heights Sex.","code":"\nggplot(data = nh_500cc, aes(x = Sex, y = Height, fill = Sex)) + \n    geom_boxplot() + \n    labs(title = \"Boxplot of Height by Sex for NHANES subjects ages 21-64\",\n         y = \"Height in cm.\")"},{"path":"visualizing-nhanes-data.html","id":"adding-a-violin-plot","chapter":"5 Visualizing NHANES Data","heading":"5.3.2 Adding a violin plot","text":"boxplot often supplemented violin plot better show shape distribution.usually works better boxes given different fill violins, shown following figure.can also flip boxplots side, using coord_flip().","code":"\nggplot(data = nh_500cc, aes(x = Sex, y = Height, fill = Sex)) +\n    geom_violin() +\n    geom_boxplot(width = 0.3) +\n    labs(title = \"Boxplot of Height by Sex for NHANES subjects ages 21-64\",\n         y = \"Height in cm.\")\nggplot(data = nh_500cc, aes(x = Sex, y = Height)) +\n    geom_violin(aes(fill = Sex)) +\n    geom_boxplot(width = 0.3) +\n    labs(title = \"Boxplot of Height by Sex for NHANES subjects ages 21-64\",\n         y = \"Height in cm.\")\nggplot(data = nh_500cc, aes(x = Sex, y = Height)) +\n    geom_violin() +\n    geom_boxplot(aes(fill = Sex), width = 0.3) +\n    labs(title = \"Boxplot of Height by Sex for NHANES subjects ages 21-64\",\n         y = \"Height in cm.\") +\n    coord_flip()"},{"path":"visualizing-nhanes-data.html","id":"histograms-of-height-by-sex","chapter":"5 Visualizing NHANES Data","heading":"5.3.3 Histograms of Height by Sex","text":"perhaps ’d like see pair histograms?Can redraw histograms little comparable, get rid unnecessary legend?","code":"\nggplot(data = nh_500cc, aes(x = Height, fill = Sex)) + \n    geom_histogram(color = \"white\", bins = 20) + \n    labs(title = \"Histogram of Height by Sex for NHANES subjects ages 21-64\",\n         x = \"Height in cm.\") + \n    facet_wrap(~ Sex)\nggplot(data = nh_500cc, aes(x = Height, fill = Sex)) + \n    geom_histogram(color = \"white\", bins = 20) + \n    labs(title = \"Histogram of Height by Sex for NHANES subjects ages 21-64 (Revised)\",\n         x = \"Height in cm.\") + \n    guides(fill = \"none\") +\n    facet_grid(Sex ~ .)"},{"path":"visualizing-nhanes-data.html","id":"looking-at-pulse-rate","chapter":"5 Visualizing NHANES Data","heading":"5.4 Looking at Pulse Rate","text":"Let’s look different outcome, pulse rate subjects.’s histogram, CWRU colors, pulse rates sample.Suppose instead bin groups 5 beats per minute together plot Pulse rates.useful representation depend lot questions ’re trying answer.","code":"\nggplot(data = nh_500cc, aes(x = Pulse)) + \n    geom_histogram(binwidth = 1, \n                   fill = cwru.blue, col = cwru.gray) + \n    labs(title = \"Histogram of Pulse Rate: NHANES subjects ages 21-64\",\n         x = \"Pulse Rate (beats per minute)\")\nggplot(data = nh_500cc, aes(x = Pulse)) + \n    geom_histogram(binwidth = 5, \n                   fill = cwru.blue, col = cwru.gray) + \n    labs(title = \"Histogram of Pulse Rate: NHANES subjects ages 21-64\",\n         x = \"Pulse Rate (beats per minute)\")"},{"path":"visualizing-nhanes-data.html","id":"pulse-rate-and-physical-activity","chapter":"5 Visualizing NHANES Data","heading":"5.4.1 Pulse Rate and Physical Activity","text":"can also split data groups based whether subjects physically active. Let’s try boxplot.accompanying numerical summary, might ask many people fall PhysActive categories, “average” Pulse rate.knitr::kable(digits = 2) piece command tells R Markdown generate table attractive formatting, rounding decimals two figures.","code":"\nggplot(data = nh_500cc, \n       aes(y = Pulse, x = PhysActive, fill = PhysActive)) + \n    geom_boxplot() + \n    labs(title = \"Pulse Rate by Physical Activity Status for NHANES ages 21-64\")\nnh_500cc %>%\n    group_by(PhysActive) %>%\n    summarise(count = n(), mean(Pulse), median(Pulse)) %>%\n    knitr::kable(digits = 2) "},{"path":"visualizing-nhanes-data.html","id":"pulse-by-sleeping-trouble","chapter":"5 Visualizing NHANES Data","heading":"5.4.2 Pulse by Sleeping Trouble","text":"many people fall SleepTrouble categories, “average” Pulse rate?","code":"\nggplot(data = nh_500cc, aes(x = Pulse, fill = SleepTrouble)) + \n    geom_histogram(color = \"white\", bins = 20) + \n    labs(title = \"Histogram of Pulse Rate by Sleep Trouble for NHANES subjects ages 21-64\",\n         x = \"Pulse Rate (beats per minute)\") + \n    guides(fill = \"none\") +\n    facet_grid(SleepTrouble ~ ., labeller = \"label_both\")\nnh_500cc %>%\n    group_by(SleepTrouble) %>%\n    summarise(count = n(), mean(Pulse), median(Pulse)) %>%\n    knitr::kable(digits = 2) "},{"path":"visualizing-nhanes-data.html","id":"pulse-and-healthgen","chapter":"5 Visualizing NHANES Data","heading":"5.4.3 Pulse and HealthGen","text":"can compare distribution Pulse rate across groups subject’s self-reported overall health (HealthGen), well.many people fall HealthGen categories, “average” Pulse rate?","code":"\nggplot(data = nh_500cc, aes(x = HealthGen, y = Pulse, fill = HealthGen)) + \n    geom_boxplot() +\n    labs(title = \"Pulse by Self-Reported Overall Health for NHANES ages 21-64\",\n         x = \"Self-Reported Overall Health\", y = \"Pulse Rate\") + \n    guides(fill = \"none\") \nnh_500cc %>%\n    group_by(HealthGen) %>%\n    summarise(count = n(), mean(Pulse), median(Pulse)) %>%\n    knitr::kable(digits = 2) "},{"path":"visualizing-nhanes-data.html","id":"pulse-rate-and-systolic-blood-pressure","chapter":"5 Visualizing NHANES Data","heading":"5.4.4 Pulse Rate and Systolic Blood Pressure","text":"","code":"\nggplot(data = nh_500cc, aes(x = SBP, y = Pulse)) +\n    geom_point() +\n    geom_smooth(method = \"loess\", formula = y ~ x) +\n    labs(title = \"Pulse Rate vs. SBP for NHANES subjects, ages 21-64\")"},{"path":"visualizing-nhanes-data.html","id":"sleep-trouble-vs.-no-sleep-trouble","chapter":"5 Visualizing NHANES Data","heading":"5.4.5 Sleep Trouble vs. No Sleep Trouble?","text":"see whether subjects described SleepTrouble show different SBP-pulse rate patterns subjects haven’t?Let’s try changing shape color points based SleepTrouble.plot might easier interpret faceted SleepTrouble, well.","code":"\nggplot(data = nh_500cc, \n       aes(x = SBP, y = Pulse, \n           color = SleepTrouble, shape = SleepTrouble)) +\n    geom_point() +\n    geom_smooth(method = \"loess\", formula = y ~ x) +\n    labs(title = \"Pulse Rate vs. SBP for NHANES subjects, ages 21-64\")\nggplot(data = nh_500cc, \n       aes(x = SBP, y = Pulse, \n           color = SleepTrouble, shape = SleepTrouble)) +\n    geom_point() +\n    geom_smooth(method = \"loess\", formula = y ~ x) +\n    labs(title = \"Pulse Rate vs. SBP for NHANES subjects, ages 21-64\") +\n    facet_wrap(~ SleepTrouble, labeller = \"label_both\")"},{"path":"visualizing-nhanes-data.html","id":"general-health-status","chapter":"5 Visualizing NHANES Data","heading":"5.5 General Health Status","text":"’s Table General Health Status results. , self-reported rating subject’s health five point scale (Excellent, Good, Good, Fair, Poor.)HealthGen data categorical, means summarizing averages isn’t appealing looking percentages, proportions rates. tabyl function comes janitor package R.don’t actually like title percent , ’s really proportion, can adjusted, can add total.working unordered categorical variable, like MaritalStatus, approach can work.","code":"\nnh_500cc %>%\n    tabyl(HealthGen)  HealthGen   n percent\n Excellent  52   0.104\n     Vgood 167   0.334\n      Good 204   0.408\n      Fair  65   0.130\n      Poor  12   0.024\nnh_500cc %>%\n    tabyl(HealthGen) %>%\n    adorn_totals() %>%\n    adorn_pct_formatting() HealthGen   n percent\n Excellent  52   10.4%\n     Vgood 167   33.4%\n      Good 204   40.8%\n      Fair  65   13.0%\n      Poor  12    2.4%\n     Total 500  100.0%\nnh_500cc %>%\n    tabyl(MaritalStatus) %>%\n    adorn_totals() %>%\n    adorn_pct_formatting() MaritalStatus   n percent\n      Divorced  47    9.4%\n   LivePartner  46    9.2%\n       Married 256   51.2%\n  NeverMarried 125   25.0%\n     Separated  17    3.4%\n       Widowed   9    1.8%\n         Total 500  100.0%"},{"path":"visualizing-nhanes-data.html","id":"bar-chart-for-categorical-data","chapter":"5 Visualizing NHANES Data","heading":"5.5.1 Bar Chart for Categorical Data","text":"Usually, bar chart best choice graphing variable made categories.lots things can make plot fancier., can really go crazy…","code":"\nggplot(data = nh_500cc, aes(x = HealthGen)) + \n    geom_bar()\nggplot(data = nh_500cc, aes(x = HealthGen, fill = HealthGen)) + \n    geom_bar() + \n    guides(fill = \"none\") +\n    labs(x = \"Self-Reported Health Status\",\n         y = \"Number of NHANES subjects\",\n         title = \"Self-Reported Health Status in NHANES subjects ages 21-64\")\nnh_500cc %>%\n    count(HealthGen) %>%\n    mutate(pct = round_half_up(prop.table(n) * 100, 1)) %>%\n    ggplot(aes(x = HealthGen, y = pct, fill = HealthGen)) + \n    geom_bar(stat = \"identity\", position = \"dodge\") +\n    scale_fill_viridis_d() +\n    guides(fill = \"none\") +\n    geom_text(aes(y = pct + 1,    # nudge above top of bar\n                  label = paste0(pct, '%')),  # prettify\n              position = position_dodge(width = .9), \n              size = 4) +\n    labs(x = \"Self-Reported Health Status\",\n         y = \"Percentage of NHANES subjects\",\n         title = \"Self-Reported Health Status in NHANES subjects ages 21-64\") +\n    theme_bw()"},{"path":"visualizing-nhanes-data.html","id":"two-way-tables","chapter":"5 Visualizing NHANES Data","heading":"5.5.2 Two-Way Tables","text":"can create cross-classifications two categorical variables (example HealthGen Smoke100), adding row column marginal totals, compare subjects Sex, follows…like, can make look little polished knitr::kable function…, can get complete cross-tabulation, including (case) percentages people within two categories Smoke100 fall HealthGen category (percentages within row) like ., wanted column percentages, determine sex higher rate HealthGen status level, can get changing adorn_percentages describe results column level:","code":"\nnh_500cc %>%\n    tabyl(Smoke100, HealthGen) %>%\n    adorn_totals(c(\"row\", \"col\"))  Smoke100 Excellent Vgood Good Fair Poor Total\n       No        44   108  105   29    5   291\n      Yes         8    59   99   36    7   209\n    Total        52   167  204   65   12   500\nnh_500cc %>%\n    tabyl(Smoke100, HealthGen) %>%\n    adorn_totals(c(\"row\", \"col\")) %>%\n    knitr::kable()\nnh_500cc %>%\n    tabyl(Smoke100, HealthGen) %>%\n    adorn_totals(\"row\") %>%\n    adorn_percentages(\"row\") %>%\n    adorn_pct_formatting() %>%\n    adorn_ns() %>%\n    knitr::kable()\nnh_500cc %>%\n    tabyl(Sex, HealthGen) %>%\n    adorn_totals(\"col\") %>%\n    adorn_percentages(\"col\") %>%\n    adorn_pct_formatting() %>%\n    adorn_ns() %>%\n    knitr::kable()"},{"path":"visualizing-nhanes-data.html","id":"sbp-by-general-health-status","chapter":"5 Visualizing NHANES Data","heading":"5.5.3 SBP by General Health Status","text":"Let’s consider now relationship self-reported overall health systolic blood pressure.can see many people self-identify “Poor” health category.","code":"\nggplot(data = nh_500cc, aes(x = HealthGen, y = SBP, \n                            fill = HealthGen)) + \n    geom_boxplot() + \n    labs(title = \"SBP by Health Status, Overall Health for NHANES ages 21-64\",\n         y = \"Systolic Blood Pressure\", \n         x = \"Self-Reported Overall Health\") + \n    guides(fill = \"none\") \nnh_500cc %>%\n    group_by(HealthGen) %>%\n    summarise(count = n(), mean(SBP), median(SBP)) %>%\n    knitr::kable() "},{"path":"visualizing-nhanes-data.html","id":"sbp-by-physical-activity-and-general-health-status","chapter":"5 Visualizing NHANES Data","heading":"5.5.4 SBP by Physical Activity and General Health Status","text":"’ll build panel boxplots try understand relationships Systolic Blood Pressure, General Health Status Physical Activity. Note use coord_flip rotate graph 90 degrees, use labeller within facet_wrap include name (Physical Activity) variable value.","code":"\nggplot(data = nh_500cc, aes(x = HealthGen, y = SBP, fill = HealthGen)) + \n    geom_boxplot() + \n    labs(title = \"SBP by Health Status, Overall Health for NHANES ages 21-64\",\n         y = \"Systolic BP\", x = \"Self-Reported Overall Health\") + \n    guides(fill = \"none\") +\n    facet_wrap(~ PhysActive, labeller = \"label_both\") + \n    coord_flip()"},{"path":"visualizing-nhanes-data.html","id":"sbp-by-sleep-trouble-and-general-health-status","chapter":"5 Visualizing NHANES Data","heading":"5.5.5 SBP by Sleep Trouble and General Health Status","text":"’s plot faceted histograms, might used address similar questions related relationship Overall Health, Systolic Blood Pressure whether someone trouble sleeping.","code":"\nggplot(data = nh_500cc, aes(x = SBP, fill = HealthGen)) + \n    geom_histogram(color = \"white\", bins = 20) + \n    labs(title = \"SBP by Overall Health and Sleep Trouble for NHANES ages 21-64\",\n         x = \"Systolic BP\") + \n    guides(fill = \"none\") +\n    facet_grid(SleepTrouble ~ HealthGen, labeller = \"label_both\")"},{"path":"visualizing-nhanes-data.html","id":"conclusions","chapter":"5 Visualizing NHANES Data","heading":"5.6 Conclusions","text":"just small piece toolbox visualizations ’ll create class. Many additional tools way, main idea won’t change. Using ggplot2 package, can accomplish several critical tasks creating visualization, including:Identifying (labeling) axes titlesIdentifying type geom use, like point, bar histogramChanging fill, color, shape, size facilitate comparisonsBuilding “small multiples” plots facetingGood data visualizations make easy see data, ggplot2’s tools make relatively difficult make really bad graph.","code":""},{"path":"summarizing_quantities.html","id":"summarizing_quantities","chapter":"6 Summarizing Quantities","heading":"6 Summarizing Quantities","text":"numerical summaries might new applied appropriately quantitative variables. measures interest us relate :center distribution,spread distribution, andthe shape distribution.demonstrate key ideas Chapter, consider sample 750 adults ages 21-64 NHANES 2011-12 includes missing values. ’ll load nh_750 data frame information nh_adult750.Rds file created Section 4.2.","code":"\nnh_750 <- read_rds(\"data/nh_adult750.Rds\")"},{"path":"summarizing_quantities.html","id":"the-summary-function-for-quantitative-data","chapter":"6 Summarizing Quantities","heading":"6.1 The summary function for Quantitative data","text":"R provides small sampling numerical summaries summary function, instance.basic summary includes set five quantiles18, plus sample’s mean.Min. = minimum value variable, , example, youngest subject’s Age 21.1st Qu. = first quartile (25th percentile) variable - example, 25% subjects Age 30 younger.Median = median (50th percentile) - half subjects Age 40 younger.Mean = mean, usually one means average - sum Ages divided 750 40.8,3rd Qu. = third quartile (75th percentile) - 25% subjects Age 51 older.Max. = maximum value variable, oldest subject Age 64.summary also specifies number missing values variable. , missing 5 BMI values, example.","code":"\nnh_750 %>%\n  select(Age, BMI, SBP, DBP, Pulse) %>%\n  summary()      Age             BMI             SBP       \n Min.   :21.00   Min.   :16.70   Min.   : 83.0  \n 1st Qu.:30.00   1st Qu.:24.20   1st Qu.:108.0  \n Median :40.00   Median :27.90   Median :118.0  \n Mean   :40.82   Mean   :29.08   Mean   :118.8  \n 3rd Qu.:51.00   3rd Qu.:32.10   3rd Qu.:127.0  \n Max.   :64.00   Max.   :80.60   Max.   :209.0  \n                 NA's   :5       NA's   :33     \n      DBP             Pulse       \n Min.   :  0.00   Min.   : 40.00  \n 1st Qu.: 66.00   1st Qu.: 66.00  \n Median : 73.00   Median : 72.00  \n Mean   : 72.69   Mean   : 73.53  \n 3rd Qu.: 80.00   3rd Qu.: 80.00  \n Max.   :108.00   Max.   :124.00  \n NA's   :33       NA's   :32      "},{"path":"summarizing_quantities.html","id":"measuring-the-center-of-a-distribution","chapter":"6 Summarizing Quantities","heading":"6.2 Measuring the Center of a Distribution","text":"","code":""},{"path":"summarizing_quantities.html","id":"the-mean-and-the-median","chapter":"6 Summarizing Quantities","heading":"6.2.1 The Mean and The Median","text":"mean median commonly used measures center distribution quantitative variable. median generally useful value, relevant even data shape symmetric. might also collect sum observations, count number observations, usually symbolized n.variables without missing values, like Age, pretty straightforward., Mean just Sum (30616), divided number non-missing values Age (750), 40.8213333.Median middle value data sorted order. odd number values, sufficient. even number, case, take mean two middle values. sort list 500 Ages, wanted .data set figures don’t want output 10 observations table like .really want see data, can use View(nh_750) get spreadsheet-style presentation, use sort command…, find median, take mean middle two observations sorted data set. 250th 251st largest Ages.","code":"\nnh_750 %>%\n    summarise(n = n(), Mean = mean(Age), Median = median(Age), Sum = sum(Age))# A tibble: 1 x 4\n      n  Mean Median   Sum\n  <int> <dbl>  <dbl> <int>\n1   750  40.8     40 30616\nnh_750 %>% select(Age) %>% \n    arrange(Age)# A tibble: 750 x 1\n     Age\n   <int>\n 1    21\n 2    21\n 3    21\n 4    21\n 5    21\n 6    21\n 7    21\n 8    21\n 9    21\n10    21\n# ... with 740 more rows\nsort(nh_750$Age)  [1] 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21\n [19] 21 21 21 21 22 22 22 22 22 22 22 22 22 22 22 22 22 22\n [37] 22 22 22 22 22 22 22 22 23 23 23 23 23 23 23 23 23 23\n [55] 23 23 23 23 23 23 23 23 23 23 23 23 24 24 24 24 24 24\n [73] 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 25\n [91] 25 25 25 25 25 25 25 25 25 25 25 25 25 26 26 26 26 26\n[109] 26 26 26 26 26 26 26 26 26 27 27 27 27 27 27 27 27 27\n[127] 27 27 27 27 28 28 28 28 28 28 28 28 28 28 28 28 28 28\n[145] 28 28 28 28 28 28 29 29 29 29 29 29 29 29 29 29 29 29\n[163] 29 29 29 29 29 29 29 29 30 30 30 30 30 30 30 30 30 30\n[181] 30 30 30 30 30 30 30 30 30 30 30 30 30 30 31 31 31 31\n[199] 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 32 32 32\n[217] 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32\n[235] 32 32 32 32 32 32 32 33 33 33 33 33 33 33 33 33 33 33\n[253] 33 33 33 33 33 33 33 33 33 33 33 33 33 34 34 34 34 34\n[271] 34 34 34 34 34 34 34 34 34 35 35 35 35 35 35 35 35 35\n[289] 35 35 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36\n[307] 36 36 36 36 36 36 36 36 36 36 37 37 37 37 37 37 37 37\n[325] 37 37 37 37 37 37 37 37 37 37 38 38 38 38 38 38 38 38\n[343] 38 38 38 38 38 38 38 38 39 39 39 39 39 39 39 39 39 39\n[361] 39 39 39 39 39 39 39 39 39 40 40 40 40 40 40 40 40 40\n[379] 40 40 40 40 40 40 40 40 40 41 41 41 41 41 41 41 41 41\n[397] 41 41 41 41 42 42 42 42 42 42 42 42 42 42 42 42 42 42\n[415] 42 42 42 42 42 43 43 43 43 43 43 43 43 43 43 43 43 43\n[433] 43 43 43 43 43 44 44 44 44 44 44 44 44 44 44 44 44 44\n[451] 44 44 44 45 45 45 45 45 45 45 45 45 45 45 45 45 45 45\n[469] 45 45 46 46 46 46 46 46 46 46 46 46 46 46 46 46 47 47\n[487] 47 47 47 47 47 47 47 47 47 47 47 47 47 47 47 48 48 48\n[505] 48 48 48 48 48 48 48 48 49 49 49 49 49 49 49 49 49 49\n[523] 49 49 49 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50\n[541] 50 50 50 50 50 50 50 50 50 50 50 51 51 51 51 51 51 51\n[559] 51 51 51 51 51 51 51 51 51 51 51 51 51 52 52 52 52 52\n[577] 52 52 52 52 52 52 52 53 53 53 53 53 53 53 53 53 53 53\n[595] 53 53 53 53 54 54 54 54 54 54 54 54 54 54 54 54 54 54\n[613] 54 54 55 55 55 55 55 55 55 55 55 55 56 56 56 56 56 56\n[631] 56 56 56 56 56 56 56 56 56 56 56 56 56 57 57 57 57 57\n[649] 57 57 57 57 58 58 58 58 58 58 58 58 58 58 58 58 58 58\n[667] 58 58 58 58 59 59 59 59 59 59 59 59 59 59 59 59 59 60\n[685] 60 60 60 60 60 60 60 60 60 60 60 60 61 61 61 61 61 61\n[703] 61 61 61 61 61 61 61 61 62 62 62 62 62 62 62 62 62 62\n[721] 62 62 62 63 63 63 63 63 63 63 63 63 63 63 63 63 64 64\n[739] 64 64 64 64 64 64 64 64 64 64 64 64\nsort(nh_750$Age)[250:251][1] 33 33"},{"path":"summarizing_quantities.html","id":"dealing-with-missingness","chapter":"6 Summarizing Quantities","heading":"6.2.2 Dealing with Missingness","text":"calculating mean, may tempted try something like …fails missing values Pulse data. can address either omitting data missing values run summarise() function, tell mean median summary functions remove missing values19., tell summary functions remove NA values.Chapter 8, discuss various assumptions can make missing data, importance imputation dealing modeling making inferences. now, limit descriptive summaries observed values, called complete case available case analyses.","code":"\nnh_750 %>%\n    summarise(mean(Pulse), median(Pulse))# A tibble: 1 x 2\n  `mean(Pulse)` `median(Pulse)`\n          <dbl>           <int>\n1            NA              NA\nnh_750 %>%\n    filter(complete.cases(Pulse)) %>%\n    summarise(count = n(), mean(Pulse), median(Pulse))# A tibble: 1 x 3\n  count `mean(Pulse)` `median(Pulse)`\n  <int>         <dbl>           <dbl>\n1   718          73.5              72\nnh_750 %>%\n    summarise(mean(Pulse, na.rm=TRUE), median(Pulse, na.rm=TRUE))# A tibble: 1 x 2\n  `mean(Pulse, na.rm = TRUE)` `median(Pulse, na.rm = TRUE)`\n                        <dbl>                         <dbl>\n1                        73.5                            72"},{"path":"summarizing_quantities.html","id":"the-mode-of-a-quantitative-variable","chapter":"6 Summarizing Quantities","heading":"6.2.3 The Mode of a Quantitative Variable","text":"One less common measure center quantitative variable’s distribution frequently observed value, referred mode. measure appropriate discrete variables, quantitative categorical. find mode, usually tabulate data, sort counts numbers observations.mode just common Age observed data.Note use three different “verbs” function - explanation strategy, visit Grolemund Wickham.20 group_by function useful. converts nh_750 data frame new grouped tibble operations performed groups. , means groups data Age counting observations, sorting groups (Ages) frequencies.alternative, modeest package’s mfv function calculates sample mode (frequent value).21","code":"\nnh_750 %>%\n    group_by(Age) %>%\n    summarise(count = n()) %>%\n    arrange(desc(count)) # A tibble: 44 x 2\n     Age count\n   <int> <int>\n 1    32    28\n 2    36    26\n 3    50    26\n 4    30    24\n 5    33    24\n 6    24    23\n 7    21    22\n 8    22    22\n 9    23    22\n10    28    20\n# ... with 34 more rows"},{"path":"summarizing_quantities.html","id":"measuring-the-spread-of-a-distribution","chapter":"6 Summarizing Quantities","heading":"6.3 Measuring the Spread of a Distribution","text":"Statistics variation, spread dispersion important fundamental concept statistics. Measures spread like inter-quartile range range (maximum - minimum) can help us understand compare data sets. values data close center, spread small. many values data scattered far away center, spread large.","code":""},{"path":"summarizing_quantities.html","id":"rangeandiqr","chapter":"6 Summarizing Quantities","heading":"6.3.1 The Range and the Interquartile Range (IQR)","text":"range quantitative variable sometimes interpreted difference maximum minimum, even though R presents actual minimum maximum values ask range…, variable missing values, can use…interesting useful statistic inter-quartile range, IQR, range middle half distribution, calculated subtracting 25th percentile value 75th percentile value.can calculate range IQR nicely summary information quantiles, course:","code":"\nnh_750 %>% \n    select(Age) %>% \n    range()[1] 21 64\nnh_750 %>% \n    select(BMI) %>% \n    range(., na.rm=TRUE)[1] 16.7 80.6\nnh_750 %>%\n    summarise(IQR(Age), quantile(Age, 0.25), quantile(Age, 0.75))# A tibble: 1 x 3\n  `IQR(Age)` `quantile(Age, 0.25)` `quantile(Age, 0.75)`\n       <dbl>                 <dbl>                 <dbl>\n1         21                    30                    51\nnh_750 %>%\n    select(Age, BMI, SBP, DBP, Pulse) %>%\n    summary()      Age             BMI             SBP       \n Min.   :21.00   Min.   :16.70   Min.   : 83.0  \n 1st Qu.:30.00   1st Qu.:24.20   1st Qu.:108.0  \n Median :40.00   Median :27.90   Median :118.0  \n Mean   :40.82   Mean   :29.08   Mean   :118.8  \n 3rd Qu.:51.00   3rd Qu.:32.10   3rd Qu.:127.0  \n Max.   :64.00   Max.   :80.60   Max.   :209.0  \n                 NA's   :5       NA's   :33     \n      DBP             Pulse       \n Min.   :  0.00   Min.   : 40.00  \n 1st Qu.: 66.00   1st Qu.: 66.00  \n Median : 73.00   Median : 72.00  \n Mean   : 72.69   Mean   : 73.53  \n 3rd Qu.: 80.00   3rd Qu.: 80.00  \n Max.   :108.00   Max.   :124.00  \n NA's   :33       NA's   :32      "},{"path":"summarizing_quantities.html","id":"the-variance-and-the-standard-deviation","chapter":"6 Summarizing Quantities","heading":"6.3.2 The Variance and the Standard Deviation","text":"IQR always reasonable summary spread, just median always reasonable summary center distribution. Yet, people inclined summarize batch data using two numbers: mean standard deviation. really sensible thing willing assume data follow Normal distribution: bell-shaped, symmetric distribution without substantial outliers.data (even approximately) follow Normal distribution. Summarizing median quartiles (25th 75th percentiles) much robust, explaining R’s emphasis .","code":""},{"path":"summarizing_quantities.html","id":"obtaining-the-variance-and-standard-deviation-in-r","chapter":"6 Summarizing Quantities","heading":"6.3.3 Obtaining the Variance and Standard Deviation in R","text":"variances quantitative variables nh_750 data. Note need include na.rm = TRUE deal missing values variables.standard deviations variables.","code":"\nnh_750 %>%\n    select(Age, BMI, SBP, DBP, Pulse) %>%\n    summarise_all(var, na.rm = TRUE)# A tibble: 1 x 5\n    Age   BMI   SBP   DBP Pulse\n  <dbl> <dbl> <dbl> <dbl> <dbl>\n1  157.  52.4  229.  128.  136.\nnh_750 %>%\n    select(Age, BMI, SBP, DBP, Pulse) %>%\n    summarise_all(sd, na.rm = TRUE)# A tibble: 1 x 5\n    Age   BMI   SBP   DBP Pulse\n  <dbl> <dbl> <dbl> <dbl> <dbl>\n1  12.5  7.24  15.1  11.3  11.6"},{"path":"summarizing_quantities.html","id":"defining-the-variance-and-standard-deviation","chapter":"6 Summarizing Quantities","heading":"6.3.4 Defining the Variance and Standard Deviation","text":"Bock, Velleman, De Veaux22 lots useful thoughts , lightly edited .thinking spread, might consider far data value mean. difference called deviation. just average deviations, positive negative differences always cancel , leaving average deviation zero, ’s helpful. Instead, square deviation obtain non-negative values, emphasize larger differences. add squared deviations find mean (almost), yields variance.\\[\n\\mbox{Variance} = s^2 = \\frac{\\Sigma (y - \\bar{y})^2}{n-1}\n\\]almost? mean squared deviations divided sum \\(n\\), instead divide \\(n-1\\) produces estimate true (population) variance unbiased23. ’re looking intuitive explanation, Stack Exchange link awaits attention.return original units measurement, take square root \\(s^2\\), instead work \\(s\\), standard deviation, also abbreviated SD.\\[\n\\mbox{Standard Deviation} = s = \\sqrt{\\frac{\\Sigma (y - \\bar{y})^2}{n-1}}\n\\]","code":""},{"path":"summarizing_quantities.html","id":"interpreting-the-sd-when-the-data-are-normally-distributed","chapter":"6 Summarizing Quantities","heading":"6.3.5 Interpreting the SD when the data are Normally distributed","text":"set measurements follow Normal distribution, interval:Mean \\(\\pm\\) Standard Deviation contains approximately 68% measurements;Mean \\(\\pm\\) 2(Standard Deviation) contains approximately 95% measurements;Mean \\(\\pm\\) 3(Standard Deviation) contains approximately (99.7%) measurements.often refer population process mean distribution \\(\\mu\\) standard deviation \\(\\sigma\\), leading Figure .\n(#fig:c6_Emp_Rule)Normal Distribution Empirical Rule\ndata approximately Normal distribution, Empirical Rule less helpful.","code":""},{"path":"summarizing_quantities.html","id":"chebyshevs-inequality-one-interpretation-of-the-standard-deviation","chapter":"6 Summarizing Quantities","heading":"6.3.6 Chebyshev’s Inequality: One Interpretation of the Standard Deviation","text":"Chebyshev’s Inequality tells us distribution, regardless relationship Normal distribution, 1/k2 distribution’s values can lie k standard deviations mean. implies, instance, distribution, least 75% values must lie within two standard deviations mean, least 89% must lie within three standard deviations mean., data sets follow Normal distribution. ’ll return notion soon. first, let’s try draw pictures let us get better understanding distribution data.","code":""},{"path":"summarizing_quantities.html","id":"measuring-the-shape-of-a-distribution","chapter":"6 Summarizing Quantities","heading":"6.4 Measuring the Shape of a Distribution","text":"considering shape distribution, one often interested three key points.number modes distribution, always assess plotting data.skewness, symmetry present, typically assess looking plot distribution data, required , summarize non-parametric measure skewness.kurtosis, heavy-tailedness (outlier-proneness) present, usually comparison Normal distribution. , something nearly inevitably assess graphically, measures.Normal distribution single mode, symmetric , naturally, neither heavy-tailed light-tailed compared Normal distribution (call mesokurtic).","code":""},{"path":"summarizing_quantities.html","id":"multimodal-vs.-unimodal-distributions","chapter":"6 Summarizing Quantities","heading":"6.4.1 Multimodal vs. Unimodal distributions","text":"unimodal distribution, level, straightforward. distribution single mode, “peak” distribution. distribution may skewed symmetric, light-tailed heavy-tailed. usually describe multimodal distributions like two right , multiple local maxima, even though just single global maximum peak.\n(#fig:c6_modality-fig)Unimodal Multimodal Sketches\nTruly multimodal distributions usually described way terms shape. unimodal distributions, skewness kurtosis become useful ideas.","code":""},{"path":"summarizing_quantities.html","id":"skew","chapter":"6 Summarizing Quantities","heading":"6.4.2 Skew","text":"Whether distribution approximately symmetric important consideration describing shape. Graphical assessments always useful setting, particularly unimodal data. favorite measure skew, skewness data single mode, :\\[\nskew_1 = \\frac{\\mbox{mean} - \\mbox{median}}{\\mbox{standard deviation}}\n\\]Symmetric distributions generally show values \\(skew_1\\) near zero. distribution actually symmetric, mean equal median.Distributions \\(skew_1\\) values 0.2 absolute value generally indicate meaningful skew.Positive skew (mean > median data unimodal) also referred right skew.Negative skew (mean < median data unimodal) referred left skew.\n(#fig:c6_negandposskew-fig)Negative (Left) Skew Positive (Right) Skew\n","code":""},{"path":"summarizing_quantities.html","id":"kurtosis","chapter":"6 Summarizing Quantities","heading":"6.4.3 Kurtosis","text":"unimodal distribution symmetric, often interested behavior tails distribution, compared Normal distribution mean standard deviation. High values kurtosis measures (several) indicate data extreme outliers, heavy-tailed.mesokurtic distribution similar tail behavior expect Normal distribution.leptokurtic distribution thinner, slender distribution, heavier tails ’d expect Normal distribution. One example t distribution.platykurtic distribution broader, flatter distribution, thinner tails ’d expect Normal distribution. One example uniform distribution.Graphical tools cases best way identify issues related kurtosis.","code":"\nset.seed(431)\nsims_kurt <- tibble(meso = rnorm(n = 300, mean = 0, sd = 1),\n                    lepto = rt(n = 300, df = 4),\n                    platy = runif(n = 300, min = -2, max = 2))\n\np1 <- ggplot(sims_kurt, aes(x = meso)) +\n  geom_histogram(aes(y = stat(density)), \n                 bins = 25, fill = \"royalblue\", col = \"white\") +\n  stat_function(fun = dnorm, \n                args = list(mean = mean(sims_kurt$meso), \n                            sd = sd(sims_kurt$meso)),\n                col = \"red\") +\n  labs(title = \"Normal (mesokurtic)\")\n\np1a <- ggplot(sims_kurt, aes(x = meso, y = \"\")) +\n  geom_violin() +\n  geom_boxplot(fill = \"royalblue\", outlier.color = \"royalblue\", width = 0.3) +\n  labs(y = \"\", x = \"Normal (mesokurtic)\")\n\np2 <- ggplot(sims_kurt, aes(x = lepto)) +\n  geom_histogram(aes(y = stat(density)), \n                 bins = 25, fill = \"tomato\", col = \"white\") +\n  stat_function(fun = dnorm, \n                args = list(mean = mean(sims_kurt$lepto), \n                            sd = sd(sims_kurt$lepto)),\n                col = \"royalblue\") +\n  labs(title = \"t (leptokurtic)\")\n\np2a <- ggplot(sims_kurt, aes(x = lepto, y = \"\")) +\n  geom_violin() +\n  geom_boxplot(fill = \"tomato\", outlier.color = \"tomato\", width = 0.3) +\n  labs(y = \"\", x = \"t (slender with heavy tails)\")\n\np3 <- ggplot(sims_kurt, aes(x = platy)) +\n  geom_histogram(aes(y = stat(density)), \n                 bins = 25, fill = \"yellow\", col = \"black\") +\n  stat_function(fun = dnorm, \n                args = list(mean = mean(sims_kurt$platy), \n                            sd = sd(sims_kurt$platy)),\n                col = \"royalblue\", lwd = 1.5) +\n  xlim(-3, 3) +\n  labs(title = \"Uniform (platykurtic)\")\n\np3a <- ggplot(sims_kurt, aes(x = platy, y = \"\")) +\n  geom_violin() +\n  geom_boxplot(fill = \"yellow\", width = 0.3) + \n  xlim(-3, 3) +\n  labs(y = \"\", x = \"Uniform (broad with thin tails)\")\n\n\n(p1 + p2 + p3) / (p1a + p2a + p3a) + \n  plot_layout(heights = c(3, 1))"},{"path":"summarizing_quantities.html","id":"numerical-summaries-for-quantitative-variables","chapter":"6 Summarizing Quantities","heading":"6.5 Numerical Summaries for Quantitative Variables","text":"","code":""},{"path":"summarizing_quantities.html","id":"favstats-in-the-mosaic-package","chapter":"6 Summarizing Quantities","heading":"6.5.1 favstats in the mosaic package","text":"favstats function adds standard deviation, counts overall missing observations usual summary continuous variable. Let’s look systolic blood pressure, haven’t yet., course, duplicate results several summarise() pieces…somewhat unusual structure favstats (complete easy forget ~) actually helpful. allows look interesting grouping approaches, like :course, accomplish comparison dplyr commands, , favstats approach much offer.","code":"\nmosaic::favstats(~ SBP, data = nh_750) min  Q1 median  Q3 max     mean       sd   n missing\n  83 108    118 127 209 118.7908 15.14329 717      33\nnh_750 %>%\n    filter(complete.cases(SBP)) %>%\n    summarise(min = min(SBP), Q1 = quantile(SBP, 0.25), \n              median = median(SBP), Q3 = quantile(SBP, 0.75), \n              max = max(SBP),  mean = mean(SBP), \n              sd = sd(SBP), n = n(), miss = sum(is.na(SBP)))# A tibble: 1 x 9\n    min    Q1 median    Q3   max  mean    sd     n  miss\n  <int> <dbl>  <int> <dbl> <int> <dbl> <dbl> <int> <int>\n1    83   108    118   127   209  119.  15.1   717     0\nmosaic::favstats(SBP ~ Education, data = nh_750)       Education min     Q1 median     Q3 max     mean\n1      8th Grade  96 110.25  119.5 129.75 167 122.4565\n2 9 - 11th Grade  85 107.75  116.0 127.00 191 118.8026\n3    High School  84 111.50  120.5 129.00 209 121.0882\n4   Some College  85 108.00  117.0 126.00 186 118.6293\n5   College Grad  83 107.00  117.0 125.00 171 116.8326\n        sd   n missing\n1 16.34993  46       4\n2 15.79453  76       0\n3 16.52853 136       7\n4 14.32736 232       9\n5 14.41202 227      13\nnh_750 %>%\n    filter(complete.cases(SBP, Education)) %>%\n    group_by(Education) %>%\n    summarise(min = min(SBP), Q1 = quantile(SBP, 0.25), \n              median = median(SBP), Q3 = quantile(SBP, 0.75), \n              max = max(SBP), mean = mean(SBP), \n              sd = sd(SBP), n = n(), miss = sum(is.na(SBP)))# A tibble: 5 x 10\n  Education   min    Q1 median    Q3   max  mean    sd     n\n  <fct>     <int> <dbl>  <dbl> <dbl> <int> <dbl> <dbl> <int>\n1 8th Grade    96  110.   120.  130.   167  122.  16.3    46\n2 9 - 11th~    85  108.   116   127    191  119.  15.8    76\n3 High Sch~    84  112.   120.  129    209  121.  16.5   136\n4 Some Col~    85  108    117   126    186  119.  14.3   232\n5 College ~    83  107    117   125    171  117.  14.4   227\n# ... with 1 more variable: miss <int>"},{"path":"summarizing_quantities.html","id":"describe-in-the-psych-package","chapter":"6 Summarizing Quantities","heading":"6.5.2 describe in the psych package","text":"psych package detailed list numerical summaries quantitative variables lets us look group observations .additional statistics presented :trimmed = trimmed mean (default function, removes top bottom 10% data, computes mean remaining values - middle 80% full data set.)mad = median absolute deviation (median), can used manner similar standard deviation IQR measure spread.\ndata \\(Y_1, Y_2, ..., Y_n\\), mad defined \\(median(|Y_i - median(Y_i)|)\\).\nfind mad set numbers, find median, subtract median value find absolute value difference, find median absolute differences.\nnon-normal data skewed shape tails well approximated Normal, mad likely better (robust) estimate spread standard deviation.\ndata \\(Y_1, Y_2, ..., Y_n\\), mad defined \\(median(|Y_i - median(Y_i)|)\\).find mad set numbers, find median, subtract median value find absolute value difference, find median absolute differences.non-normal data skewed shape tails well approximated Normal, mad likely better (robust) estimate spread standard deviation.measure skew, refers much asymmetry present shape distribution. measure nonparametric skew measure usually prefer. [Wikipedia page skewness][https://en.wikipedia.org/wiki/Skewness] detailed.measure excess kurtosis, refers outlier-prone, heavy-tailed shape distribution , compared Normal distribution.se = standard error sample mean, equal sample sd divided square root sample size.","code":"\npsych::describe(nh_750 %>% select(Age, BMI, SBP, DBP, Pulse))      vars   n   mean    sd median trimmed   mad  min   max\nAge      1 750  40.82 12.54   40.0   40.53 14.83 21.0  64.0\nBMI      2 745  29.08  7.24   27.9   28.31  5.93 16.7  80.6\nSBP      3 717 118.79 15.14  118.0  117.88 13.34 83.0 209.0\nDBP      4 717  72.69 11.34   73.0   72.65 10.38  0.0 108.0\nPulse    5 718  73.53 11.65   72.0   73.11 11.86 40.0 124.0\n      range  skew kurtosis   se\nAge    43.0  0.16    -1.15 0.46\nBMI    63.9  1.72     6.16 0.27\nSBP   126.0  0.96     3.10 0.57\nDBP   108.0 -0.28     2.59 0.42\nPulse  84.0  0.48     0.73 0.43"},{"path":"summarizing_quantities.html","id":"the-hmisc-packages-version-of-describe","chapter":"6 Summarizing Quantities","heading":"6.5.3 The Hmisc package’s version of describe","text":"Hmisc package’s version describe distribution data presents three new ideas, addition comprehensive list quartiles (5th, 10th, 25th, 50th, 75th, 90th 95th shown) lowest highest observations. :distinct - number different values observed data.Info - measure “continuous” variable , related many “ties” data, Info taking higher value (closer maximum one) data continuous.Gmd - Gini mean difference - robust measure spread calculated mean absolute difference pairs observations. Larger values Gmd indicate spread-distributions. (Gini pronounced either “Genie” “Ginny.”)","code":"\nHmisc::describe(nh_750 %>% \n                  select(Age, BMI, SBP, DBP, Pulse))nh_750 %>% select(Age, BMI, SBP, DBP, Pulse) \n\n 5  Variables      750  Observations\n------------------------------------------------------------\nAge \n       n  missing distinct     Info     Mean      Gmd \n     750        0       44    0.999    40.82    14.46 \n     .05      .10      .25      .50      .75      .90 \n      22       24       30       40       51       59 \n     .95 \n      62 \n\nlowest : 21 22 23 24 25, highest: 60 61 62 63 64\n------------------------------------------------------------\nBMI \n       n  missing distinct     Info     Mean      Gmd \n     745        5      250        1    29.08    7.538 \n     .05      .10      .25      .50      .75      .90 \n   20.22    21.30    24.20    27.90    32.10    37.60 \n     .95 \n   41.28 \n\nlowest : 16.7 17.6 17.8 17.9 18.0, highest: 59.1 62.8 63.3 69.0 80.6\n------------------------------------------------------------\nSBP \n       n  missing distinct     Info     Mean      Gmd \n     717       33       81    0.999    118.8    16.36 \n     .05      .10      .25      .50      .75      .90 \n    98.0    102.0    108.0    118.0    127.0    137.0 \n     .95 \n   144.2 \n\nlowest :  83  84  85  86  89, highest: 171 179 186 191 209\n------------------------------------------------------------\nDBP \n       n  missing distinct     Info     Mean      Gmd \n     717       33       66    0.999    72.69    12.43 \n     .05      .10      .25      .50      .75      .90 \n      55       59       66       73       80       86 \n     .95 \n      91 \n\nlowest :   0  25  41  42  44, highest: 104 105 106 107 108\n------------------------------------------------------------\nPulse \n       n  missing distinct     Info     Mean      Gmd \n     718       32       37    0.997    73.53    12.95 \n     .05      .10      .25      .50      .75      .90 \n      56       60       66       72       80       88 \n     .95 \n      94 \n\nlowest :  40  44  46  48  50, highest: 108 112 114 118 124\n------------------------------------------------------------"},{"path":"summarizing_quantities.html","id":"other-options","chapter":"6 Summarizing Quantities","heading":"6.5.4 Other options","text":"package summarytools function called dfSummary like Dominic Comtois also published Recommendations Using summarytools R Markdown. Note isn’t really Word documents.DataExplorer can used automated exploratory data analyses (people also like skimr) visdat, well.df_stats function available mosaic package loaded allows run favstats multiple outcome variables simultaneously.","code":""},{"path":"summarizing-categories.html","id":"summarizing-categories","chapter":"7 Summarizing Categories","heading":"7 Summarizing Categories","text":"demonstrate key ideas Chapter, consider sample 750 adults ages 21-64 NHANES 2011-12 includes missing values. ’ll load nh_750 data frame information nh_adult750.Rds file created Section 4.2.Summarizing categorical variables numerically mostly building tables, calculating percentages proportions. ’ll save discussion modeling categorical data later. Recall nh_750 data set built Section 4.2 following categorical variables. number levels indicates number possible categories categorical variable.","code":"\nnh_750 <- read_rds(\"data/nh_adult750.Rds\")"},{"path":"summarizing-categories.html","id":"the-summary-function-for-categorical-data","chapter":"7 Summarizing Categories","heading":"7.1 The summary function for Categorical data","text":"R recognizes variable categorical, stores factor. variables get special treatment summary function, particular table available values (long aren’t many.)","code":"\nnh_750 %>%\n  select(Sex, Race, Education, PhysActive, Smoke100, \n         SleepTrouble, HealthGen, MaritalStatus) %>%\n  summary()     Sex            Race              Education  \n female:388   Asian   : 70   8th Grade     : 50  \n male  :362   Black   :128   9 - 11th Grade: 76  \n              Hispanic: 63   High School   :143  \n              Mexican : 80   Some College  :241  \n              White   :393   College Grad  :240  \n              Other   : 16                       \n PhysActive Smoke100  SleepTrouble     HealthGen  \n No :326    No :453   No :555      Excellent: 84  \n Yes:424    Yes:297   Yes:195      Vgood    :197  \n                                   Good     :252  \n                                   Fair     :104  \n                                   Poor     : 14  \n                                   NA's     : 99  \n      MaritalStatus\n Divorced    : 78  \n LivePartner : 70  \n Married     :388  \n NeverMarried:179  \n Separated   : 19  \n Widowed     : 16  "},{"path":"summarizing-categories.html","id":"tables-to-describe-one-categorical-variable","chapter":"7 Summarizing Categories","heading":"7.2 Tables to describe One Categorical Variable","text":"Suppose build table (using tabyl function janitor package) describe HealthGen distribution.Note missing (<NA>) values included valid_percent calculation, percent calculation. Note also use percentage formatting.want add total count, sometimes called marginal total?marital status, missing data sample?","code":"\nnh_750 %>%\n    tabyl(HealthGen) %>%\n    adorn_pct_formatting() HealthGen   n percent valid_percent\n Excellent  84   11.2%         12.9%\n     Vgood 197   26.3%         30.3%\n      Good 252   33.6%         38.7%\n      Fair 104   13.9%         16.0%\n      Poor  14    1.9%          2.2%\n      <NA>  99   13.2%             -\nnh_750 %>%\n    tabyl(HealthGen) %>%\n    adorn_totals() %>%\n    adorn_pct_formatting() HealthGen   n percent valid_percent\n Excellent  84   11.2%         12.9%\n     Vgood 197   26.3%         30.3%\n      Good 252   33.6%         38.7%\n      Fair 104   13.9%         16.0%\n      Poor  14    1.9%          2.2%\n      <NA>  99   13.2%             -\n     Total 750  100.0%        100.0%\nnh_750 %>%\n    tabyl(MaritalStatus) %>%\n    adorn_totals() %>%\n    adorn_pct_formatting() MaritalStatus   n percent\n      Divorced  78   10.4%\n   LivePartner  70    9.3%\n       Married 388   51.7%\n  NeverMarried 179   23.9%\n     Separated  19    2.5%\n       Widowed  16    2.1%\n         Total 750  100.0%"},{"path":"summarizing-categories.html","id":"constructing-tables-well","chapter":"7 Summarizing Categories","heading":"7.3 Constructing Tables Well","text":"prolific Howard Wainer responsible many interesting books visualization related issues, including Howard Wainer24 Howard Wainer.25 rules come Chapter 10 Howard Wainer.26Order rows columns way makes sense.Round, lot!different important","code":""},{"path":"summarizing-categories.html","id":"alabama-first","chapter":"7 Summarizing Categories","heading":"7.3.1 Alabama First!","text":"Tables useful ?2013 Percent Students grades 9-12 obeseor …rare event Alabama first best choice.","code":""},{"path":"summarizing-categories.html","id":"all-is-different-and-important","chapter":"7 Summarizing Categories","heading":"7.3.2 ALL is different and important","text":"Summaries rows columns provide measure typical usual. Sometimes sum helpful, times, consider presenting median summary. category, Wainer27 suggests, visually different individual entries set spatially apart.whole, ’s far easier fall good graph R (least ggplot2 skills) produce good table.","code":""},{"path":"summarizing-categories.html","id":"the-mode-of-a-categorical-variable","chapter":"7 Summarizing Categories","heading":"7.4 The Mode of a Categorical Variable","text":"common measure applied categorical variable identify mode, frequently observed value. find mode variables lots categories (summary may sufficient), usually tabulate data, sort counts numbers observations, discrete quantitative variables.","code":"\nnh_750 %>%\n    group_by(HealthGen) %>%\n    summarise(count = n()) %>%\n    arrange(desc(count)) # A tibble: 6 x 2\n  HealthGen count\n  <fct>     <int>\n1 Good        252\n2 Vgood       197\n3 Fair        104\n4 <NA>         99\n5 Excellent    84\n6 Poor         14"},{"path":"summarizing-categories.html","id":"describe-in-the-hmisc-package","chapter":"7 Summarizing Categories","heading":"7.5 describe in the Hmisc package","text":"","code":"\nHmisc::describe(nh_750 %>% \n                    select(Sex, Race, Education, PhysActive, \n                           Smoke100, SleepTrouble, \n                           HealthGen, MaritalStatus))nh_750 %>% select(Sex, Race, Education, PhysActive, Smoke100, SleepTrouble, HealthGen, MaritalStatus) \n\n 8  Variables      750  Observations\n------------------------------------------------------------\nSex \n       n  missing distinct \n     750        0        2 \n                        \nValue      female   male\nFrequency     388    362\nProportion  0.517  0.483\n------------------------------------------------------------\nRace \n       n  missing distinct \n     750        0        6 \n\nlowest : Asian    Black    Hispanic Mexican  White   \nhighest: Black    Hispanic Mexican  White    Other   \n                                                       \nValue         Asian    Black Hispanic  Mexican    White\nFrequency        70      128       63       80      393\nProportion    0.093    0.171    0.084    0.107    0.524\n                   \nValue         Other\nFrequency        16\nProportion    0.021\n------------------------------------------------------------\nEducation \n       n  missing distinct \n     750        0        5 \n\nlowest : 8th Grade      9 - 11th Grade High School    Some College   College Grad  \nhighest: 8th Grade      9 - 11th Grade High School    Some College   College Grad  \n                                                       \nValue           8th Grade 9 - 11th Grade    High School\nFrequency              50             76            143\nProportion          0.067          0.101          0.191\n                                        \nValue        Some College   College Grad\nFrequency             241            240\nProportion          0.321          0.320\n------------------------------------------------------------\nPhysActive \n       n  missing distinct \n     750        0        2 \n                      \nValue         No   Yes\nFrequency    326   424\nProportion 0.435 0.565\n------------------------------------------------------------\nSmoke100 \n       n  missing distinct \n     750        0        2 \n                      \nValue         No   Yes\nFrequency    453   297\nProportion 0.604 0.396\n------------------------------------------------------------\nSleepTrouble \n       n  missing distinct \n     750        0        2 \n                    \nValue        No  Yes\nFrequency   555  195\nProportion 0.74 0.26\n------------------------------------------------------------\nHealthGen \n       n  missing distinct \n     651       99        5 \n\nlowest : Excellent Vgood     Good      Fair      Poor     \nhighest: Excellent Vgood     Good      Fair      Poor     \n                                                  \nValue      Excellent     Vgood      Good      Fair\nFrequency         84       197       252       104\nProportion     0.129     0.303     0.387     0.160\n                    \nValue           Poor\nFrequency         14\nProportion     0.022\n------------------------------------------------------------\nMaritalStatus \n       n  missing distinct \n     750        0        6 \n\nlowest : Divorced     LivePartner  Married      NeverMarried Separated   \nhighest: LivePartner  Married      NeverMarried Separated    Widowed     \n                                                 \nValue          Divorced  LivePartner      Married\nFrequency            78           70          388\nProportion        0.104        0.093        0.517\n                                                 \nValue      NeverMarried    Separated      Widowed\nFrequency           179           19           16\nProportion        0.239        0.025        0.021\n------------------------------------------------------------"},{"path":"summarizing-categories.html","id":"cross-tabulations-of-two-variables","chapter":"7 Summarizing Categories","heading":"7.6 Cross-Tabulations of Two Variables","text":"common us want describe association one categorical variable another. instance, relationship Education SleepTrouble data?Note use adorn_totals get marginal counts, specify want row column totals. can add title columns …Often, ’ll want show percentages cross-tabulation like . get row percentages can directly see probability SleepTrouble = Yes level Education, can use:want compare distribution Education two levels SleepTrouble column percentages, can use following…want overall percentages cells table, total across combinations Education SleepTrouble 100%, can use:Another common approach include counts percentages cross-tabulation. Let’s look breakdown HealthGen MaritalStatus.wanted ignore missing HealthGen values? often, filter complete observations.working tabyls, see vignette janitor package. ’ll find complete list adorn functions, example.’s another approach, look cross-classification Race HealthGen:","code":"\nnh_750 %>%\n    tabyl(Education, SleepTrouble) %>%\n    adorn_totals(where = c(\"row\", \"col\"))       Education  No Yes Total\n      8th Grade  40  10    50\n 9 - 11th Grade  52  24    76\n    High School 102  41   143\n   Some College 173  68   241\n   College Grad 188  52   240\n          Total 555 195   750\nnh_750 %>%\n    tabyl(Education, SleepTrouble) %>%\n    adorn_totals(where = c(\"row\", \"col\")) %>%\n    adorn_title(placement = \"combined\") Education/SleepTrouble  No Yes Total\n              8th Grade  40  10    50\n         9 - 11th Grade  52  24    76\n            High School 102  41   143\n           Some College 173  68   241\n           College Grad 188  52   240\n                  Total 555 195   750\nnh_750 %>%\n    tabyl(Education, SleepTrouble) %>%\n    adorn_totals(where = \"row\") %>%\n    adorn_percentages(denominator = \"row\") %>%\n    adorn_pct_formatting() %>%\n    adorn_title(placement = \"combined\") Education/SleepTrouble    No   Yes\n              8th Grade 80.0% 20.0%\n         9 - 11th Grade 68.4% 31.6%\n            High School 71.3% 28.7%\n           Some College 71.8% 28.2%\n           College Grad 78.3% 21.7%\n                  Total 74.0% 26.0%\nnh_750 %>%\n    tabyl(Education, SleepTrouble) %>%\n    adorn_totals(where = \"col\") %>%\n    adorn_percentages(denominator = \"col\") %>%\n    adorn_pct_formatting() %>%\n    adorn_title(placement = \"combined\")  Education/SleepTrouble    No   Yes Total\n              8th Grade  7.2%  5.1%  6.7%\n         9 - 11th Grade  9.4% 12.3% 10.1%\n            High School 18.4% 21.0% 19.1%\n           Some College 31.2% 34.9% 32.1%\n           College Grad 33.9% 26.7% 32.0%\nnh_750 %>%\n    tabyl(Education, SleepTrouble) %>%\n    adorn_totals(where = c(\"row\", \"col\")) %>%\n    adorn_percentages(denominator = \"all\") %>%\n    adorn_pct_formatting() %>%\n    adorn_title(placement = \"combined\")  Education/SleepTrouble    No   Yes  Total\n              8th Grade  5.3%  1.3%   6.7%\n         9 - 11th Grade  6.9%  3.2%  10.1%\n            High School 13.6%  5.5%  19.1%\n           Some College 23.1%  9.1%  32.1%\n           College Grad 25.1%  6.9%  32.0%\n                  Total 74.0% 26.0% 100.0%\nnh_750 %>%\n    tabyl(MaritalStatus, HealthGen) %>%\n    adorn_totals(where = c(\"row\")) %>%\n    adorn_percentages(denominator = \"row\") %>%\n    adorn_pct_formatting() %>%\n    adorn_ns(position = \"front\") %>%\n    adorn_title(placement = \"combined\") %>%\n    knitr::kable()\nnh_750 %>%\n    filter(complete.cases(MaritalStatus, HealthGen)) %>%\n    tabyl(MaritalStatus, HealthGen) %>%\n    adorn_totals(where = c(\"row\")) %>%\n    adorn_percentages(denominator = \"row\") %>%\n    adorn_pct_formatting() %>%\n    adorn_ns(position = \"front\") %>%\n    adorn_title(placement = \"combined\") MaritalStatus/HealthGen  Excellent       Vgood        Good\n                Divorced  7 (10.1%)  19 (27.5%)  29 (42.0%)\n             LivePartner  4  (6.1%)  19 (28.8%)  25 (37.9%)\n                 Married 46 (14.2%) 101 (31.2%) 130 (40.1%)\n            NeverMarried 25 (15.6%)  52 (32.5%)  56 (35.0%)\n               Separated  2 (11.8%)   3 (17.6%)   4 (23.5%)\n                 Widowed  0  (0.0%)   3 (20.0%)   8 (53.3%)\n                   Total 84 (12.9%) 197 (30.3%) 252 (38.7%)\n        Fair       Poor\n  11 (15.9%)  3  (4.3%)\n  18 (27.3%)  0  (0.0%)\n  41 (12.7%)  6  (1.9%)\n  24 (15.0%)  3  (1.9%)\n   8 (47.1%)  0  (0.0%)\n   2 (13.3%)  2 (13.3%)\n 104 (16.0%) 14  (2.2%)\nxtabs(~ Race + HealthGen, data = nh_750)          HealthGen\nRace       Excellent Vgood Good Fair Poor\n  Asian           10    17   24    6    1\n  Black           15    28   40   24    4\n  Hispanic         4     9   24   13    2\n  Mexican          6    12   25   21    2\n  White           48   128  131   37    5\n  Other            1     3    8    3    0"},{"path":"summarizing-categories.html","id":"cross-classifying-three-categorical-variables","chapter":"7 Summarizing Categories","heading":"7.7 Cross-Classifying Three Categorical Variables","text":"Suppose interested Smoke100 relationship PhysActive SleepTrouble.result tabyl Smoke100 (rows) PhysActive (columns), split list SleepTrouble.several alternative approaches , although expect us stick tabyl work 431. alternatives include use xtabs function:can also build flat version table, follows:can dplyr functions table() function, well, example…","code":"\nnh_750 %>%\n    tabyl(Smoke100, PhysActive, SleepTrouble) %>%\n    adorn_title(placement = \"top\")$No\n          PhysActive    \n Smoke100         No Yes\n       No        137 219\n      Yes         93 106\n\n$Yes\n          PhysActive    \n Smoke100         No Yes\n       No         41  56\n      Yes         55  43\nxtabs(~ Smoke100 + PhysActive + SleepTrouble, data = nh_750), , SleepTrouble = No\n\n        PhysActive\nSmoke100  No Yes\n     No  137 219\n     Yes  93 106\n\n, , SleepTrouble = Yes\n\n        PhysActive\nSmoke100  No Yes\n     No   41  56\n     Yes  55  43\nftable(Smoke100 ~ PhysActive + SleepTrouble, data = nh_750)                        Smoke100  No Yes\nPhysActive SleepTrouble                 \nNo         No                    137  93\n           Yes                    41  55\nYes        No                    219 106\n           Yes                    56  43\nnh_750 %>%\n    select(Smoke100, PhysActive, SleepTrouble) %>%\n    table() , , SleepTrouble = No\n\n        PhysActive\nSmoke100  No Yes\n     No  137 219\n     Yes  93 106\n\n, , SleepTrouble = Yes\n\n        PhysActive\nSmoke100  No Yes\n     No   41  56\n     Yes  55  43"},{"path":"summarizing-categories.html","id":"gaining-control-over-tables-in-r-the-gt-package","chapter":"7 Summarizing Categories","heading":"7.8 Gaining Control over Tables in R: the gt package","text":"gt package, anyone can make wonderful-looking tables using R programming language. gt package allows start tibble data frame, use make detailed tables look professional, includes tools enable include titles subtitles, sorts labels, well footnotes source notes.’s fairly simple example cross-tabulation part nh_750 data built using tools gt package.gt package usage described detail https://gt.rstudio.com/.","code":"\nlibrary(gt)\n\ntemp_tbl <- nh_750 %>% filter(complete.cases(PhysActive, HealthGen)) %>%\n  tabyl(PhysActive, HealthGen) %>%\n  tibble() \n\ngt(temp_tbl) %>%\n  tab_header(title = md(\"**Cross-Tabulation from nh_750**\"),\n             subtitle = md(\"Physical Activity vs. Overall Health\"))"},{"path":"miss.html","id":"miss","chapter":"8 Missing Data and Single Imputation","heading":"8 Missing Data and Single Imputation","text":"Almost serious statistical analyses deal missing data. Data values missing indicated R, R, symbol NA.’ll focus tools naniar simputation packages work.","code":""},{"path":"miss.html","id":"a-simulated-example-with-15-subjects","chapter":"8 Missing Data and Single Imputation","heading":"8.1 A Simulated Example with 15 subjects","text":"following tiny data set called sbp_example, four variables set 15 subjects. addition subject id, :treatment subject received (, B C treatments),indicator (1 = yes, 0 = ) whether subject diabetes,subject’s systolic blood pressure baselinethe subject’s systolic blood pressure application treatment","code":"\n# create some temporary variables\nsubject <- 101:115\nx1 <- c(\"A\", \"B\", \"C\", \"A\", \"C\", \"A\", \"A\", NA, \"B\", \"C\", \"A\", \"B\", \"C\", \"A\", \"B\")\nx2 <- c(1, 0, 0, 1, NA, 1, 0, 1, NA, 1, 0, 0, 1, 1, NA)\nx3 <- c(120, 145, 150, NA, 155, NA, 135, NA, 115, 170, 150, 145, 140, 160, 135)\nx4 <- c(105, 135, 150, 120, 135, 115, 160, 150, 130, 155, 140, 140, 150, 135, 120)\n\nsbp_example <- \n  tibble(subject, treat = factor(x1), diabetes = x2, \n         sbp.before = x3, sbp.after = x4) \n\nrm(subject, x1, x2, x3, x4) # just cleaning up\n\nsbp_example# A tibble: 15 x 5\n   subject treat diabetes sbp.before sbp.after\n     <int> <fct>    <dbl>      <dbl>     <dbl>\n 1     101 A            1        120       105\n 2     102 B            0        145       135\n 3     103 C            0        150       150\n 4     104 A            1         NA       120\n 5     105 C           NA        155       135\n 6     106 A            1         NA       115\n 7     107 A            0        135       160\n 8     108 <NA>         1         NA       150\n 9     109 B           NA        115       130\n10     110 C            1        170       155\n11     111 A            0        150       140\n12     112 B            0        145       140\n13     113 C            1        140       150\n14     114 A            1        160       135\n15     115 B           NA        135       120"},{"path":"miss.html","id":"identifying-missingness-with-naniar-functions","chapter":"8 Missing Data and Single Imputation","heading":"8.2 Identifying missingness with naniar functions","text":"naniar package many useful functions.many missing values , overall?many variables missing values, overall?variables contain missing values?many missing values variable?missing one treat, 3 diabetes 3 sbp.values.Can plot missingness, variable?many cases (rows) missing values?many cases complete data, missing values?Can tabulate missingness case?cases missing values?can identify subjects missing data?nine subjects complete data, three subjects missing diabetes (), two subjects missing sbp.(), 1 subject missing treat sbp..","code":"\nn_miss(sbp_example)[1] 7\nn_var_miss(sbp_example)[1] 3\nmiss_var_which(sbp_example)[1] \"treat\"      \"diabetes\"   \"sbp.before\"\nmiss_var_summary(sbp_example)# A tibble: 5 x 3\n  variable   n_miss pct_miss\n  <chr>       <int>    <dbl>\n1 diabetes        3    20   \n2 sbp.before      3    20   \n3 treat           1     6.67\n4 subject         0     0   \n5 sbp.after       0     0   \ngg_miss_var(sbp_example)Warning: It is deprecated to specify `guide = FALSE` to\nremove a guide. Please use `guide = \"none\"` instead.\nn_case_miss(sbp_example)[1] 6\nn_case_complete(sbp_example)[1] 9\nmiss_case_table(sbp_example)# A tibble: 3 x 3\n  n_miss_in_case n_cases pct_cases\n           <int>   <int>     <dbl>\n1              0       9     60   \n2              1       5     33.3 \n3              2       1      6.67\nmiss_case_summary(sbp_example)# A tibble: 15 x 3\n    case n_miss pct_miss\n   <int>  <int>    <dbl>\n 1     8      2       40\n 2     4      1       20\n 3     5      1       20\n 4     6      1       20\n 5     9      1       20\n 6    15      1       20\n 7     1      0        0\n 8     2      0        0\n 9     3      0        0\n10     7      0        0\n11    10      0        0\n12    11      0        0\n13    12      0        0\n14    13      0        0\n15    14      0        0\nsbp_example %>% filter(!complete.cases(.))# A tibble: 6 x 5\n  subject treat diabetes sbp.before sbp.after\n    <int> <fct>    <dbl>      <dbl>     <dbl>\n1     104 A            1         NA       120\n2     105 C           NA        155       135\n3     106 A            1         NA       115\n4     108 <NA>         1         NA       150\n5     109 B           NA        115       130\n6     115 B           NA        135       120"},{"path":"miss.html","id":"missing-data-mechanisms","chapter":"8 Missing Data and Single Imputation","heading":"8.3 Missing-data mechanisms","text":"source description mechanisms Chapter 25 Andrew Gelman Jennifer Hill,28 chapter available link.MCAR = Missingness completely random. variable missing completely random probability missingness units, example, subject, decide whether collect diabetes status rolling die refusing answer “6” shows . data missing completely random, throwing cases missing data bias inferences.Missingness depends observed predictors. general assumption, called missing random MAR, probability variable missing depends available information. , willing assume probability nonresponse diabetes depends , fully recorded variables data. often reasonable model process logistic regression, outcome variable equals 1 observed cases 0 missing. outcome variable missing random, acceptable exclude missing cases (, treat NA), long regression controls variables affect probability missingness.Missingness depends unobserved predictors. Missingness longer “random” depends information recorded information also predicts missing values. particular treatment causes discomfort, patient likely drop study. missingness random (unless “discomfort” measured observed patients). missingness random, must explicitly modeled, else must accept bias inferences.Missingness depends missing value . Finally, particularly difficult situation arises probability missingness depends (potentially missing) variable . example, suppose people higher earnings less likely reveal .Essentially, situations 3 4 referred collectively non-random missingness, cause trouble us 1 2.","code":""},{"path":"miss.html","id":"options-for-dealing-with-missingness","chapter":"8 Missing Data and Single Imputation","heading":"8.4 Options for Dealing with Missingness","text":"several available methods dealing missing data MCAR MAR, basically boil :Complete Case (Available Case) analysesSingle ImputationMultiple Imputation","code":""},{"path":"miss.html","id":"complete-case-and-available-case-analyses","chapter":"8 Missing Data and Single Imputation","heading":"8.5 Complete Case (and Available Case) analyses","text":"Complete Case analyses, rows containing NA values omitted data analyses commence. default approach many statistical software packages, may introduce unpredictable bias fail include useful, often hard-won information.complete case analysis can appropriate number missing observations large, missing pattern either MCAR (missing completely random) MAR (missing random.)Two problems arise complete-case analysis:\nunits missing values differ systematically completely observed cases, bias complete-case analysis.\nmany variables included model, may complete cases, data discarded sake straightforward analysis.\nunits missing values differ systematically completely observed cases, bias complete-case analysis.many variables included model, may complete cases, data discarded sake straightforward analysis.related approach available-case analysis different aspects problem studied different subsets data, perhaps identified basis missing .","code":""},{"path":"miss.html","id":"single-imputation","chapter":"8 Missing Data and Single Imputation","heading":"8.6 Single Imputation","text":"single imputation analyses, NA values estimated/replaced one time one particular data value purpose obtaining complete samples, expense creating potential bias eventual conclusions obtaining slightly less accurate estimates available missing values data.single imputation can just replacement mean median (quantity) mode (categorical variable.) However, approach, though easy understand, underestimates variance ignores relationship missing values variables.Single imputation can also done using variety models try capture information NA values available variables within data set.simputation package can help us execute single imputations using wide variety techniques, within pipe approach used tidyverse. Another approach used past mice package, can also perform single imputations.","code":""},{"path":"miss.html","id":"multiple-imputation","chapter":"8 Missing Data and Single Imputation","heading":"8.7 Multiple Imputation","text":"Multiple imputation, NA values repeatedly estimated/replaced multiple data values, purpose obtaining mode complete samples capturing details variation inherent fact data missingness, obtain accurate estimates possible single imputation.’ll postpone discussion multiple imputation later semester.","code":""},{"path":"miss.html","id":"building-a-complete-case-analysis","chapter":"8 Missing Data and Single Imputation","heading":"8.8 Building a Complete Case Analysis","text":"can drop missing values data set drop_na na.omit filtering complete.cases. approaches produces result - new data set 9 rows (dropping six subjects NA values) 5 columns.","code":"\ncc.1 <- na.omit(sbp_example)\ncc.2 <- sbp_example %>% drop_na\ncc.3 <- sbp_example %>% filter(complete.cases(.))"},{"path":"miss.html","id":"single-imputation-with-the-mean-or-mode","chapter":"8 Missing Data and Single Imputation","heading":"8.9 Single Imputation with the Mean or Mode","text":"straightforward approach single imputation impute single summary variable, mean, median mode., suppose decide imputesbp.mean (143.3) among non-missing values,diabetes common value, 1, andtreat common value, mode ()","code":"\nmosaic::favstats(~ sbp.before, data = sbp_example) min  Q1 median     Q3 max     mean       sd  n missing\n 115 135    145 151.25 170 143.3333 15.71527 12       3\nsbp_example %>% tabyl(diabetes, treat) %>%\n  adorn_totals(where = c(\"row\", \"col\")) diabetes A B C NA_ Total\n        0 2 2 1   0     5\n        1 4 0 2   1     7\n     <NA> 0 2 1   0     3\n    Total 6 4 4   1    15\nsi.1 <- sbp_example %>%\n    replace_na(list(sbp.before = 143.33,\n                    diabetes = 1,\n                    treat = \"A\"))\nsi.1# A tibble: 15 x 5\n   subject treat diabetes sbp.before sbp.after\n     <int> <fct>    <dbl>      <dbl>     <dbl>\n 1     101 A            1       120        105\n 2     102 B            0       145        135\n 3     103 C            0       150        150\n 4     104 A            1       143.       120\n 5     105 C            1       155        135\n 6     106 A            1       143.       115\n 7     107 A            0       135        160\n 8     108 A            1       143.       150\n 9     109 B            1       115        130\n10     110 C            1       170        155\n11     111 A            0       150        140\n12     112 B            0       145        140\n13     113 C            1       140        150\n14     114 A            1       160        135\n15     115 B            1       135        120"},{"path":"miss.html","id":"doing-single-imputation-with-simputation","chapter":"8 Missing Data and Single Imputation","heading":"8.10 Doing Single Imputation with simputation","text":"Single imputation potentially appropriate method missingness can assumed either completely random (MCAR) dependent observed predictors (MAR). ’ll use simputation package accomplish .simputation vignette available https://cran.r-project.org/web/packages/simputation/vignettes/intro.htmlThe simputation reference manual available https://cran.r-project.org/web/packages/simputation/simputation.pdfSuppose wanted use:robust linear model predict sbp.missing values, basis sbp.diabetes status, anda predictive mean matching approach (, unlike robust linear model, ensure values diabetes ’ve seen imputed) predict diabetes status, basis sbp., anda decision tree approach predict treat status, using variables dataDetails many available methods simputation provided manual. include:impute_cart uses Classification Regression Tree approach numerical categorical data. also impute_rf command uses Random Forests imputation.impute_pmm one several “hot deck” options imputation, one predictive mean matching, can used numeric data (). Missing values first imputed using predictive model. Next, predictions replaced observed values nearest prediction. imputation options group include random hot deck, sequential hot deck k-nearest neighbor imputation.impute_rlm one several regression imputation methods, including linear models, robust linear models (use called M-estimation impute numerical variables) lasso/elastic net/ridge regression models.simputation package can also EM-based multivariate imputation, multivariate random forest imputation, several approaches.","code":"\nset.seed(50001)\n\nimp.2 <- sbp_example %>%\n    impute_rlm(sbp.before ~ sbp.after + diabetes) %>%\n    impute_pmm(diabetes ~ sbp.after) %>%\n    impute_cart(treat ~ .)\n\nimp.2# A tibble: 15 x 5\n   subject treat diabetes sbp.before sbp.after\n *   <int> <fct>    <dbl>      <dbl>     <dbl>\n 1     101 A            1       120        105\n 2     102 B            0       145        135\n 3     103 C            0       150        150\n 4     104 A            1       139.       120\n 5     105 C            1       155        135\n 6     106 A            1       136.       115\n 7     107 A            0       135        160\n 8     108 A            1       155.       150\n 9     109 B            1       115        130\n10     110 C            1       170        155\n11     111 A            0       150        140\n12     112 B            0       145        140\n13     113 C            1       140        150\n14     114 A            1       160        135\n15     115 B            1       135        120"},{"path":"NYFS-Study.html","id":"NYFS-Study","chapter":"9 National Youth Fitness Survey","heading":"9 National Youth Fitness Survey","text":"nnyfs.csv nnyfs.Rds data files built Professor Love using data 2012 National Youth Fitness Survey.NHANES National Youth Fitness Survey (NNYFS) conducted 2012 collect data physical activity fitness levels order provide evaluation health fitness children U.S. ages 3 15. NNYFS collected data physical activity fitness levels youth interviews fitness tests.nnyfs data file (either .csv .Rds), ’m providing modest fraction available information. NNYFS (including information ’m using) available https://wwwn.cdc.gov/nchs/nhanes/search/nnyfs12.aspx.data elements ’m using fall four main groups, components:DemographicsDietaryExamination andQuestionnaireWhat merge elements available components NHANES National Youth Fitness Survey, reformulated (cases simplified) variables, restricted sample kids completed elements four components.","code":""},{"path":"NYFS-Study.html","id":"the-variables-included-in-nnyfs","chapter":"9 National Youth Fitness Survey","heading":"9.1 The Variables included in nnyfs","text":"section tells data come , briefly describe collected.","code":""},{"path":"NYFS-Study.html","id":"from-the-nnyfs-demographic-component","chapter":"9 National Youth Fitness Survey","heading":"9.1.1 From the NNYFS Demographic Component","text":"come Y_DEMO file.","code":""},{"path":"NYFS-Study.html","id":"from-the-nnyfs-dietary-component","chapter":"9 National Youth Fitness Survey","heading":"9.1.2 From the NNYFS Dietary Component","text":"Y_DR1TOT file, number variables related child’s diet, following summaries mostly describing consumption “yesterday” dietary recall questionnaire.","code":""},{"path":"NYFS-Study.html","id":"from-the-nnyfs-examination-component","chapter":"9 National Youth Fitness Survey","heading":"9.1.3 From the NNYFS Examination Component","text":"Y_BMX file Body Measures:Y_PLX file Plank test results:","code":""},{"path":"NYFS-Study.html","id":"from-the-nnyfs-questionnaire-component","chapter":"9 National Youth Fitness Survey","heading":"9.1.4 From the NNYFS Questionnaire Component","text":"Y_PAQ file Physical Activity questions:Y_DBQ file Diet Behavior Nutrition questions:Y_HIQ file Health Insurance questions:Y_HUQ file Access Care questions:Y_MCQ file Medical Conditions questions:Y_RXQ_RX file Prescription Medication questions:","code":""},{"path":"NYFS-Study.html","id":"looking-over-a-few-variables","chapter":"9 National Youth Fitness Survey","heading":"9.2 Looking over A Few Variables","text":"Now, ’ll take look nnyfs data, ’ve made available comma-separated version (nnyfs.csv), prefer, well R data set (nnyfs.Rds) loads bit faster. loading file, let’s get handle size contents. R Project notes, data contained separate data subdirectory.1518 rows (subjects) 45 columns (variables), mean 1518 kids nnyfs data frame, 45 pieces information subject.\n, , exactly?Tibbles modern reimagining main way people stored data R, called data frame. Tibbles developed keep time proven effective, throwing . can learn something structure tibble functions str glimpse.lot variables . Let’s run first little detail.","code":"\nnnyfs <- readRDS(\"data/nnyfs.Rds\")\n\n## size of the tibble\ndim(nnyfs)[1] 1518   45\nnnyfs # this is a tibble, has some nice features in a print-out like this# A tibble: 1,518 x 45\n    SEQN sex    age_child race_eth       educ_child language\n   <dbl> <fct>      <dbl> <fct>               <dbl> <fct>   \n 1 71917 Female        15 3_Black Non-H~          9 English \n 2 71918 Female         8 3_Black Non-H~          2 English \n 3 71919 Female        14 2_White Non-H~          8 English \n 4 71920 Female        15 2_White Non-H~          8 English \n 5 71921 Male           3 2_White Non-H~         NA English \n 6 71922 Male          12 1_Hispanic              6 English \n 7 71923 Male          12 2_White Non-H~          5 English \n 8 71924 Female         8 4_Other Race/~          2 English \n 9 71925 Male           7 1_Hispanic              0 English \n10 71926 Male           8 3_Black Non-H~          2 English \n# ... with 1,508 more rows, and 39 more variables:\n#   sampling_wt <dbl>, income_pov <dbl>, age_adult <dbl>,\n#   educ_adult <fct>, respondent <fct>, salt_used <fct>,\n#   energy <dbl>, protein <dbl>, sugar <dbl>, fat <dbl>,\n#   diet_yesterday <fct>, water <dbl>, plank_time <dbl>,\n#   height <dbl>, weight <dbl>, bmi <dbl>, bmi_cat <fct>,\n#   arm_length <dbl>, waist <dbl>, arm_circ <dbl>, ...\nstr(nnyfs)tibble [1,518 x 45] (S3: tbl_df/tbl/data.frame)\n $ SEQN                : num [1:1518] 71917 71918 71919 71920 71921 ...\n $ sex                 : Factor w/ 2 levels \"Female\",\"Male\": 1 1 1 1 2 2 2 1 2 2 ...\n $ age_child           : num [1:1518] 15 8 14 15 3 12 12 8 7 8 ...\n $ race_eth            : Factor w/ 4 levels \"1_Hispanic\",\"2_White Non-Hispanic\",..: 3 3 2 2 2 1 2 4 1 3 ...\n $ educ_child          : num [1:1518] 9 2 8 8 NA 6 5 2 0 2 ...\n $ language            : Factor w/ 2 levels \"English\",\"Spanish\": 1 1 1 1 1 1 1 1 1 1 ...\n $ sampling_wt         : num [1:1518] 28299 15127 29977 80652 55592 ...\n $ income_pov          : num [1:1518] 0.21 5 5 0.87 4.34 5 5 2.74 0.46 1.57 ...\n $ age_adult           : num [1:1518] 46 46 42 53 31 42 39 31 45 56 ...\n $ educ_adult          : Factor w/ 5 levels \"1_Less than 9th Grade\",..: 2 3 5 3 3 4 2 3 2 3 ...\n $ respondent          : Factor w/ 3 levels \"Child\",\"Mom\",..: 1 2 1 1 2 1 1 1 2 1 ...\n $ salt_used           : Factor w/ 2 levels \"No\",\"Yes\": 2 2 2 2 1 2 2 2 1 2 ...\n $ energy              : num [1:1518] 2844 1725 2304 1114 1655 ...\n $ protein             : num [1:1518] 169.1 55.2 199.3 14 50.6 ...\n $ sugar               : num [1:1518] 128.2 118.7 81.4 119.2 90.3 ...\n $ fat                 : num [1:1518] 127.9 63.7 86.1 36 53.3 ...\n $ diet_yesterday      : Factor w/ 3 levels \"1_Much more than usual\",..: 2 2 2 2 2 2 1 2 2 3 ...\n $ water               : num [1:1518] 607 178 503 859 148 ...\n $ plank_time          : num [1:1518] NA 45 121 45 11 107 127 44 184 58 ...\n $ height              : num [1:1518] NA 131.6 172 167.1 90.2 ...\n $ weight              : num [1:1518] NA 38.6 58.7 92.5 12.4 66.4 56.7 22.2 20.9 28.3 ...\n $ bmi                 : num [1:1518] NA 22.3 19.8 33.1 15.2 25.9 22.5 14.4 15.9 17 ...\n $ bmi_cat             : Factor w/ 4 levels \"1_Underweight\",..: NA 4 2 4 2 4 3 2 2 2 ...\n $ arm_length          : num [1:1518] NA 27.7 38.4 35.9 18.3 34.2 33 26.5 24.2 26 ...\n $ waist               : num [1:1518] NA 71.9 79.4 96.4 46.8 90 72.3 56.1 54.5 59.7 ...\n $ arm_circ            : num [1:1518] NA 25.4 26 37.9 15.1 29.5 27.9 17.6 17.7 19.9 ...\n $ calf_circ           : num [1:1518] NA 32.3 35.3 46.8 19.4 36.9 36.8 24 24.3 27.3 ...\n $ calf_skinfold       : num [1:1518] NA 22 18.4 NA 8.4 22 18.3 7 7.2 8.2 ...\n $ triceps_skinfold    : num [1:1518] NA 19.9 15 20.6 8.6 22.8 20.5 12.9 6.9 8.8 ...\n $ subscapular_skinfold: num [1:1518] NA 17.4 9.8 22.8 5.7 24.4 12.6 6.8 4.8 6.1 ...\n $ active_days         : num [1:1518] 3 5 3 3 7 2 5 3 7 7 ...\n $ tv_hours            : num [1:1518] 2 2 1 3 2 3 0 4 2 2 ...\n $ computer_hours      : num [1:1518] 1 2 3 3 0 1 0 3 1 1 ...\n $ physical_last_week  : Factor w/ 2 levels \"No\",\"Yes\": 1 1 2 2 2 2 2 2 2 2 ...\n $ enjoy_recess        : Factor w/ 5 levels \"1_Strongly Agree\",..: 1 1 3 2 NA 2 2 NA 1 1 ...\n $ meals_out           : num [1:1518] 0 2 3 2 1 1 2 1 0 2 ...\n $ insured             : Factor w/ 2 levels \"Has Insurance\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ phys_health         : Factor w/ 5 levels \"1_Excellent\",..: 1 3 1 3 1 1 3 1 2 1 ...\n $ access_to_care      : Factor w/ 2 levels \"Has Usual Care Source\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ care_source         : Factor w/ 6 levels \"Clinic or Health Center\",..: 1 2 2 2 2 2 2 2 2 2 ...\n $ asthma_ever         : Factor w/ 2 levels \"History of Asthma\",..: 2 1 2 1 2 2 2 2 2 2 ...\n $ asthma_now          : Factor w/ 2 levels \"Asthma Now\",\"No Asthma Now\": 2 1 2 1 2 2 2 2 2 2 ...\n $ med_use             : Factor w/ 2 levels \"Had Medication\",..: 2 1 2 1 2 2 2 2 2 2 ...\n $ med_count           : num [1:1518] 0 1 0 2 0 0 0 0 0 0 ...\n $ insurance           : Factor w/ 10 levels \"Medicaid\",\"Medicare\",..: 8 8 5 8 5 5 5 5 8 1 ..."},{"path":"NYFS-Study.html","id":"seqn","chapter":"9 National Youth Fitness Survey","heading":"9.2.1 SEQN","text":"first variable, SEQN just (numerical) identifying code attributable given subject survey. nominal data, little interest line. occasions, case, ID numbers sequential, sense subject 71919 included data base subject 71918, fact isn’t particularly interesting , protocol remained unchanged throughout study.","code":""},{"path":"NYFS-Study.html","id":"sex","chapter":"9 National Youth Fitness Survey","heading":"9.2.2 sex","text":"second variable, sex, listed factor variable (R uses factor character refer categorical, especially non-numeric information). , can see , two levels, Female Male.","code":"\nnnyfs %>%\n  tabyl(sex) %>%\n  adorn_totals() %>%\n  adorn_pct_formatting()    sex    n percent\n Female  760   50.1%\n   Male  758   49.9%\n  Total 1518  100.0%"},{"path":"NYFS-Study.html","id":"age_child","chapter":"9 National Youth Fitness Survey","heading":"9.2.3 age_child","text":"third variable, age_child, age child time screening study, measured years. Note age continuous concept, measure used (number full years alive) common discrete approach measurement. Age, course, meaningful zero point, can thought ratio variable; child 6 half old one 12. can tabulate observed values, since dozen .time initial screening, children 3 15 years age, things look reasonable. Since meaningful quantitative variable, may interested descriptive summary.six numbers provide nice, incomplete, look ages.Min. = minimum, youngest age examination 3 years old.1st Qu. = first quartile (25th percentile) ages 6. means 25 percent subjects age 6 less.Median = second quartile (50th percentile) ages 9. often used describe center data. Half subjects age 9 less.3rd Qu. = third quartile (75th percentile) ages 12Max. = maximum, oldest age examination 15 years.get standard deviation count missing non-missing observations favstats mosaic package.","code":"\nnnyfs %>% tabyl(age_child) %>%\n  adorn_pct_formatting() age_child   n percent\n         3 110    7.2%\n         4 112    7.4%\n         5 114    7.5%\n         6 129    8.5%\n         7 123    8.1%\n         8 112    7.4%\n         9  99    6.5%\n        10 124    8.2%\n        11 111    7.3%\n        12 137    9.0%\n        13 119    7.8%\n        14 130    8.6%\n        15  98    6.5%\nnnyfs %>% select(age_child) %>% \n  summary()   age_child     \n Min.   : 3.000  \n 1st Qu.: 6.000  \n Median : 9.000  \n Mean   : 9.033  \n 3rd Qu.:12.000  \n Max.   :15.000  \nmosaic::favstats(~ age_child, data = nnyfs) %>%\n  kable(digits = 1)"},{"path":"NYFS-Study.html","id":"race_eth","chapter":"9 National Youth Fitness Survey","heading":"9.2.4 race_eth","text":"fourth variable data set race_eth, multi-categorical variable describing child’s race ethnicity.now, get idea looking whether numerical summaries children’s ages varies race/ethnicity…","code":"\nnnyfs %>% tabyl(race_eth) %>% \n  adorn_pct_formatting() %>%\n  knitr::kable()\nmosaic::favstats(age_child ~ race_eth, data = nnyfs)                race_eth min   Q1 median Q3 max     mean\n1             1_Hispanic   3 5.25    9.0 12  15 8.793333\n2   2_White Non-Hispanic   3 6.00    9.0 12  15 9.137705\n3   3_Black Non-Hispanic   3 6.00    9.0 12  15 9.038462\n4 4_Other Race/Ethnicity   3 7.00    9.5 12  15 9.383333\n        sd   n missing\n1 3.733846 450       0\n2 3.804421 610       0\n3 3.576423 338       0\n4 3.427970 120       0"},{"path":"NYFS-Study.html","id":"income_pov","chapter":"9 National Youth Fitness Survey","heading":"9.2.5 income_pov","text":"Skipping bit, let’s look family income multiple poverty level. ’s summary.see missing data . Let’s ignore moment concentrate interpreting results children actual data. start picture.histogram shows us values truncated 5, children whose actual family income 5 times poverty line listed 5. also see message reminding us data missing variable.relationship income_pov race_eth data?deserves picture. Let’s try boxplot.","code":"\nnnyfs %>% select(income_pov) %>% summary()   income_pov   \n Min.   :0.000  \n 1st Qu.:0.870  \n Median :1.740  \n Mean   :2.242  \n 3rd Qu.:3.520  \n Max.   :5.000  \n NA's   :89     \nggplot(nnyfs, aes(x = income_pov)) +\n  geom_histogram(bins = 30, fill = \"white\", col = \"blue\")Warning: Removed 89 rows containing non-finite values\n(stat_bin).\nmosaic::favstats(income_pov ~ race_eth, data = nnyfs) %>%\n  kable(digits = 1)\nggplot(nnyfs, aes(x = race_eth, y = income_pov)) +\n  geom_boxplot()Warning: Removed 89 rows containing non-finite values\n(stat_boxplot)."},{"path":"NYFS-Study.html","id":"bmi","chapter":"9 National Youth Fitness Survey","heading":"9.2.6 bmi","text":"Moving body measurement data, bmi body-mass index child. BMI person’s weight kilograms divided height meters squared. Symbolically, BMI = weight kg / (height m)2. continuous concept, measured many decimal places like, meaningful zero point, ’s ratio variable.table BMI values great idea, data? hint R represents variable num numeric depiction data structure, implies R decimal values stored. , ’ll use head() function tail() function show first last values prove long table bmi values.","code":"\nnnyfs %>% select(bmi) %>% summary()      bmi       \n Min.   :11.90  \n 1st Qu.:15.90  \n Median :18.10  \n Mean   :19.63  \n 3rd Qu.:21.90  \n Max.   :48.30  \n NA's   :4      \nnnyfs %>% tabyl(bmi) %>% \n  adorn_pct_formatting() %>% \n  head()  bmi n percent valid_percent\n 11.9 1    0.1%          0.1%\n 12.6 1    0.1%          0.1%\n 12.7 1    0.1%          0.1%\n 12.9 1    0.1%          0.1%\n 13.0 2    0.1%          0.1%\n 13.1 1    0.1%          0.1%\nnnyfs %>% tabyl(bmi) %>% \n  adorn_pct_formatting() %>% \n  tail()  bmi n percent valid_percent\n 42.8 1    0.1%          0.1%\n 43.0 1    0.1%          0.1%\n 46.9 1    0.1%          0.1%\n 48.2 1    0.1%          0.1%\n 48.3 1    0.1%          0.1%\n   NA 4    0.3%             -"},{"path":"NYFS-Study.html","id":"bmi_cat","chapter":"9 National Youth Fitness Survey","heading":"9.2.7 bmi_cat","text":"Next ’ll look bmi_cat information. four-category ordinal variable, divides sample according BMI four groups. BMI categories use sex-specific 2000 BMI--age (months) growth charts prepared Centers Disease Control US. can get breakdown table variable’s values.terms percentiles age sex growth charts, meanings categories :Underweight (BMI < 5th percentile)Normal weight (BMI 5th < 85th percentile)Overweight (BMI 85th < 95th percentile)Obese (BMI \\(\\geq\\) 95th percentile)Note ’ve used labels bmi_cat variable include number start table results sorted rational way. R sorts tables alphabetically, general. ’ll use forcats package work categorical variables store factors eventually, now, ’ll keep things relatively simple.Note bmi_cat data don’t completely separate raw bmi data, calculation percentiles requires different tables combination age sex.","code":"\nnnyfs %>% tabyl(bmi_cat) %>% adorn_pct_formatting()       bmi_cat   n percent valid_percent\n 1_Underweight  41    2.7%          2.7%\n      2_Normal 920   60.6%         60.8%\n  3_Overweight 258   17.0%         17.0%\n       4_Obese 295   19.4%         19.5%\n          <NA>   4    0.3%             -\nmosaic::favstats(bmi ~ bmi_cat, data = nnyfs) %>%\n  kable(digits = 1)"},{"path":"NYFS-Study.html","id":"waist","chapter":"9 National Youth Fitness Survey","heading":"9.2.8 waist","text":"Let’s also look briefly waist, circumference child’s waist, centimeters. , numeric variable, perhaps ’ll stick simple summary, rather obtaining table observed values.’s histogram waist circumference data.","code":"\nmosaic::favstats(~ waist, data = nnyfs)   min   Q1 median   Q3   max     mean       sd    n missing\n 42.5 55.6   64.8 76.6 144.7 67.70536 15.19809 1512       6\nggplot(nnyfs, aes(x = waist)) +\n  geom_histogram(bins = 25, fill = \"tomato\", color = \"cyan\")Warning: Removed 6 rows containing non-finite values\n(stat_bin)."},{"path":"NYFS-Study.html","id":"triceps_skinfold","chapter":"9 National Youth Fitness Survey","heading":"9.2.9 triceps_skinfold","text":"last variable ’ll look now triceps_skinfold, measured millimeters. one several common locations used assessment body fat using skinfold calipers, frequent part growth assessments children. , numeric variable according R.’s histogram triceps skinfold data, fill color flipped saw plot waist circumference data moment ago.OK. ’ve seen variables, ’ll move now look seriously data.","code":"\nmosaic::favstats(~ triceps_skinfold, data = nnyfs) min  Q1 median Q3  max     mean       sd    n missing\n   4 9.1   12.4 18 38.8 14.35725 6.758825 1497      21\nggplot(nnyfs, aes(x = triceps_skinfold)) +\n  geom_histogram(bins = 25, fill = \"cyan\", color = \"tomato\")Warning: Removed 21 rows containing non-finite values\n(stat_bin)."},{"path":"NYFS-Study.html","id":"additional-numeric-summaries","chapter":"9 National Youth Fitness Survey","heading":"9.3 Additional Numeric Summaries","text":"","code":""},{"path":"NYFS-Study.html","id":"the-five-number-summary-quantiles-and-iqr","chapter":"9 National Youth Fitness Survey","heading":"9.3.1 The Five Number Summary, Quantiles and IQR","text":"five number summary famous used form box plot - ’s minimum, 25th percentile, median, 75th percentile maximum. numerical integer variables, summary function produces five number summary, plus mean, count missing values (NA’s).alternative, can use $ notation indicate variable wish study inside data set, can use fivenum function get five numbers used developing box plot. ’ll focus little number kilocalories consumed child, according dietary recall questionnaire. ’s energy variable.mentioned 6.3.1, inter-quartile range, IQR, sometimes used competitor standard deviation. ’s difference 75th percentile 25th percentile. 25th percentile, median, 75th percentile referred quartiles data set, , together, split data quarters.can obtain quantiles (percentiles) like - , ’m asking 1st 99th:","code":"\nnnyfs %>% \n  select(waist, energy, sugar) %>%\n  summary()     waist            energy         sugar       \n Min.   : 42.50   Min.   : 257   Min.   :  1.00  \n 1st Qu.: 55.60   1st Qu.:1368   1st Qu.: 82.66  \n Median : 64.80   Median :1794   Median :116.92  \n Mean   : 67.71   Mean   :1877   Mean   :124.32  \n 3rd Qu.: 76.60   3rd Qu.:2306   3rd Qu.:157.05  \n Max.   :144.70   Max.   :5265   Max.   :405.49  \n NA's   :6                                       \nfivenum(nnyfs$energy)[1]  257.0 1367.0 1794.5 2306.0 5265.0\nIQR(nnyfs$energy)[1] 938.5\nquantile(nnyfs$energy, probs=c(0.01, 0.99))     1%     99% \n 566.85 4051.75 "},{"path":"NYFS-Study.html","id":"additional-summaries-from-favstats","chapter":"9 National Youth Fitness Survey","heading":"9.4 Additional Summaries from favstats","text":"’re focusing single variable, favstats function mosaic package can helpful. Rather calling entire mosaic library , ’ll just specify function within library.adds three useful results base summary - standard deviation, sample size number missing observations.","code":"\nmosaic::favstats(~ energy, data = nnyfs) min     Q1 median   Q3  max     mean       sd    n missing\n 257 1367.5 1794.5 2306 5265 1877.157 722.3537 1518       0"},{"path":"NYFS-Study.html","id":"the-histogram","chapter":"9 National Youth Fitness Survey","heading":"9.5 The Histogram","text":"Obtaining basic histogram , example, energy (kilocalories consumed) nnyfs data pretty straightforward.","code":"\nggplot(data = nnyfs, aes(x = energy)) +\n    geom_histogram(binwidth = 100, col = \"white\")"},{"path":"NYFS-Study.html","id":"freedman-diaconis-rule-to-select-bin-width","chapter":"9 National Youth Fitness Survey","heading":"9.5.1 Freedman-Diaconis Rule to select bin width","text":"like, can suggest particular number cells histogram, instead accepting defaults. case, \\(n\\) = 1518 observations. Freedman-Diaconis rule can helpful . rule suggests set bin-width \\[\nh = \\frac{2*IQR}{n^{1/3}}\n\\]number bins equal range data set (maximum - minimum) divided \\(h\\).energy data nnyfs tibble, haveIQR 938.5, \\(n\\) = 1518 range = 5008Thus, Freedman-Diaconis rule, optimal binwidth \\(h\\) 163.3203676, , realistically, 163.number bins 30.6636586, , realistically 31., ’ll draw graph , using Freedman-Diaconis rule identify number bins, also play around bit fill color bars.nice start, means finished graph.Let’s improve axis labels, add title, fill bars distinctive blue use black outline around bar. ’ll just use 25 bars, like looks case, optimizing number bins rarely important.","code":"\nbw <- 2 * IQR(nnyfs$energy) / length(nnyfs$energy)^(1/3)\nggplot(data = nnyfs, aes(x = energy)) +\n    geom_histogram(binwidth=bw, color = \"white\", fill = \"black\")\nggplot(data = nnyfs, aes(x = energy)) +\n    geom_histogram(bins=25, color = \"black\", fill = \"dodgerblue\") + \n    labs(title = \"Histogram of Body-Mass Index Results in the nnyfs data\",\n         x = \"Energy Consumed (kcal)\", y = \"# of Subjects\")"},{"path":"NYFS-Study.html","id":"a-note-on-colors","chapter":"9 National Youth Fitness Survey","heading":"9.5.2 A Note on Colors","text":"simplest way specify color name, enclosed parentheses. favorite list R colors http://www.stat.columbia.edu/~tzheng/files/Rcolor.pdf. pinch, can usually find googling Colors R. can also type colors() R console obtain list names 657 colors.using colors make comparisons, may interested using scale nice properties. viridis package vignette describes four color scales (viridis, magma, plasma inferno) designed colorful, robust colorblindness gray scale printing, perceptually uniform, means (package authors describe ) values close similar-appearing colors values far away different-appearing colors, consistently across range values. can apply colors special functions within ggplot.’s comparison several histograms, looking energy consumed function whether yesterday typical terms food consumption.don’t really need legend , perhaps restrict plot participants responded diet_yesterday question, put title better axis labels?","code":"\nggplot(data = nnyfs, aes(x = energy, fill = diet_yesterday)) +\n  geom_histogram(bins = 20, col = \"white\") +\n  scale_fill_viridis_d() +\n  facet_wrap(~ diet_yesterday)\nnnyfs %>% filter(complete.cases(energy, diet_yesterday)) %>%\n  ggplot(data = ., aes(x = energy, fill = diet_yesterday)) +\n  geom_histogram(bins = 20, col = \"white\") +\n  scale_fill_viridis_d() +\n  guides(fill = \"none\") +\n  facet_wrap(~ diet_yesterday) +\n  labs(x = \"Energy consumed, in kcal\",\n       title = \"Energy Consumption and How Typical Was Yesterday's Eating\",\n       subtitle = \"NHANES National Youth Fitness Survey, no survey weighting\")"},{"path":"NYFS-Study.html","id":"the-frequency-polygon","chapter":"9 National Youth Fitness Survey","heading":"9.6 The Frequency Polygon","text":"’ve seen, can also plot distribution single continuous variable using freqpoly geom. can also add rug plot, places small vertical line horizontal axis everywhere observation appears data.","code":"\nggplot(data = nnyfs, aes(x = energy)) +\n    geom_freqpoly(binwidth = 150, color = \"dodgerblue\") + \n    geom_rug(color = \"red\") +\n    labs(title = \"Frequency Polygon of nnyfs Energy data\",\n         x = \"Energy (kcal)\", y = \"# of Patients\")"},{"path":"NYFS-Study.html","id":"plotting-the-probability-density-function","chapter":"9 National Youth Fitness Survey","heading":"9.7 Plotting the Probability Density Function","text":"can also produce density function, effect smoothing bumps histogram frequency polygon, also changing plotted y-axis., ’s density function?probability density function function continuous variable, x, represents probability x falling within given range. Specifically, integral interval (,b) density function gives probability value x within (,b).’re interested exploring notion density functions continuous (discrete) random variables, nice elementary material available Khan Academy.","code":"\nggplot(data = nnyfs, aes(x = energy)) +\n    geom_density(kernel = \"gaussian\", color = \"dodgerblue\") + \n    labs(title = \"Density of nnyfs Energy data\",\n         x = \"Energy (kcal)\", y = \"Probability Density function\")"},{"path":"NYFS-Study.html","id":"the-boxplot","chapter":"9 National Youth Fitness Survey","heading":"9.8 The Boxplot","text":"Sometimes, ’s helpful picture five-number summary data way get general sense distribution. One approach boxplot, sometimes called box--whisker plot.","code":""},{"path":"NYFS-Study.html","id":"drawing-a-boxplot-for-one-variable-in-ggplot2","chapter":"9 National Youth Fitness Survey","heading":"9.8.1 Drawing a Boxplot for One Variable in ggplot2","text":"ggplot2 library easily handles comparison boxplots multiple distributions, ’ll see moment. However, building boxplot single distribution requires little trickiness.","code":"\nggplot(nnyfs, aes(x = 1, y = energy)) + \n    geom_boxplot(fill = \"deepskyblue\") + \n    coord_flip() + \n    labs(title = \"Boxplot of Energy for kids in the NNYFS\",\n         y = \"Energy (kcal)\",\n         x = \"\") +\n    theme(axis.text.y = element_blank(),\n          axis.ticks.y = element_blank())"},{"path":"NYFS-Study.html","id":"about-the-boxplot","chapter":"9 National Youth Fitness Survey","heading":"9.8.2 About the Boxplot","text":"boxplot another John Tukey invention.R draws box (yellow) edges box fall 25th 75th percentiles data, thick line inside box falls median (50th percentile).whiskers extend largest smallest values classified plot candidate outliers.outlier unusual point, far center distribution.Note ’ve used horizontal option show boxplot direction. comparison boxplots, ’ll see , oriented vertically.boxplot’s whiskers drawn first third quartiles (.e. 25th 75th percentiles) extreme points data meet standard ``candidate outliers.’’ outlier simply point far away center data - may due number reasons, generally indicates need investigation.software, including R, uses standard proposed Tukey describes ``candidate outlier’’ point upper fence lower fence. definitions fences based inter-quartile range (IQR).IQR = 75th percentile - 25th percentile, upper fence 75th percentile + 1.5 IQR, lower fence 25th percentile - 1.5 IQR.energy data,upper fence located 2306 + 1.5(938.5) = 3713.75the lower fence located 1367 - 1.5(938.5) = -40.75In case, see points identified outliers low part distribution, quite identified way high side. tends identify 5% data candidate outlier, data follow Normal distribution.plot indicating clearly asymmetry (skew) data, specifically right skew.standard R uses indicate outliers points 1.5 inter-quartile ranges away edges box.horizontal orientation ’ve chosen clarifies relationship direction skew plot. plot like , multiple outliers right side indicative long right tail distribution, hence, positive right skew - mean larger median. indications skew include one side box substantially wider , one side whiskers substantially longer . skew later.","code":""},{"path":"NYFS-Study.html","id":"a-simple-comparison-boxplot","chapter":"9 National Youth Fitness Survey","heading":"9.9 A Simple Comparison Boxplot","text":"Boxplots often used comparison. can build boxplots using ggplot2, well, ’ll discuss detail later. now, ’s boxplot built compare energy results subject’s race/ethnicity.Let’s look comparison observed energy levels across five categories phys_health variable, now making use viridis color scheme.graph, ’s bad, want improve ?Let’s turn boxes horizontal direction, get rid perhaps unnecessary phys_health labels.","code":"\nggplot(nnyfs, aes(x = factor(race_eth), y = energy, fill=factor(race_eth))) +\n  geom_boxplot() + \n  guides(fill = \"none\") +\n  labs(y = \"Energy consumed (kcal)\", x = \"Race/Ethnicity\")\nggplot(nnyfs, aes(x = factor(phys_health), y = energy, fill = factor(phys_health))) +\n  geom_boxplot() + \n  scale_fill_viridis_d() + \n  labs(title = \"Energy by Self-Reported Physical Health, in nnyfs data\")\nggplot(nnyfs, aes(x = factor(phys_health), y = energy, fill = factor(phys_health))) +\n    geom_boxplot() + \n    scale_fill_viridis_d() + \n    coord_flip() + \n    guides(fill = \"none\") +\n    labs(title = \"Energy Consumed by Self-Reported Physical Health\", \n         subtitle = \"NHANES National Youth Fitness Survey, unweighted\", \n         x = \"\")"},{"path":"NYFS-Study.html","id":"using-describe-in-the-psych-library","chapter":"9 National Youth Fitness Survey","heading":"9.10 Using describe in the psych library","text":"additional numerical summaries, one option consider using describe function psych library.package provides, order, following…n = sample sizemean = sample meansd = sample standard deviationmedian = median, 50th percentiletrimmed = mean middle 80% datamad = median absolute deviationmin = minimum value samplemax = maximum value samplerange = max - minskew = skewness measure, described (indicates degree asymmetry)kurtosis = kurtosis measure, described (indicates heaviness tails, degree outlier-proneness)se = standard error sample mean = sd / square root sample size, useful inference","code":"\npsych::describe(nnyfs$energy)   vars    n    mean     sd median trimmed    mad min  max\nX1    1 1518 1877.16 722.35 1794.5  1827.1 678.29 257 5265\n   range skew kurtosis    se\nX1  5008  0.8     1.13 18.54"},{"path":"NYFS-Study.html","id":"the-trimmed-mean","chapter":"9 National Youth Fitness Survey","heading":"9.10.1 The Trimmed Mean","text":"trimmed mean trim value R indicates proportion observations trimmed end outcome distribution mean calculated. trimmed value provided psych::describe package describes particular package calls 20% trimmed mean (bottom top 10% energy values removed taking mean - ’s mean middle 80% data.) might call 10% trimmed mean settings, ’s just .","code":"\nmean(nnyfs$energy, trim=.1) [1] 1827.1"},{"path":"NYFS-Study.html","id":"the-median-absolute-deviation","chapter":"9 National Youth Fitness Survey","heading":"9.10.2 The Median Absolute Deviation","text":"alternative IQR fancier, bit robust, median absolute deviation, , large sample sizes, data follow Normal distribution, (expectation) equal standard deviation. MAD median absolute deviations median, multiplied constant (1.4826) yield asymptotically normal consistency.","code":"\nmad(nnyfs$energy)[1] 678.2895"},{"path":"NYFS-Study.html","id":"assessing-skew","chapter":"9 National Youth Fitness Survey","heading":"9.11 Assessing Skew","text":"relatively common idea assess skewness, several measures available. Many models assume Normal distribution, , among things, data symmetric around mean.Skewness measures asymmetry distribution, left skew (mean < median) indicated negative skewness values, right skew (mean > median) indicated positive values. skew value near zero data follow symmetric distribution.","code":""},{"path":"NYFS-Study.html","id":"non-parametric-skewness","chapter":"9 National Youth Fitness Survey","heading":"9.11.1 Non-parametric Skewness","text":"simpler measure skew, sometimes called nonparametric skew closely related Pearson’s notion median skewness, falls -1 +1 distribution. just difference mean median, divided standard deviation.Values greater +0.2 sometimes taken indicate fairly substantial right skew, values -0.2 indicate fairly substantial left skew.Wikipedia page skewness, material derived, provides definitions several skewness measures.","code":"\n(mean(nnyfs$energy) - median(nnyfs$energy))/sd(nnyfs$energy)[1] 0.114427"},{"path":"NYFS-Study.html","id":"assessing-kurtosis-heavy-tailedness","chapter":"9 National Youth Fitness Survey","heading":"9.12 Assessing Kurtosis (Heavy-Tailedness)","text":"Another measure distribution’s shape can found psych library kurtosis. Kurtosis indicator whether distribution heavy-tailed light-tailed compared Normal distribution. Positive kurtosis means variance due outliers - unusual points far away mean relative might expect Normally distributed data set standard deviation.Normal distribution kurtosis value near 0, distribution similar tail behavior expect Normal said mesokurticHigher kurtosis values (meaningfully higher 0) indicate , compared Normal distribution, observed variance result extreme outliers (.e. heavy tails) opposed result modest sized deviations mean. heavy-tailed, outlier prone, distributions sometimes called leptokurtic.Kurtosis values meaningfully lower 0 indicate light-tailed data, fewer outliers ’d expect Normal distribution. distributions sometimes referred platykurtic, include distributions without outliers, like Uniform distribution.’s table:Note kurtosi() function strangely named, part psych package.","code":"\npsych::kurtosi(nnyfs$energy)[1] 1.130539"},{"path":"NYFS-Study.html","id":"the-standard-error-of-the-sample-mean","chapter":"9 National Youth Fitness Survey","heading":"9.12.1 The Standard Error of the Sample Mean","text":"standard error sample mean, standard deviation divided square root sample size:","code":"\nsd(nnyfs$energy)/sqrt(length(nnyfs$energy))[1] 18.54018"},{"path":"NYFS-Study.html","id":"the-describe-function-in-the-hmisc-package","chapter":"9 National Youth Fitness Survey","heading":"9.13 The describe function in the Hmisc package","text":"Hmisc package lots useful functions. ’s named main developer, Frank Harrell. describe function Hmisc knows enough separate numerical categorical variables, give separate (detailed) summaries .categorical variable, provides counts total observations (n), number missing values, number unique categories, along counts percentages falling category.numerical variable, provides:counts total observations (n), number missing values, number unique valuesan Info value data, indicates continuous variable (score 1 generally indicative completely continuous variable ties, scores near 0 indicate lots ties, unique values)sample MeanGini’s mean difference, robust measure spread, larger values indicating greater dispersion data. defined mean absolute difference pairs observations.many sample percentiles (quantiles) data, specifically (5, 10, 25, 50, 75, 90, 95, 99)either complete table observed values, counts percentages (modest number unique values), ora table five smallest five largest values data set, useful range checkingMore Info value Hmisc::describe available ","code":"\nnnyfs %>% \n  select(waist, energy, bmi) %>%\n  Hmisc::describe(). \n\n 3  Variables      1518  Observations\n------------------------------------------------------------\nwaist \n       n  missing distinct     Info     Mean      Gmd \n    1512        6      510        1    67.71     16.6 \n     .05      .10      .25      .50      .75      .90 \n   49.40    51.40    55.60    64.80    76.60    88.70 \n     .95 \n   96.84 \n\nlowest :  42.5  43.4  44.1  44.4  44.5\nhighest: 125.8 126.0 127.0 132.3 144.7\n------------------------------------------------------------\nenergy \n       n  missing distinct     Info     Mean      Gmd \n    1518        0     1137        1     1877    796.1 \n     .05      .10      .25      .50      .75      .90 \n     849     1047     1368     1794     2306     2795 \n     .95 \n    3195 \n\nlowest :  257  260  326  349  392, highest: 4382 4529 5085 5215 5265\n------------------------------------------------------------\nbmi \n       n  missing distinct     Info     Mean      Gmd \n    1514        4      225        1    19.63    5.269 \n     .05      .10      .25      .50      .75      .90 \n   14.30    14.90    15.90    18.10    21.90    26.27 \n     .95 \n   30.20 \n\nlowest : 11.9 12.6 12.7 12.9 13.0, highest: 42.8 43.0 46.9 48.2 48.3\n------------------------------------------------------------"},{"path":"NYFS-Study.html","id":"summarizing-data-within-subgroups","chapter":"9 National Youth Fitness Survey","heading":"9.14 Summarizing data within subgroups","text":"Suppose want understand subjects whose diet involved consuming much usual yesterday compare consumer usual amount, consumed much less usual, terms energy consumed, well protein. might start looking medians means.Perhaps restrict people missing diet_yesterday category, look now sugar water consumption.looks like children “Much usual” category consumed energy, protein, sugar water children two categories. Let’s draw picture .can see considerable overlap distributions, regardless ’re measuring.","code":"\nnnyfs %>%\n    group_by(diet_yesterday) %>%\n    select(diet_yesterday, energy, protein) %>%\n    summarise_all(list(median = median, mean = mean))# A tibble: 4 x 5\n  diet_yesterday    energy_median protein_median energy_mean\n  <fct>                     <dbl>          <dbl>       <dbl>\n1 1_Much more than~          2098           69.4       2150.\n2 2_Usual                    1794           61.3       1858.\n3 3_Much less than~          1643           53.9       1779.\n4 <NA>                       4348          155.        4348 \n# ... with 1 more variable: protein_mean <dbl>\nnnyfs %>%\n    filter(complete.cases(diet_yesterday)) %>%\n    group_by(diet_yesterday) %>%\n    select(diet_yesterday, energy, protein, sugar, water) %>%\n    summarise_all(list(median))# A tibble: 3 x 5\n  diet_yesterday         energy protein sugar water\n  <fct>                   <dbl>   <dbl> <dbl> <dbl>\n1 1_Much more than usual   2098    69.4  137.  500 \n2 2_Usual                  1794    61.3  114.  385.\n3 3_Much less than usual   1643    53.9  115.  311.\ntemp_dat <- nnyfs %>%\n    filter(complete.cases(diet_yesterday)) %>%\n    mutate(diet_yesterday = fct_recode(diet_yesterday,\n        \"Much more\" = \"1_Much more than usual\",\n        \"Usual diet\" = \"2_Usual\",\n        \"Much less\" = \"3_Much less than usual\"))\n\np1 <- ggplot(temp_dat, aes(x = diet_yesterday, y = energy)) +\n    geom_violin() +\n    geom_boxplot(aes(fill = diet_yesterday), width = 0.2) +\n    theme_light() + \n    scale_fill_viridis_d() +\n    guides(fill = \"none\") +\n    labs(title = \"Energy Comparison\")\n\np2 <- ggplot(temp_dat, aes(x = diet_yesterday, y = protein)) +\n    geom_violin() +\n    geom_boxplot(aes(fill = diet_yesterday), width = 0.2) +\n    theme_light() + \n    scale_fill_viridis_d() +\n    guides(fill = \"none\") +\n    labs(title = \"Protein Comparison\")\n\np3 <- ggplot(temp_dat, aes(x = diet_yesterday, y = sugar)) +\n    geom_violin() +\n    geom_boxplot(aes(fill = diet_yesterday), width = 0.2) +\n    theme_light() + \n    scale_fill_viridis_d() +\n    guides(fill = \"none\") +\n    labs(title = \"Sugar Comparison\")\n\np4 <- ggplot(temp_dat, aes(x = diet_yesterday, y = water)) +\n    geom_violin() +\n    geom_boxplot(aes(fill = diet_yesterday), width = 0.2) +\n    theme_light() + \n    scale_fill_viridis_d() +\n    guides(fill = \"none\") +\n    labs(title = \"Water Comparison\")\n\np1 + p2 + p3 + p4"},{"path":"NYFS-Study.html","id":"another-example","chapter":"9 National Youth Fitness Survey","heading":"9.15 Another Example","text":"Suppose now ask different question. kids larger categories BMI larger waist circumferences?Oops. Looks like need filter cases complete data BMI category waist circumference order get meaningful results. add count, ., use something like favstats mosaic package, automatically accounts missing data, omits calculating summary statistics within group.patients heavier groups generally higher waist circumferences, standard deviations suggest may meaningful overlap. Let’s draw picture, case comparison boxplot accompanying violin plot.data transformation dplyr cheat sheet found Help menu RStudio great resource. , course, details, visit Grolemund Wickham.29","code":"\nnnyfs %>%\n    group_by(bmi_cat) %>%\n    summarise(mean = mean(waist), sd = sd(waist), \n              median = median(waist), \n              skew_1 = round((mean(waist) - median(waist)) / \n                                 sd(waist),2))# A tibble: 5 x 5\n  bmi_cat        mean    sd median skew_1\n  <fct>         <dbl> <dbl>  <dbl>  <dbl>\n1 1_Underweight  55.2  7.58   54.5   0.09\n2 2_Normal       NA   NA      NA    NA   \n3 3_Overweight   72.3 11.9    74    -0.14\n4 4_Obese        NA   NA      NA    NA   \n5 <NA>           NA   NA      NA    NA   \nnnyfs %>%\n    filter(complete.cases(bmi_cat, waist)) %>%\n    group_by(bmi_cat) %>%\n    summarise(count = n(), mean = mean(waist), \n              sd = sd(waist), median = median(waist), \n       skew_1 = \n         round((mean(waist) - median(waist)) / sd(waist),2))# A tibble: 4 x 6\n  bmi_cat       count  mean    sd median skew_1\n  <fct>         <int> <dbl> <dbl>  <dbl>  <dbl>\n1 1_Underweight    41  55.2  7.58   54.5   0.09\n2 2_Normal        917  61.2  9.35   59.5   0.19\n3 3_Overweight    258  72.3 11.9    74    -0.14\n4 4_Obese         294  85.6 17.1    86.8  -0.07\nmosaic::favstats(waist ~ bmi_cat, data = nnyfs) %>%\n    kable(digits = 1)\nnnyfs %>%\n    filter(complete.cases(bmi_cat, waist)) %>%\n    ggplot(., aes(x = bmi_cat, y = waist)) +\n    geom_violin() +\n    geom_boxplot(aes(fill = bmi_cat), width = 0.2) +\n    theme_light() + \n    scale_fill_viridis_d() +\n    guides(fill = \"none\") +\n    labs(title = \"Waist Circumference by BMI Category\")"},{"path":"NYFS-Study.html","id":"boxplots-to-relate-an-outcome-to-a-categorical-predictor","chapter":"9 National Youth Fitness Survey","heading":"9.16 Boxplots to Relate an Outcome to a Categorical Predictor","text":"Boxplots much useful comparing samples data. instance, consider comparison boxplot describing triceps skinfold results across four levels BMI category., probably want omit missing values (bmi_cat triceps_skinfold) also eliminate repetitive legend (guides) right.always, boxplot shows five-number summary (minimum, 25th percentile, median, 75th percentile maximum) addition highlighting candidate outliers.","code":"\nggplot(nnyfs, aes(x = bmi_cat, y = triceps_skinfold,\n                  fill = bmi_cat)) +\n    geom_boxplot() +\n    scale_fill_viridis_d() +\n    theme_light()Warning: Removed 21 rows containing non-finite values\n(stat_boxplot).\nnnyfs %>% \n    filter(complete.cases(bmi_cat, triceps_skinfold)) %>%\n    ggplot(., aes(x = bmi_cat, y = triceps_skinfold,\n                  fill = bmi_cat)) +\n    geom_boxplot() +\n    scale_fill_viridis_d() +\n    guides(fill = \"none\") +\n    theme_light() +\n    labs(x = \"BMI Category\", y = \"Triceps Skinfold in mm\",\n         title = \"Triceps Skinfold increases with BMI category\",\n         subtitle = \"NNYFS children\")"},{"path":"NYFS-Study.html","id":"augmenting-the-boxplot-with-the-sample-mean","chapter":"9 National Youth Fitness Survey","heading":"9.16.1 Augmenting the Boxplot with the Sample Mean","text":"Often, want augment plot, perhaps adding little diamond show sample mean within category, highlight skew (terms whether mean meaningfully different median.)","code":"\nnnyfs %>% \n    filter(complete.cases(bmi_cat, triceps_skinfold)) %>%\n    ggplot(., aes(x = bmi_cat, y = triceps_skinfold,\n                  fill = bmi_cat)) +\n    geom_boxplot() +\n    stat_summary(fun=\"mean\", geom=\"point\", \n                 shape=23, size=3, fill=\"white\") +\n    scale_fill_viridis_d() +\n    guides(fill = \"none\") +\n    theme_light() +\n    labs(x = \"BMI Category\", y = \"Triceps Skinfold in mm\",\n         title = \"Triceps Skinfold increases with BMI category\",\n         subtitle = \"NNYFS children\")"},{"path":"NYFS-Study.html","id":"building-a-violin-plot","chapter":"9 National Youth Fitness Survey","heading":"9.17 Building a Violin Plot","text":"number plots compare distributions data sets. interesting one called violin plot. violin plot kernel density estimate, mirrored form symmetrical shape.Traditionally, plots shown overlaid boxplots white dot median, like example, now looking waist circumference .","code":"\nnnyfs %>%\n    filter(complete.cases(triceps_skinfold, bmi_cat)) %>%\n    ggplot(., aes(x=bmi_cat, y=triceps_skinfold, \n                  fill = bmi_cat)) + \n    geom_violin(trim=FALSE) +\n    scale_fill_viridis_d() +\n    guides(fill = \"none\") +\n    labs(title = \"Triceps Skinfold by BMI Category\")\nnnyfs %>%\n    filter(complete.cases(waist, bmi_cat)) %>%\n    ggplot(., aes(x = bmi_cat, y = waist, \n                  fill = bmi_cat)) + \n    geom_violin(trim=FALSE) +\n    geom_boxplot(width=.1, outlier.colour=NA, \n                 color = c(rep(\"white\",2), rep(\"black\",2))) +\n    stat_summary(fun=median, geom=\"point\", \n                 fill=\"white\", shape=21, size=3) + \n    scale_fill_viridis_d() +\n    guides(fill = \"none\") +\n    labs(title = \"Waist Circumference by BMI Category\")"},{"path":"NYFS-Study.html","id":"adding-notches-to-a-boxplot","chapter":"9 National Youth Fitness Survey","heading":"9.17.1 Adding Notches to a Boxplot","text":"Notches used boxplots help visually assess whether medians distributions across various groups actually differ statistically detectable extent. Think confidence regions around medians. notches overlap, situation, provides evidence medians populations represented samples may different.overlap notches four categories, might reasonably conclude true median triceps skinfold values across four categories statistically significantly different.example notches overlap, consider comparison plank times BMI category.overlap notches (instance Underweight Normal) suggests median plank times population interest don’t necessarily differ meaningful way BMI category, perhaps Obese group may shorter time.data somewhat right skewed. logarithmic transformation plot help us see patterns clearly?","code":"\nnnyfs %>% \n    filter(complete.cases(bmi_cat, triceps_skinfold)) %>%\n    ggplot(., aes(x = bmi_cat, y = triceps_skinfold)) +\n    geom_violin() +\n    geom_boxplot(aes(fill = bmi_cat), width = 0.3, notch = TRUE) +\n    scale_fill_viridis_d() +\n    guides(fill = \"none\") +\n    theme_light() +\n    labs(x = \"BMI Category\", y = \"Triceps Skinfold in mm\",\n         title = \"Triceps Skinfold increases with BMI category\",\n         subtitle = \"NNYFS children\")\nnnyfs %>% \n    filter(complete.cases(bmi_cat, plank_time)) %>%\n    ggplot(., aes(x=bmi_cat, y=plank_time)) +\n    geom_violin(aes(fill = bmi_cat)) +\n    geom_boxplot(width = 0.3, notch=TRUE) +\n    scale_fill_viridis_d() +\n    guides(fill = \"none\") + \n    theme_light() +\n    labs(title = \"Plank Times by BMI category\", \n         x = \"\", y = \"Plank Time (in seconds)\")\nnnyfs %>% \n    filter(complete.cases(bmi_cat, plank_time)) %>%\n    ggplot(., aes(x=bmi_cat, y = log(plank_time))) +\n    geom_violin() +\n    geom_boxplot(aes(fill = bmi_cat), width = 0.3, notch=TRUE) +\n    scale_fill_viridis_d() +\n    guides(fill = \"none\") + \n    theme_light() +\n    labs(title = \"log(Plank Times) by BMI category\", \n         x = \"\", y = \"Natural Log of Plank Time\")"},{"path":"NYFS-Study.html","id":"using-multiple-histograms-to-make-comparisons","chapter":"9 National Youth Fitness Survey","heading":"9.18 Using Multiple Histograms to Make Comparisons","text":"can make array histograms describe multiple groups data, using ggplot2 notion faceting plot.","code":"\nnnyfs %>% \n    filter(complete.cases(triceps_skinfold, bmi_cat)) %>%\n    ggplot(., aes(x=triceps_skinfold, fill = bmi_cat)) +\n    geom_histogram(binwidth = 2, color = \"black\") + \n    facet_wrap(~ bmi_cat) +\n    scale_fill_viridis_d() +\n    guides(fill = \"none\") +\n    labs(title = \"Triceps Skinfold by BMI Category\")"},{"path":"NYFS-Study.html","id":"using-multiple-density-plots-to-make-comparisons","chapter":"9 National Youth Fitness Survey","heading":"9.19 Using Multiple Density Plots to Make Comparisons","text":", can make series density plots describe multiple groups data., can plot densities top semi-transparent fills.really works better comparing two groups, like females males.","code":"\nnnyfs %>% \n    filter(complete.cases(triceps_skinfold, bmi_cat)) %>%\n    ggplot(., aes(x=triceps_skinfold, fill = bmi_cat)) +\n    geom_density(color = \"black\") + \n    facet_wrap(~ bmi_cat) +\n    scale_fill_viridis_d() +\n    guides(fill = \"none\") +\n    labs(title = \"Triceps Skinfold by BMI Category\")\nnnyfs %>% \n    filter(complete.cases(triceps_skinfold, bmi_cat)) %>%\n    ggplot(., aes(x=triceps_skinfold, fill = bmi_cat)) +\n    geom_density(alpha=0.3) + \n    scale_fill_viridis_d() + \n    labs(title = \"Triceps Skinfold by BMI Category\")\nnnyfs %>% \n    filter(complete.cases(triceps_skinfold, sex)) %>%\n    ggplot(., aes(x=triceps_skinfold, fill = sex)) +\n    geom_density(alpha=0.5) + \n    labs(title = \"Triceps Skinfold by Sex\")"},{"path":"NYFS-Study.html","id":"a-ridgeline-plot","chapter":"9 National Youth Fitness Survey","heading":"9.20 A Ridgeline Plot","text":"people don’t like violin plots - example, see https://simplystatistics.org/2017/07/13/-joy----violin-plots/. alternative plot available part ggridges package. shows distribution several groups simultaneously, especially lots subgroup categories, called ridgeline plot.’s ridgeline plot triceps skinfolds. ’ll start sorting subgroups median value outcome (triceps skinfold) case, though turns matter. ’ll also add color.one last example, ’ll look age BMI category, sorting BMI subgroups median matters, ’ll try alternate color scheme, theme specially designed ridgeline plot.","code":"\nnnyfs %>% \n    filter(complete.cases(waist, bmi_cat)) %>%\n    ggplot(., aes(x = waist, y = bmi_cat, height = ..density..)) +\n    ggridges::geom_density_ridges(scale = 0.85) + \n    theme_light() +\n    labs(title = \"Ridgeline Plot of Waist Circumference by BMI category (nnyfs)\",\n         x = \"Waist Circumference\", y = \"BMI Category\")Picking joint bandwidth of 3.47\nnnyfs %>%\n    filter(complete.cases(bmi_cat, triceps_skinfold)) %>%\n    mutate(bmi_cat = fct_reorder(bmi_cat,\n                                 triceps_skinfold, \n                                 .fun = median)) %>%\n    ggplot(., aes(x = triceps_skinfold, y = bmi_cat, \n                  fill = bmi_cat, height = ..density..)) +\n    ggridges::geom_density_ridges(scale = 0.85) + \n    scale_fill_viridis_d(option = \"magma\") +\n    guides(fill = \"none\") +\n    labs(title = \"Ridgeline Plot of Triceps Skinfold by BMI Category (nnyfs)\",\n         x = \"Triceps Skinfold\", y = \"BMI Category\") +\n    theme_light()Picking joint bandwidth of 1.37\nnnyfs %>%\n    filter(complete.cases(bmi_cat, age_child)) %>%\n    mutate(bmi_cat = reorder(bmi_cat, age_child, median)) %>%\n    ggplot(aes(x = age_child, y = bmi_cat, fill = bmi_cat, height = ..density..)) +\n    ggridges::geom_density_ridges(scale = 0.85) + \n    scale_fill_brewer(palette = \"YlOrRd\") +\n    guides(fill = \"none\") +\n    labs(title = \"Ridgeline Plot of Age at Exam by BMI category (nnyfs)\",\n         x = \"Age of Child at Exam\", y = \"BMI Category\") +\n    ggridges::theme_ridges()Picking joint bandwidth of 1.15"},{"path":"NYFS-Study.html","id":"what-summaries-to-report","chapter":"9 National Youth Fitness Survey","heading":"9.21 What Summaries to Report","text":"usually helpful focus shape, center spread distribution. Bock, Velleman DeVeaux provide useful advice:data skewed, report median IQR (three middle quantiles). may want include mean standard deviation, point mean median differ. fact mean median agree sign distribution may skewed. histogram help make point.data symmetric, report mean standard deviation, possibly median IQR well.clear outliers reporting mean standard deviation, report outliers present outliers removed. differences may revealing. median IQR likely seriously affected outliers.","code":""},{"path":"assessing-normality.html","id":"assessing-normality","chapter":"10 Assessing Normality","heading":"10 Assessing Normality","text":"Data well approximated Normal distribution shape data’s distribution good match Normal distribution mean standard deviation equal sample statistics.data symmetrically distributed single peak, located sample meanthe spread distribution well characterized Normal distribution standard deviation equal sample standard deviationthe data show outlying values (number candidate outliers, size distance outliers center distribution) similar predicted Normal model.several tools assessing Normality single batch data, including:histogram superimposed Normal distributionhistogram variants (like boxplot) provide information center, spread shape distributionthe Empirical Rule interpretation standard deviationa specialized normal Q-Q plot (also called normal probability plot normal quantile-quantile plot) designed reveal differences sample distribution might expect normal distribution similar number values mean standard deviation","code":""},{"path":"assessing-normality.html","id":"empirical-rule-interpretation-of-the-standard-deviation","chapter":"10 Assessing Normality","heading":"10.1 Empirical Rule Interpretation of the Standard Deviation","text":"set measurements follows Normal distribution, interval:Mean \\(\\pm\\) Standard Deviation contains approximately 68% measurements;Mean \\(\\pm\\) 2(Standard Deviation) contains approximately 95% measurements;Mean \\(\\pm\\) 3(Standard Deviation) contains approximately (99.7%) measurements., data sets follow Normal distribution. occasionally think transforming re-expressing data obtain results better approximated Normal distribution, part standard deviation can meaningful.energy data studying, summary statistics…mean 1877 standard deviation 722, data really Normally distributed, ’d expect see:68% data range (1155, 2600). fact, 1085 1518 energy values range, 71.5%.95% data range (432, 3322). fact, 1450 1518 energy values range, 95.5%.99.7% data range (-290, 4044). fact, 1502 1518 energy values range, 98.9%., based Empirical Rule approximation, energy data seem well approximated Normal distribution?","code":"\nnnyfs <- read_rds(\"data/nnyfs.Rds\")\nmosaic::favstats(nnyfs$energy) min     Q1 median   Q3  max     mean       sd    n missing\n 257 1367.5 1794.5 2306 5265 1877.157 722.3537 1518       0"},{"path":"assessing-normality.html","id":"describing-outlying-values-with-z-scores","chapter":"10 Assessing Normality","heading":"10.2 Describing Outlying Values with Z Scores","text":"maximum energy consumption value 5265. One way gauge extreme (much outlier ) uses observation’s Z score, number standard deviations away mean observation falls., maximum value, 5265 4.69 standard deviations mean, thus Z score 4.7.negative Z score indicate point mean, positive Z score indicates, ’ve seen, point mean. minimum body-mass index, 257 2.24 standard deviations mean, Z score -2.2.Recall Empirical Rule suggests variable follows Normal distribution, approximately 95% observations falling inside Z score (-2, 2), 99.74% falling inside Z score range (-3, 3).","code":""},{"path":"assessing-normality.html","id":"fences-and-z-scores","chapter":"10 Assessing Normality","heading":"10.2.1 Fences and Z Scores","text":"Note relationship fences (Tukey’s approach identifying points fall within whiskers boxplot, compared candidate outliers) Z scores.upper inner fence case falls 3713.75, indicates Z score 2.5, lower inner fence falls -40.25, indicates Z score -2.7. neither unusual inevitable inner fences fall Z scores near -2.0 +2.0.","code":""},{"path":"assessing-normality.html","id":"comparing-a-histogram-to-a-normal-distribution","chapter":"10 Assessing Normality","heading":"10.3 Comparing a Histogram to a Normal Distribution","text":"time, want understand whether data well approximated Normal distribution, use graph aid decision.One option build histogram Normal density function (mean standard deviation data) superimposed. one way help visualize deviations data might expected Normal distribution.seem though Normal model (shown blue density curve) effective approximation observed distribution shown bars histogram?’ll return shortly questions:Normal distribution model fit data well? andIf data aren’t Normal, want use Normal model anyway, ?","code":"\nres <- mosaic::favstats(~ energy, data = nnyfs)\nbin_w <- 50 # specify binwidth\n\nggplot(nnyfs, aes(x=energy)) +\n    geom_histogram(aes(y = ..density..), binwidth = bin_w, \n                   fill = \"papayawhip\", color = \"seagreen\") +\n    stat_function(fun = dnorm, \n                  args = list(mean = res$mean, sd = res$sd), \n                  lwd = 1.5, col = \"blue\") +\n    geom_text(aes(label = paste(\"Mean\", round(res$mean,1), \n                                \", SD\", round(res$sd,1))),\n              x = 4000, y = 0.0006, \n              color=\"blue\", fontface = \"italic\") + \n    labs(title = \"nnyfs energy values with Normal Density Superimposed\", \n         x = \"Energy (kcal)\", y = \"Probability Density Function\")"},{"path":"assessing-normality.html","id":"histogram-of-energy-with-normal-model-with-counts","chapter":"10 Assessing Normality","heading":"10.3.1 Histogram of energy with Normal model (with Counts)","text":"first, ’ll demonstrate approach building histogram counts (rather probability density) superimposing Normal model.","code":"\nres <- mosaic::favstats(~ energy, data = nnyfs)\nbin_w <- 50 # specify binwidth\n\nggplot(nnyfs, aes(x = energy)) +\n  geom_histogram(binwidth = bin_w, \n                 fill = \"papayawhip\", \n                 col = \"navy\") +\n  theme_bw() +\n  stat_function(\n    fun = function(x) dnorm(x, mean = res$mean, \n                            sd = res$sd) * res$n * bin_w,\n    col = \"blue\", size = 2) +\n    geom_text(aes(label = paste(\"Mean\", round(res$mean,1), \n                                \", SD\", round(res$sd,1))),\n              x = 4000, y = 50, \n              color=\"blue\", fontface = \"italic\") + \n    labs(title = \"Histogram of energy, with Normal Model\", \n         x = \"Energy consumed (kcal)\", y = \"# of subjects\")"},{"path":"assessing-normality.html","id":"does-a-normal-model-work-well-for-the-waist-circumference","chapter":"10 Assessing Normality","heading":"10.4 Does a Normal model work well for the waist circumference?","text":"Now, suppose instead look waist data, remembering filter data complete cases plotting. data appear follow Normal distribution?mean 67.71 standard deviation 15.2 waist data really Normally distributed, ’d expect see:68% data range (52.51, 82.9). fact, 1076 1512 Age values range, 71.2%.68% data range (52.51, 82.9). fact, 1076 1512 Age values range, 71.2%.95% data range (37.31, 98.1). fact, 1443 1512 Age values range, 95.4%.95% data range (37.31, 98.1). fact, 1443 1512 Age values range, 95.4%.99.7% data range (22.11, 113.3). fact, 1500 1512 Age values range, 99.2%.99.7% data range (22.11, 113.3). fact, 1500 1512 Age values range, 99.2%.Normal approximation work waist circumference, according Empirical Rule?","code":"\nres <- mosaic::favstats(~ waist, data = nnyfs)\nbin_w <- 5 # specify binwidth\n\nnnyfs %>% filter(complete.cases(waist)) %>%\n    ggplot(., aes(x = waist)) +\n    geom_histogram(binwidth = bin_w, \n                   fill = \"antiquewhite\", \n                   col = \"navy\") +\n    theme_bw() +\n    stat_function(\n        fun = function(x) dnorm(x, mean = res$mean, \n                                sd = res$sd) * \n            res$n * bin_w,\n        col = \"darkred\", size = 2) +\n    geom_text(aes(label = paste(\"Mean\", round(res$mean,1), \n                                \", SD\", round(res$sd,1))),\n              x = 100, y = 200, \n              color=\"darkred\", fontface = \"italic\") + \n    labs(title = \"Histogram of waist, with Normal Model\", \n         x = \"Waist Circumference (cm)\", y = \"# of subjects\")\nmosaic::favstats(~ waist, data = nnyfs)  min   Q1 median   Q3   max     mean       sd    n missing\n 42.5 55.6   64.8 76.6 144.7 67.70536 15.19809 1512       6"},{"path":"assessing-normality.html","id":"the-normal-q-q-plot","chapter":"10 Assessing Normality","heading":"10.5 The Normal Q-Q Plot","text":"normal probability plot (normal quantile-quantile plot) energy results nnyfs data, developed using ggplot2 shown . case, picture 1518 energy consumption assessments. idea normal Q-Q plot plots observed sample values (vertical axis) , horizontal, expected theoretical quantiles observed standard normal distribution (Normal distribution mean 0 standard deviation 1) number observations.Normal Q-Q plot follow straight line data (approximately) Normally distributed. data different shape, plot reflect .","code":"\nggplot(nnyfs, aes(sample = energy)) +\n    geom_qq() + geom_qq_line(col = \"red\") +\n    theme_light() +\n    labs(title = \"Normal Q-Q plot for energy data\")"},{"path":"assessing-normality.html","id":"interpreting-the-normal-q-q-plot","chapter":"10 Assessing Normality","heading":"10.6 Interpreting the Normal Q-Q Plot","text":"purpose Normal Q-Q plot help point distinctions Normal distribution. Normal distribution symmetric certain expectations regarding tails. Normal Q-Q plot can help us identify data well approximated Normal distribution, , :skew (including distinguishing right skew left skew)behavior tails (heavy-tailed [outliers expected] light-tailed)","code":""},{"path":"assessing-normality.html","id":"data-from-a-normal-distribution-shows-up-as-a-straight-line-in-a-normal-q-q-plot","chapter":"10 Assessing Normality","heading":"10.6.1 Data from a Normal distribution shows up as a straight line in a Normal Q-Q plot","text":"’ll demonstrate looks can obtain Normal Q-Q plot simulations. First, example Normal Q-Q plot, associated histogram, sample 200 observations simulated Normal distribution.simulated data appear well-modeled Normal distribution, points Normal Q-Q plot follow diagonal reference line. particular,substantial curve (’d see data skewed)particularly surprising behavior (curves away line) either tail, ’s obvious problem outliers","code":"\nset.seed(123431) # so the results can be replicated\n                                          \n# simulate 200 observations from a Normal(20, 5) distribution and place them \n# in the d variable within the temp.1 data frame\ntemp.1 <- data.frame(d = rnorm(200, mean = 20, sd = 5)) \n                                          \n# left plot - basic Normal Q-Q plot of simulated data\np1 <- ggplot(temp.1, aes(sample = d)) +\n    geom_qq() + geom_qq_line(col = \"red\") +\n    theme_light() +\n    labs(y = \"Ordered Simulated Sample Data\")\n\n# right plot - histogram with superimposed normal distribution\nres <- mosaic::favstats(~ d, data = temp.1)\nbin_w <- 2 # specify binwidth\n\np2 <- ggplot(temp.1, aes(x = d)) +\n    geom_histogram(binwidth = bin_w, \n                   fill = \"papayawhip\", \n                   col = \"seagreen\") +\n    theme_bw() +\n    stat_function(\n        fun = function(x) dnorm(x, mean = res$mean, \n                                sd = res$sd) * \n            res$n * bin_w,\n        col = \"blue\", size = 1.5) +\n    geom_text(aes(label = paste(\"Mean\", round(res$mean,1), \n                                \", SD\", round(res$sd,1))),\n              x = 25, y = 35, \n              color=\"blue\", fontface = \"italic\") + \n    labs(x = \"Simulated Sample Data\", y = \"\")\n\np1 + p2 + \n  plot_annotation(title = \"200 observations from a simulated Normal distribution\") \n# uses patchwork package to combine plots"},{"path":"assessing-normality.html","id":"skew-is-indicated-by-monotonic-curves-in-the-normal-q-q-plot","chapter":"10 Assessing Normality","heading":"10.6.2 Skew is indicated by monotonic curves in the Normal Q-Q plot","text":"Data come skewed distribution appear curve away straight line Q-Q plot.Note bends away straight line sample. non-Normality may easier see histogram.","code":"\nset.seed(123431) # so the results can be replicated\n\n# simulate 200 observations from a beta(5, 2) distribution into the e1 variable\n# simulate 200 observations from a beta(1, 5) distribution into the e2 variable\ntemp.2 <- data.frame(e1 = rbeta(200, 5, 2), e2 = rbeta(200, 1, 5)) \n\np1 <- ggplot(temp.2, aes(sample = e1)) +\n    geom_qq(col = \"orchid\") + geom_qq_line(col = \"blue\") +\n    theme_light() +\n    labs(y = \"Ordered Sample e1\",\n         title = \"Beta(5, 2) sample: Left Skewed\")\n\np2 <- ggplot(temp.2, aes(sample = e2)) +\n    geom_qq(col = \"darkorange\") + geom_qq_line(col = \"blue\") +\n    theme_light() +\n    labs(y = \"Ordered Sample e2\",\n         title = \"Beta(1, 5) sample: Right Skewed\")\n\np1 + p2 + plot_annotation(title = \"200 observations from simulated Beta distributions\")\nres1 <- mosaic::favstats(~ e1, data = temp.2)\nbin_w1 <- 0.025 # specify binwidth\n\np1 <- ggplot(temp.2, aes(x = e1)) +\n    geom_histogram(binwidth = bin_w1, \n                   fill = \"orchid\", \n                   col = \"black\") +\n    theme_bw() +\n    stat_function(\n        fun = function(x) dnorm(x, mean = res1$mean, \n                                sd = res1$sd) * \n            res1$n * bin_w1,\n        col = \"blue\", size = 1.5) +\nlabs(x = \"Sample e1\", y = \"\",\n     title = \"Beta(5,2) sample: Left Skew\")\n\nres2 <- mosaic::favstats(~ e2, data = temp.2)\nbin_w2 <- 0.025 # specify binwidth\n\np2 <- ggplot(temp.2, aes(x = e2)) +\n    geom_histogram(binwidth = bin_w2, \n                   fill = \"darkorange\", \n                   col = \"black\") +\n    theme_bw() +\n    stat_function(\n        fun = function(x) dnorm(x, mean = res2$mean, \n                                sd = res2$sd) * \n            res2$n * bin_w2,\n        col = \"blue\", size = 1.5) +\nlabs(x = \"Sample e1\", y = \"\",\n     title = \"Beta(1,5) sample: Right Skew\")\n\np1 + p2 + plot_annotation(caption = \"Histograms with Normal curve superimposed\")"},{"path":"assessing-normality.html","id":"direction-of-skew","chapter":"10 Assessing Normality","heading":"10.6.3 Direction of Skew","text":"pairs plots, see basic result.left plot (data e1) shows left skew, longer tail left hand side clustered data right end distribution.right plot (data e2) shows right skew, longer tail right hand side, mean larger median, clustered data left end distribution.","code":""},{"path":"assessing-normality.html","id":"outlier-proneness-is-indicated-by-s-shaped-curves-in-a-normal-q-q-plot","chapter":"10 Assessing Normality","heading":"10.6.4 Outlier-proneness is indicated by “s-shaped” curves in a Normal Q-Q plot","text":"Heavy-tailed symmetric distributions indicated reverse “S”-shapes, shown left .Light-tailed symmetric distributions indicated “S” shapes plot, shown right ., can also visualize simulations histograms, although ’re less helpful understanding tail behavior skew.Instead, boxplots (augmented violin plots) can helpful thinking light-tailed vs. heavy-tailed distributions.","code":"\nset.seed(4311) # so the results can be replicated\n\n# sample 200 observations from each of two probability distributions\ntemp.3 <- data.frame(s1 = rcauchy(200, location=10, scale = 1),\n                     s2 = runif(200, -30, 30)) \n\np1 <- ggplot(temp.3, aes(sample = s1)) +\n    geom_qq(col = \"slateblue\") + geom_qq_line(col = \"black\") +\n    theme_light() +\n    labs(y = \"Ordered Sample s1\",\n         title = \"Heavy-Tailed Symmetric Sample s1\")\n\np2 <- ggplot(temp.3, aes(sample = s2)) +\n    geom_qq(col = \"dodgerblue\") + geom_qq_line(col = \"black\") +\n    theme_light() +\n    labs(y = \"Ordered Sample s2\",\n         title = \"Light-Tailed Symmetric Sample s2\")\n\np1 + p2 + plot_annotation(title = \"200 observations from simulated distributions\")\nres1 <- mosaic::favstats(~ s1, data = temp.3)\nbin_w1 <- 20 # specify binwidth\n\np1 <- ggplot(temp.3, aes(x = s1)) +\n    geom_histogram(binwidth = bin_w1, \n                   fill = \"slateblue\", \n                   col = \"white\") +\n    theme_bw() +\n    stat_function(\n        fun = function(x) dnorm(x, mean = res1$mean, \n                                sd = res1$sd) * \n            res1$n * bin_w1,\n        col = \"blue\") +\nlabs(x = \"Sample s1\", y = \"\",\n     title = \"Cauchy sample: Heavy Tails\")\n\nres2 <- mosaic::favstats(~ s2, data = temp.3)\nbin_w2 <- 2 # specify binwidth\n\np2 <- ggplot(temp.3, aes(x = s2)) +\n    geom_histogram(binwidth = bin_w2, \n                   fill = \"dodgerblue\", \n                   col = \"white\") +\n    theme_bw() +\n    stat_function(\n        fun = function(x) dnorm(x, mean = res2$mean, \n                                sd = res2$sd) * \n            res2$n * bin_w2,\n        col = \"blue\") +\nlabs(x = \"Sample s2\", y = \"\",\n     title = \"Uniform sample: Light Tails\")\n\np1 + p2 + plot_annotation(caption = \"Histograms with Normal curve superimposed\")\np1 <- ggplot(temp.3, aes(x = \"s1\", y = s1)) +\n    geom_violin(col = \"slateblue\") + \n    geom_boxplot(fill = \"slateblue\", width = 0.2) +\n    theme_light() +\n    coord_flip() +\n    labs(y = \"Ordered Sample s1\", x = \"\",\n         title = \"Heavy-Tailed Symmetric Sample s1\")\n\np2 <- ggplot(temp.3, aes(x = \"s2\", y = s2)) +\n    geom_violin(col = \"dodgerblue\") + \n    geom_boxplot(fill = \"dodgerblue\", width = 0.2) +\n    theme_light() +\n    coord_flip() +\n    labs(y = \"Ordered Sample s2\", x = \"\",\n         title = \"Light-Tailed Symmetric Sample s2\")\n\np1 + p2 + plot_annotation(title = \"200 observations from simulated distributions\")\nrm(temp.1, temp.2, temp.3, p1, p2, res, res1, res2, bin_w, bin_w1, bin_w2) # cleaning up"},{"path":"assessing-normality.html","id":"can-a-normal-distribution-fit-the-nnyfs-energy-data-well","chapter":"10 Assessing Normality","heading":"10.7 Can a Normal Distribution Fit the nnyfs energy data Well?","text":"energy data ’ve studying shows meaningful signs right skew.Skewness indicated curve Normal Q-Q plot. Curving away line tails suggests right skew, histogram.plotted original energy values (positive) instead plotted square roots energy values?Compare two plots - left describes distribution original energy data NNYFS data frame, right plot shows distribution square root values.left plot shows substantial right positive skewThe right plot shows ’s much less skew square root taken.conclusion Normal model far better fit square root energy values raw energy values.effect taking square root may clearer histograms , Normal models superimposed.confronted variable Normally distributed wish Normally distributed, sometimes useful consider whether working transformation data yield helpful result, square root instance.rest Chapter provides guidance choosing class power transformations can reduce impact non-Normality unimodal data.confronted variable Normally distributed wish Normally distributed, sometimes useful consider whether working transformation data yield helpful result.Many statistical methods, including t tests analyses variance, assume Normal distributions.’ll discuss using R assess range called Box-Cox power transformations, via plots, mainly.","code":"\np1 <- ggplot(nnyfs, aes(sample = energy)) +\n    geom_qq(col = \"coral\", size = 2) + \n    geom_qq_line(col = \"blue\") +\n    theme_light() +\n    labs(title = \"Energy Consumed\",\n         y = \"Sorted Energy data\")\n\nres <- mosaic::favstats(~ energy, data = nnyfs)\nbin_w <- 250 # specify binwidth\n\np2 <- ggplot(nnyfs, aes(x = energy)) +\n    geom_histogram(binwidth = bin_w, \n                   fill = \"coral\", \n                   col = \"white\") +\n    theme_bw() +\n    stat_function(\n        fun = function(x) dnorm(x, mean = res$mean, \n                                sd = res$sd) * \n            res$n * bin_w,\n        col = \"blue\", size = 1.5) +\nlabs(x = \"Energy (kcal consumed)\", y = \"\",\n     title = \"Energy Consumed\")\n\n\n\np1 + p2\np1 <- ggplot(nnyfs, aes(sample = energy)) +\n    geom_qq(col = \"coral\", size = 2) + \n    geom_qq_line(col = \"blue\") +\n    theme_light() +\n    labs(title = \"Energy Consumed\",\n         y = \"Sorted Energy data\")\n\np2 <- ggplot(nnyfs, aes(sample = sqrt(energy))) +\n    geom_qq(col = \"darkcyan\", size = 2) + \n    geom_qq_line(col = \"blue\") +\n    theme_light() +\n    labs(title = \"Square Root of Energy\",\n         y = \"Sorted Square Root of Energy\")\n\np1 + p2\nres <- mosaic::favstats(~ energy, data = nnyfs)\nbin_w <- 250 # specify binwidth\n\np1 <- ggplot(nnyfs, aes(x = energy)) +\n    geom_histogram(binwidth = bin_w, \n                   fill = \"coral\", \n                   col = \"white\") +\n    theme_bw() +\n    stat_function(\n        fun = function(x) dnorm(x, mean = res$mean, \n                                sd = res$sd) * \n            res$n * bin_w,\n        col = \"black\", size = 1.5) +\nlabs(x = \"Energy (kcal consumed)\", y = \"\",\n     title = \"Energy Consumed\")\n\n\nres2 <- mosaic::favstats(~ sqrt(energy), data = nnyfs)\nbin_w2 <- 5 # specify binwidth\n\np2 <- ggplot(nnyfs, aes(x = sqrt(energy))) +\n    geom_histogram(binwidth = bin_w2, \n                   fill = \"darkcyan\", \n                   col = \"white\") +\n    theme_bw() +\n    stat_function(\n        fun = function(x) dnorm(x, mean = res2$mean, \n                                sd = res2$sd) * \n            res2$n * bin_w2,\n        col = \"black\", size = 1.5) +\nlabs(x = \"Square Root of Energy\", y = \"\",\n     title = \"Square Root of Energy\")\n\n\np1 + p2 + plot_annotation(title = \"Comparing energy to sqrt(energy)\")\nrm(p1, p2, bin_w, bin_w2, res, res2) # cleanup"},{"path":"assessing-normality.html","id":"the-ladder-of-power-transformations","chapter":"10 Assessing Normality","heading":"10.8 The Ladder of Power Transformations","text":"key notion re-expression single variable obtain distribution better approximated Normal re-expression outcome simple regression model ladder power transformations, applies unimodal data.","code":""},{"path":"assessing-normality.html","id":"using-the-ladder","chapter":"10 Assessing Normality","heading":"10.9 Using the Ladder","text":"move away identity function (power = 1) change shape general direction.instance, try logarithm, seems like much change, might try square root instead.Note ladder (like many things due John Tukey) uses logarithm “power zero” transformation rather constant, x0 actually .variable x can take negative values, might take different approach. x count something zero, often simply add 1 x transformation.ladder power transformations particularly helpful confronted data shows skew.handle right skew (mean exceeds median) usually apply powers 1.handle left skew (median exceeds mean) usually apply powers greater 1.common transformations square (power 2), square root (power 1/2), logarithm (power 0) inverse (power -1), usually restrict options practical work.","code":""},{"path":"assessing-normality.html","id":"protein-consumption-in-the-nnyfs-data","chapter":"10 Assessing Normality","heading":"10.10 Protein Consumption in the NNYFS data","text":"protein consumption (grams) results NNYFS data.key point see several signs meaningful right skew, ’ll want consider transformation might make Normal model plausible.","code":"\nmosaic::favstats(~ protein, data = nnyfs)  min    Q1 median     Q3    max     mean       sd    n\n 4.18 45.33 61.255 82.565 241.84 66.90148 30.96319 1518\n missing\n       0\np1 <- ggplot(nnyfs, aes(x = \"Protein\", y = protein)) +\n    geom_violin() +\n    geom_boxplot(width = 0.2, fill = \"salmon\", \n                 outlier.color = \"red\") +\n    \n    labs(title = \"NNYFS Protein consumption\",\n         x = \"\", y = \"Protein Consumption (g)\")\n\np2 <- ggplot(nnyfs, aes(sample = protein)) +\n    geom_qq(col = \"salmon\") + \n    geom_qq_line(col = \"black\") +\n    \n    labs(title = \"NNYFS Protein Consumption\",\n         y = \"Protein Consumption (g)\")\n\np1 + p2"},{"path":"assessing-normality.html","id":"using-patchwork-to-compose-plots","chapter":"10 Assessing Normality","heading":"10.10.1 Using patchwork to compose plots","text":"mentioned previously, feel slickest approach composing series plots placed together available patchwork package. ’s another example., patchwork package repository https://patchwork.data-imaginist.com/index.html lots nice examples work .","code":"\nres <- mosaic::favstats(~ protein, data = nnyfs)\nbin_w <- 5 # specify binwidth\n\np1 <- ggplot(nnyfs, aes(x = protein)) +\n    geom_histogram(binwidth = bin_w, \n                   fill = \"salmon\", \n                   col = \"white\") +\n    \n    stat_function(\n        fun = function(x) dnorm(x, mean = res$mean, \n                                sd = res$sd) * \n            res$n * bin_w,\n        col = \"darkred\", size = 2) +\n    labs(title = \"Histogram with Normal fit\", \n         x = \"Protein Consumption (g)\", y = \"# of subjects\")\n\n\np2 <- ggplot(nnyfs, aes(sample = protein)) +\n    geom_qq(col = \"salmon\") + \n    geom_qq_line(col = \"black\") +\n    \n    labs(title = \"Normal Q-Q plot\",\n         y = \"Protein Consumption (g)\")\n\np3 <- ggplot(nnyfs, aes(x = \"\", y = protein)) +\n    geom_violin() +\n    geom_boxplot(width = 0.2, fill = \"salmon\", \n                 outlier.color = \"red\") +\n    \n    coord_flip() +\n    labs(title = \"Boxplot with Violin\",\n         x = \"\", y = \"Protein Consumption (g)\")\n\np1 + p2 - p3 + plot_layout(ncol = 1, height = c(3, 1)) +\n    plot_annotation(title = \"NNYFS Protein Consumption\")"},{"path":"assessing-normality.html","id":"can-we-transform-the-protein-data","chapter":"10 Assessing Normality","heading":"10.11 Can we transform the protein data?","text":"’ve seen, protein data right skewed, values strictly positive. want use tools Normal distribution describe data, might try taking step “” ladder power 1 (raw data) lower powers.","code":""},{"path":"assessing-normality.html","id":"the-square-root","chapter":"10 Assessing Normality","heading":"10.11.1 The Square Root","text":"square root applied protein data help alleviate right skew?looks like symmetric distribution, certainly, although still outliers right side distribution. take another step ladder?","code":"\nres <- mosaic::favstats(~ sqrt(protein), data = nnyfs)\nbin_w <- 1 # specify binwidth\n\np1 <- ggplot(nnyfs, aes(x = sqrt(protein))) +\n    geom_histogram(binwidth = bin_w, \n                   fill = \"salmon\", \n                   col = \"white\") +\n    \n    stat_function(\n        fun = function(x) dnorm(x, mean = res$mean, \n                                sd = res$sd) * \n            res$n * bin_w,\n        col = \"darkred\", size = 2) +\n    labs(title = \"Histogram with Normal fit\", \n         x = \"Square Root of Protein Consumption (g)\", y = \"# of subjects\")\n\n\np2 <- ggplot(nnyfs, aes(sample = sqrt(protein))) +\n    geom_qq(col = \"salmon\") + \n    geom_qq_line(col = \"black\") +\n    \n    labs(title = \"Normal Q-Q plot\",\n         y = \"Square Root of Protein Consumption (g)\")\n\np3 <- ggplot(nnyfs, aes(x = \"\", y = sqrt(protein))) +\n    geom_violin() +\n    geom_boxplot(width = 0.2, fill = \"salmon\", \n                 outlier.color = \"red\") +\n    \n    coord_flip() +\n    labs(title = \"Boxplot with Violin\",\n         x = \"\", y = \"Square Root of Protein Consumption (g)\")\n\np1 + p2 - p3 + plot_layout(ncol = 1, height = c(3, 1)) +\n    plot_annotation(title = \"Square Root of NNYFS Protein Consumption\")"},{"path":"assessing-normality.html","id":"the-logarithm","chapter":"10 Assessing Normality","heading":"10.11.2 The Logarithm","text":"might also try logarithm energy circumference data. can use either natural logarithm (log, R) base-10 logarithm (log10, R) - either impact skew.Now, looks like may gone far direction. looks like square root sensible choice try improve fit Normal model protein consumption data.","code":"\nres <- mosaic::favstats(~ log(protein), data = nnyfs)\nbin_w <- 0.5 # specify binwidth\n\np1 <- ggplot(nnyfs, aes(x = log(protein))) +\n    geom_histogram(binwidth = bin_w, \n                   fill = \"salmon\", \n                   col = \"white\") +\n    stat_function(\n        fun = function(x) dnorm(x, mean = res$mean, \n                                sd = res$sd) * \n            res$n * bin_w,\n        col = \"darkred\", size = 2) +\n    labs(title = \"Histogram with Normal fit\", \n         x = \"Log of Protein Consumption (g)\", y = \"# of subjects\")\n\n\np2 <- ggplot(nnyfs, aes(sample = log(protein))) +\n    geom_qq(col = \"salmon\") + \n    geom_qq_line(col = \"black\") +\n    labs(title = \"Normal Q-Q plot\",\n         y = \"Log of Protein Consumption (g)\")\n\np3 <- ggplot(nnyfs, aes(x = \"\", y = log(protein))) +\n    geom_violin() +\n    geom_boxplot(width = 0.2, fill = \"salmon\", \n                 outlier.color = \"red\") +\n    coord_flip() +\n    labs(title = \"Boxplot with Violin\",\n         x = \"\", y = \"Log of Protein Consumption (g)\")\n\np1 + p2 - p3 + plot_layout(ncol = 1, height = c(3, 1)) +\n    plot_annotation(title = \"Logarithm of NNYFS Protein Consumption\")"},{"path":"assessing-normality.html","id":"this-course-uses-natural-logarithms-unless-otherwise-specified","chapter":"10 Assessing Normality","heading":"10.11.3 This course uses Natural Logarithms, unless otherwise specified","text":"course, assume use natural logarithms unless specify otherwise. Following R’s convention, use log natural logarithms.","code":""},{"path":"assessing-normality.html","id":"what-if-we-considered-all-9-available-transformations","chapter":"10 Assessing Normality","heading":"10.12 What if we considered all 9 available transformations?","text":"square root still appears best choice transformation , even consider 8 transformation raw data.","code":"\np1 <- ggplot(nnyfs, aes(sample = protein^3)) +\n    geom_qq(col = \"salmon\") + \n    geom_qq_line(col = \"black\") +\n    labs(title = \"Cube (power 3)\",\n         y = \"Protein, Cubed\")\n\np2 <- ggplot(nnyfs, aes(sample = protein^2)) +\n    geom_qq(col = \"salmon\") + \n    geom_qq_line(col = \"black\") +\n    labs(title = \"Square (power 2)\",\n         y = \"Protein, Squared\")\n\np3 <- ggplot(nnyfs, aes(sample = protein)) +\n    geom_qq(col = \"salmon\") + \n    geom_qq_line(col = \"black\") +\n    labs(title = \"Original Data\",\n         y = \"Protein (g)\")\n\n\np4 <- ggplot(nnyfs, aes(sample = sqrt(protein))) +\n    geom_qq(col = \"salmon\") + \n    geom_qq_line(col = \"black\") +\n    labs(title = \"sqrt (power 0.5)\",\n         y = \"Square Root of Protein\")\n\np5 <- ggplot(nnyfs, aes(sample = log(protein))) +\n    geom_qq(col = \"salmon\") + \n    geom_qq_line(col = \"black\") +\n    labs(title = \"log (power 0)\",\n         y = \"Natural Log of Protein\")\n\np6 <- ggplot(nnyfs, aes(sample = protein^(-0.5))) +\n    geom_qq(col = \"salmon\") + \n    geom_qq_line(col = \"black\") +\n    labs(title = \"1/sqrt (power -0.5)\",\n         y = \"1/Square Root(Protein)\")\n\n\np7 <- ggplot(nnyfs, aes(sample = 1/protein)) +\n    geom_qq(col = \"salmon\") + \n    geom_qq_line(col = \"black\") +\n    labs(title = \"Inverse (power -1)\",\n         y = \"1/Protein\")\n\np8 <- ggplot(nnyfs, aes(sample = 1/(protein^2))) +\n    geom_qq(col = \"salmon\") + \n    geom_qq_line(col = \"black\") +\n    labs(title = \"1/Square (power -2)\",\n         y = \"1 /(Protein squared)\")\n\np9 <- ggplot(nnyfs, aes(sample = 1/(protein^3))) +\n    geom_qq(col = \"salmon\") + \n    geom_qq_line(col = \"black\") +\n    labs(title = \"1/Cube (power -3)\",\n         y = \"1/(Protein cubed)\")\n\n\np1 + p2 + p3 + p4 + p5 + p6 + p7 + p8 + p9 +\n    plot_layout(nrow = 3) +\n    plot_annotation(title = \"Transformations of NNYFS Protein Consumption\")"},{"path":"assessing-normality.html","id":"a-simulated-data-set","chapter":"10 Assessing Normality","heading":"10.13 A Simulated Data Set","text":"’d like transform data better approximate Normal distribution, start? transformation suggest?Given left skew data, looks like step ladder warranted, perhaps looking square data?Looks like best modest improvement. cubing data, instead?newly transformed (cube ) data appears symmetric, although somewhat light-tailed. Perhaps Normal model appropriate now, although standard deviation likely overstate variation see data due light tails. , wouldn’t thrilled using cube practical work, hard interpret, look like reasonable choice .","code":"\nset.seed(431); \ndata2 <- \n    data_frame(sample2 = 100*rbeta(n = 125, shape1 = 5, shape2 = 2))Warning: `data_frame()` was deprecated in tibble 1.1.0.\nPlease use `tibble()` instead.\nThis warning is displayed once every 8 hours.\nCall `lifecycle::last_warnings()` to see where this warning was generated.\nres <- mosaic::favstats(~ sample2, data = data2)\nbin_w <- 4 # specify binwidth\n\np1 <- ggplot(data2, aes(x = sample2)) +\n    geom_histogram(binwidth = bin_w, \n                   fill = \"royalblue\", \n                   col = \"white\") +\n    stat_function(\n        fun = function(x) dnorm(x, mean = res$mean, \n                                sd = res$sd) * \n            res$n * bin_w,\n        col = \"darkred\", size = 2) +\n    labs(title = \"Histogram with Normal fit\", \n         x = \"Simulated Data\", y = \"# of subjects\")\n\n\np2 <- ggplot(data2, aes(sample = sample2)) +\n    geom_qq(col = \"royalblue\") + \n    geom_qq_line(col = \"black\") +\n    labs(title = \"Normal Q-Q plot\",\n         y = \"Simulated Data\")\n\np3 <- ggplot(data2, aes(x = \"\", y = sample2)) +\n    geom_violin() +\n    geom_boxplot(width = 0.3, fill = \"royalblue\", \n                 outlier.color = \"royalblue\") +\n    coord_flip() +\n    labs(title = \"Boxplot with Violin\",\n         x = \"\", y = \"Simulated Data\")\n\np1 + p2 - p3 + plot_layout(ncol = 1, height = c(3, 1)) +\n    plot_annotation(title = \"Simulated Data\")\nres <- mosaic::favstats(~ sample2^2, data = data2)\nbin_w <- 600 # specify binwidth\n\np1 <- ggplot(data2, aes(x = sample2^2)) +\n    geom_histogram(binwidth = bin_w, \n                   fill = \"royalblue\", \n                   col = \"white\") +\n    stat_function(\n        fun = function(x) dnorm(x, mean = res$mean, \n                                sd = res$sd) * \n            res$n * bin_w,\n        col = \"darkred\", size = 2) +\n    labs(title = \"Histogram with Normal fit\", \n         x = \"Squared Simulated Data\", y = \"# of subjects\")\n\n\np2 <- ggplot(data2, aes(sample = sample2^2)) +\n    geom_qq(col = \"royalblue\") + \n    geom_qq_line(col = \"black\") +\n    labs(title = \"Normal Q-Q plot\",\n         y = \"Squared Simulated Data\")\n\np3 <- ggplot(data2, aes(x = \"\", y = sample2^2)) +\n    geom_violin() +\n    geom_boxplot(width = 0.3, fill = \"royalblue\", \n                 outlier.color = \"royalblue\") +\n    coord_flip() +\n    labs(title = \"Boxplot with Violin\",\n         x = \"\", y = \"Squared Simulated Data\")\n\np1 + p2 - p3 + plot_layout(ncol = 1, height = c(3, 1)) +\n    plot_annotation(title = \"Squared Simulated Data\")\nres <- mosaic::favstats(~ sample2^3, data = data2)\nbin_w <- 100000 # specify binwidth\n\np1 <- ggplot(data2, aes(x = sample2^3)) +\n    geom_histogram(binwidth = bin_w, \n                   fill = \"royalblue\", \n                   col = \"white\") +\n    stat_function(\n        fun = function(x) dnorm(x, mean = res$mean, \n                                sd = res$sd) * \n            res$n * bin_w,\n        col = \"darkred\", size = 2) +\n    labs(title = \"Histogram with Normal fit\", \n         x = \"Cubed Simulated Data\", y = \"# of subjects\")\n\n\np2 <- ggplot(data2, aes(sample = sample2^3)) +\n    geom_qq(col = \"royalblue\") + \n    geom_qq_line(col = \"black\") +\n    labs(title = \"Normal Q-Q plot\",\n         y = \"Cubed Simulated Data\")\n\np3 <- ggplot(data2, aes(x = \"\", y = sample2^3)) +\n    geom_violin() +\n    geom_boxplot(width = 0.3, fill = \"royalblue\", \n                 outlier.color = \"royalblue\") +\n    coord_flip() +\n    labs(title = \"Boxplot with Violin\",\n         x = \"\", y = \"Cubed Simulated Data\")\n\np1 + p2 - p3 + plot_layout(ncol = 1, height = c(3, 1)) +\n    plot_annotation(title = \"Cubed Simulated Data\")"},{"path":"assessing-normality.html","id":"what-if-we-considered-all-9-available-transformations-1","chapter":"10 Assessing Normality","heading":"10.14 What if we considered all 9 available transformations?","text":", either cube square looks like best choice , terms creating symmetric (albeit light-tailed) distribution.","code":"\np1 <- ggplot(data2, aes(sample = sample2^3)) +\n    geom_qq(col = \"royalblue\") + \n    geom_qq_line(col = \"black\") +\n    labs(title = \"Cube (power 3)\")\n\np2 <- ggplot(data2, aes(sample = sample2^2)) +\n    geom_qq(col = \"royalblue\") + \n    geom_qq_line(col = \"black\") +\n    labs(title = \"Square (power 2)\")\n\np3 <- ggplot(data2, aes(sample = sample2)) +\n    geom_qq(col = \"royalblue\") + \n    geom_qq_line(col = \"black\") +\n    labs(title = \"Original Data\")\n\np4 <- ggplot(data2, aes(sample = sqrt(sample2))) +\n    geom_qq(col = \"royalblue\") + \n    geom_qq_line(col = \"black\") +\n    labs(title = \"sqrt (power 0.5)\")\n\np5 <- ggplot(data2, aes(sample = log(sample2))) +\n    geom_qq(col = \"royalblue\") + \n    geom_qq_line(col = \"black\") +\n    labs(title = \"log (power 0)\")\n\np6 <- ggplot(data2, aes(sample = sample2^(0.5))) +\n    geom_qq(col = \"royalblue\") + \n    geom_qq_line(col = \"black\") +\n    labs(title = \"1/sqrt (power -0.5)\")\n\np7 <- ggplot(data2, aes(sample = 1/sample2)) +\n    geom_qq(col = \"royalblue\") + \n    geom_qq_line(col = \"black\") +\n    labs(title = \"Inverse (power -1)\")\n\np8 <- ggplot(data2, aes(sample = 1/(sample2^2))) +\n    geom_qq(col = \"royalblue\") + \n    geom_qq_line(col = \"black\") +\n    labs(title = \"1/Square (power -2)\")\n\np9 <- ggplot(data2, aes(sample = 1/(sample2^3))) +\n    geom_qq(col = \"royalblue\") + \n    geom_qq_line(col = \"black\") +\n    labs(title = \"1/Cube (power -3)\")\n\np1 + p2 + p3 + p4 + p5 + p6 + p7 + p8 + p9 +\n    plot_layout(nrow = 3) +\n    plot_annotation(title = \"Transformations of Simulated Sample\")"},{"path":"straight-line-models.html","id":"straight-line-models","chapter":"11 Straight Line Models","heading":"11 Straight Line Models","text":"","code":""},{"path":"straight-line-models.html","id":"assessing-a-scatterplot","chapter":"11 Straight Line Models","heading":"11.1 Assessing A Scatterplot","text":"Let’s consider relationship protein fat consumption children nnyfs data.’ll begin investigation, always , drawing relevant picture. association two quantitative variables, scatterplot usually right start. subject nnyfs data represented one points . plot, ’ve also used geom_smooth add straight line regression model, ’ll discuss later., ’ve arbitrarily decided place fat vertical axis, protein horizontal. Fitting prediction model scatterplot require predict fat basis protein.case, pattern appears :direct, positive, values \\(x\\) variable (protein) increase, values \\(y\\) variable (fat). Essentially, appears subjects consumed protein also consumed fat, don’t know cause effect .fairly linear points cluster around appears pattern well-fitted straight line.moderately strong range values fat associated particular value protein fairly tight. know someone’s protein consumption, meaningfully improve ability predict fat consumption, among subjects data.see unusual outlier values, away general pattern subjects shown data.","code":"\nnnyfs <- read_rds(\"data/nnyfs.Rds\")\nggplot(data = nnyfs, aes(x = protein, y = fat)) +\n    geom_point(shape = 1, size = 2, col = \"sienna\") +\n    geom_smooth(method = \"lm\", formula = y ~ x, se = FALSE, col = \"steelblue\") +\n    labs(title = \"Protein vs. Fat consumption\",\n         subtitle = \"Children in the NNYFS data, with fitted straight line regression model\",\n         x = \"Protein (in g)\", y = \"Fat (in g)\")"},{"path":"straight-line-models.html","id":"highlighting-an-unusual-point","chapter":"11 Straight Line Models","heading":"11.1.1 Highlighting an unusual point","text":"Consider subject protein consumption close 200 g, whose fat consumption 100 g. ’s well prediction linear model example. can identify subject person protein > 190 fat < 100 BMI > 35 waist.circ < 70. ’ll create subset nnyfs data containing point meets standard, add red point label plot.subject hardly unusual point data set, one unusual ones, terms vertical distance regression line. can identify subject printing (part ) tibble created.Now, seem like straight line model describe protein-fat relationship well?","code":"\n# identify outlier and place it in data frame s1 \ns1 <- filter(nnyfs, protein > 190 & fat < 100)\n\nggplot(data = nnyfs, aes(x = protein, y = fat)) +\n    geom_point(shape = 1, size = 2, col = \"sienna\") +\n    geom_smooth(method = \"lm\", se = FALSE, formula = y ~ x, col = \"steelblue\") +\n    geom_point(data = s1, size = 2, col = \"red\") +\n    geom_text(data = s1, label = s1$SEQN, \n              vjust = -1, col = \"red\") +\n    labs(title = \"Protein vs. Fat consumption in NNYFS\",\n         subtitle = \"with regression line, and an outlier labeled by SEQN\",\n         x = \"Protein (in g)\", y = \"Fat (in g)\")\ns1 %>% select(SEQN, sex, race_eth, age_child, protein, fat) %>% kable()"},{"path":"straight-line-models.html","id":"adding-a-scatterplot-smooth-using-loess","chapter":"11 Straight Line Models","heading":"11.1.2 Adding a Scatterplot Smooth using loess","text":"Next, ’ll use loess procedure fit smooth curve data, attempts capture general pattern.“loess” smooth curve fairly close straight line fit, indicating perhaps linear regression model might fit data well.loess smooth method fitting local polynomial regression model R uses default smooth scatterplots fewer 1000 observations. Think loess way fitting curve data tracking (point x) points within neighborhood point x, emphasis given points near x. can adjusted tweaking two specific parameters, particular:span parameter (defaults 0.75) also called \\(\\alpha\\) literature, controls degree smoothing (essentially, large neighborhood ), anda degree parameter (defaults 2) specifies degree polynomial used. Normally, either 1 2 - complex functions rarely needed simple scatterplot smoothing.addition curve, smoothing procedures can also provide confidence intervals around main fitted line. Consider following plot, adjusts span also adds confidence intervals.reducing size span, plot right shows somewhat less “smooth” function plot left.","code":"\nggplot(data = nnyfs, aes(x = protein, y = fat)) +\n    geom_point(shape = 1, size = 2, col = \"sienna\") +\n    geom_smooth(method = \"loess\", se = FALSE, formula = y ~ x, col = \"red\") +\n    geom_smooth(method = \"lm\", se = FALSE, formula = y ~ x, col = \"steelblue\") +\n    labs(title = \"Protein vs. Fat consumption in NNYFS\",\n         subtitle = \"with loess smooth (red) and linear fit (blue)\",\n         x = \"Protein (in g)\", y = \"Fat (in g)\")\np1 <- ggplot(data = nnyfs, aes(x = protein, y = fat)) +\n    geom_point(shape = 1, size = 2, col = \"sienna\") +\n    geom_smooth(method = \"loess\", span = 0.75, se = TRUE, \n                col = \"red\", formula = y ~ x) +\n    labs(title = \"loess smooth (span = 0.75)\",\n         x = \"Protein (in g)\", y = \"Fat (in g)\")\n\np2 <- ggplot(data = nnyfs, aes(x = protein, y = fat)) +\n    geom_point(shape = 1, size = 2, col = \"sienna\") +\n    geom_smooth(method = \"loess\", span = 0.2, se = TRUE, \n                col = \"red\", formula = y ~ x) +\n    labs(title = \"loess smooth (span = 0.2)\",\n         x = \"Protein (in g)\", y = \"Fat (in g)\")\n\np1 + p2 + \n    plot_annotation(title = \"Impact of adjusting loess smooth span: NNYFS\")"},{"path":"straight-line-models.html","id":"what-line-does-r-fit","chapter":"11 Straight Line Models","heading":"11.1.3 What Line Does R Fit?","text":"Returning linear regression model, can , mathematically, characterize line? straight line, model equation requires us specify two parameters: slope intercept (sometimes called y-intercept.)identify equation R used fit line (using method least squares), use lm commandSo fitted line specified \\[\n\\mbox{fat} = 18.8945 + 0.7251 \\mbox{ protein }\n\\]detailed summary fitted linear regression model also available.way ’ll usually summarize estimated coefficients linear model use broom package’s tidy function put coefficient estimates tibble.can also summarize quality fit linear model using broom package’s glance function. now, ’ll focus attention just one many summaries available linear model glance: R-squared value.’ll spend lot time working regression summaries course.now, suffice understand following:outcome variable model fat, predictor variable protein.straight line model data fitted least squares fat = 18.9 + 0.725 proteinThe slope protein positive, indicates protein increases, expect fat also increase. Specifically, expect every additional gram protein consumed, fat consumption 0.725 gram larger.multiple R-squared (squared correlation coefficient) 0.445, implies 44.5% variation fat explained using linear model protein.also implies Pearson correlation fat protein square root 0.445, 0.667. Pearson correlation soon., plan use simple (least squares) linear regression model describe fat consumption function protein consumption NNYFS data, look like least squares (linear regression) model effective choice?","code":"\nlm(fat ~ protein, data = nnyfs)\nCall:\nlm(formula = fat ~ protein, data = nnyfs)\n\nCoefficients:\n(Intercept)      protein  \n    18.8945       0.7251  \nsummary(lm(fat ~ protein, data = nnyfs))\nCall:\nlm(formula = fat ~ protein, data = nnyfs)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-77.798 -14.841  -2.449  13.601 110.597 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  18.8945     1.5330   12.32   <2e-16 ***\nprotein       0.7251     0.0208   34.87   <2e-16 ***\n---\nSignif. codes:  \n0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 25.08 on 1516 degrees of freedom\nMultiple R-squared:  0.4451,    Adjusted R-squared:  0.4447 \nF-statistic:  1216 on 1 and 1516 DF,  p-value: < 2.2e-16\ntidy(lm(fat ~ protein, data = nnyfs),\n            conf.int = TRUE, conf.level = 0.95) %>%\n    kable(digits = 3)\nglance(lm(fat ~ protein, data = nnyfs)) %>% select(r.squared) %>%\n    kable(digits = 3)"},{"path":"straight-line-models.html","id":"correlation-coefficients","chapter":"11 Straight Line Models","heading":"11.2 Correlation Coefficients","text":"Two different correlation measures worth immediate attention.one often used called Pearson correlation coefficient, symbolized letter r sometimes Greek letter rho (\\(\\rho\\)).Another tool Spearman rank correlation coefficient, also occasionally symbolized \\(\\rho\\).nnyfs data, Pearson correlation fat protein can found using cor() function.Note correlation variable 1, correlation fat protein regardless whether enter fat first protein first.","code":"\nnnyfs %$% cor(fat, protein)[1] 0.6671209"},{"path":"straight-line-models.html","id":"the-pearson-correlation-coefficient","chapter":"11 Straight Line Models","heading":"11.3 The Pearson Correlation Coefficient","text":"Suppose \\(n\\) observations two variables, called X Y. Pearson correlation coefficient assesses well relationship X Y can described using linear function.Pearson correlation dimension-free.falls -1 +1, extremes corresponding situations points scatterplot fall exactly straight line negative positive slopes, respectively.Pearson correlation zero corresponds situation linear association.Unlike estimated slope regression line, sample correlation coefficient symmetric X Y, depend labeling one (Y) response variable, one (X) predictor.Suppose \\(n\\) observations two variables, called \\(X\\) \\(Y\\), \\(\\bar{X}\\) sample mean \\(X\\) \\(s_x\\) standard deviation \\(X\\). Pearson correlation coefficient \\(r_{XY}\\) :\\[\nr_{XY} = \\frac{1}{n-1} \\sum\\limits_{=1}^n (\\frac{x_i - \\bar{x}}{s_x}) (\\frac{y_i - \\bar{y}}{s_y}) \n\\]","code":""},{"path":"straight-line-models.html","id":"studying-correlation-through-6-examples","chapter":"11 Straight Line Models","heading":"11.4 Studying Correlation through 6 Examples","text":"correx1 data file contains six different sets (x,y) points, identified set variable.","code":"\ncorrex1 <- read_csv(\"data/correx1.csv\") Rows: 277 Columns: 3-- Column specification ------------------------------------\nDelimiter: \",\"\nchr (1): set\ndbl (2): x, y\ni Use `spec()` to retrieve the full column specification for this data.\ni Specify the column types or set `show_col_types = FALSE` to quiet this message.\nsummary(correx1)     set                  x                y         \n Length:277         Min.   : 5.897   Min.   : 7.308  \n Class :character   1st Qu.:29.487   1st Qu.:30.385  \n Mode  :character   Median :46.154   Median :46.923  \n                    Mean   :46.529   Mean   :49.061  \n                    3rd Qu.:63.333   3rd Qu.:68.077  \n                    Max.   :98.205   Max.   :95.385  "},{"path":"straight-line-models.html","id":"data-set-alex","chapter":"11 Straight Line Models","heading":"11.4.1 Data Set Alex","text":"Let’s start working Alex data set.","code":"\nggplot(filter(correx1, set == \"Alex\"), aes(x = x, y = y)) + \n    geom_point() +\n    labs(title = \"correx1: Data Set Alex\")\nggplot(filter(correx1, set == \"Alex\"), aes(x = x, y = y)) + \n    geom_point() +\n    geom_smooth(method = \"loess\", formula = y ~ x, col = \"blue\") +\n    labs(title = \"correx1: Alex, with loess smooth\")\nsetA <- filter(correx1, set == \"Alex\")\n\nggplot(setA, aes(x = x, y = y)) + \n    geom_point() +\n    geom_smooth(method = \"lm\", formula = y ~ x, col = \"red\") +\n    labs(title = \"correx1: Alex, with Fitted Linear Model\") +\n    annotate(\"text\", x = 75, y = 75, col = \"purple\", size = 6,\n             label = paste(\"Pearson r = \", signif(cor(setA$x, setA$y),3))) +\n    annotate(\"text\", x = 50, y = 15,  col = \"red\", size = 5,\n             label = paste(\"y = \", signif(coef(lm(setA$y ~ setA$x))[1],3), \n                           signif(coef(lm(setA$y ~ setA$x))[2],2), \"x\"))"},{"path":"straight-line-models.html","id":"data-set-bonnie","chapter":"11 Straight Line Models","heading":"11.4.2 Data Set Bonnie","text":"","code":"\nsetB <- dplyr::filter(correx1, set == \"Bonnie\")\n\nggplot(setB, aes(x = x, y = y)) + \n    geom_point() +\n    labs(title = \"correx1: Data Set Bonnie\")\nggplot(setB, aes(x = x, y = y)) + \n    geom_point() +\n    geom_smooth(method = \"lm\", formula = y ~ x, col = \"red\") +\n    labs(title = \"correx1: Bonnie, with Fitted Linear Model\") +\n    annotate(\"text\", x = 25, y = 65, col = \"purple\", size = 6,\n             label = paste(\"Pearson r = \", signif(cor(setB$x, setB$y),2))) +\n    annotate(\"text\", x = 50, y = 15,  col = \"red\", size = 5,\n             label = paste(\"y = \", signif(coef(lm(setB$y ~ setB$x))[1],3), \n                           \" + \",\n                           signif(coef(lm(setB$y ~ setB$x))[2],2), \"x\"))"},{"path":"straight-line-models.html","id":"correlations-for-all-six-data-sets-in-the-correx1-example","chapter":"11 Straight Line Models","heading":"11.4.3 Correlations for All Six Data Sets in the Correx1 Example","text":"Let’s look Pearson correlations associated six data sets contained correx1 example.","code":"\ntab1 <- correx1 %>%\n    group_by(set) %>%\n    summarise(\"Pearson r\" = round(cor(x, y, use=\"complete\"),2))\n\nknitr::kable(tab1)"},{"path":"straight-line-models.html","id":"data-set-colin","chapter":"11 Straight Line Models","heading":"11.4.4 Data Set Colin","text":"looks like picture Colin similar (terms scatter) picture Bonnie, except Colin negative slope, rather positive one Bonnie . plays ?Uh, oh. looks like point Colin top right twisting otherwise straight regression model extremely strong negative correlation. ’s better way look outliers examine scatterplot.","code":"\nsetBC <- filter(correx1, set == \"Bonnie\" | set == \"Colin\")\n\nggplot(setBC, aes(x = x, y = y)) + \n    geom_point() +\n    geom_smooth(method = \"lm\", formula = y ~ x, col = \"red\") +\n    facet_wrap(~ set)"},{"path":"straight-line-models.html","id":"draw-the-picture","chapter":"11 Straight Line Models","heading":"11.4.5 Draw the Picture!","text":"’ve seen Danielle, Earl Fiona show Pearson correlations essentially zero. However, three data sets look different scatterplot.learn correlation zero, tend assume picture like Danielle data set. Danielle real data, might well think x little use predicting y.data looked like Earl? Earl data set, x incredibly helpful predicting y, can’t use straight line model - instead, need non-linear modeling approach.’ll recall Fiona data set also Pearson correlation zero. , picture rather interesting., remember, draw appropriate scatterplot whenever make use correlation coefficient.","code":"\nggplot(correx1, aes(x = x, y = y)) +\n    geom_point() +\n    geom_smooth(method = \"loess\", formula = y ~ x) +\n    facet_wrap(~ set)\nrm(setA, setB, setBC, tab1)"},{"path":"straight-line-models.html","id":"estimating-correlation-from-scatterplots","chapter":"11 Straight Line Models","heading":"11.5 Estimating Correlation from Scatterplots","text":"correx2 data set designed help calibrate bit terms estimating correlation scatterplot. 11 data sets buried within correx2 example, labeled Pearson correlation coefficients, ranging r = 0.01 r = 0.999Here plot 11 data sets, showing increase correlation 0.01 (Set 01) 0.999 (Set 999).Note R allow fit straight line model relationships, matter appropriate might .Note 10 points used data sets. ’s always possible lurking subgroup data within scatterplot follows strong linear relationship. ’s important (difficult) go searching thing without strong foundation logic, theory prior empirical evidence.","code":"\ncorrex2 <- read_csv(\"data/correx2.csv\")Rows: 582 Columns: 4-- Column specification ------------------------------------\nDelimiter: \",\"\nchr (1): set\ndbl (3): x, y, group\ni Use `spec()` to retrieve the full column specification for this data.\ni Specify the column types or set `show_col_types = FALSE` to quiet this message.\ncorrex2 %>%\n    group_by(set) %>%\n    summarise(cor = round(cor(x, y, use=\"complete\"),3))# A tibble: 11 x 2\n   set       cor\n   <chr>   <dbl>\n 1 Set 01  0.01 \n 2 Set 10  0.102\n 3 Set 20  0.202\n 4 Set 30  0.301\n 5 Set 40  0.403\n 6 Set 50  0.499\n 7 Set 60  0.603\n 8 Set 70  0.702\n 9 Set 80  0.799\n10 Set 90  0.902\n11 Set 999 0.999\nggplot(correx2, aes(x = x, y = y)) +\n    geom_point() + \n    facet_wrap(~ set) +\n    labs(title = \"Pearson Correlations from 0.01 to 0.999\")\nggplot(correx2, aes(x = x, y = y)) +\n    geom_point() + \n    geom_smooth(method = \"lm\", formula = y ~ x, col = \"red\") +\n    facet_wrap(~ set) +\n    labs(title = \"R will fit a straight line to anything.\")\nggplot(correx2, aes(x = x, y = y)) +\n    geom_point() + \n    geom_smooth(col = \"blue\") +\n    facet_wrap(~ set) +\n    labs(title = \"Even if a loess smooth suggests non-linearity.\")\nggplot(correx2, aes(x = x, y = y, color = factor(group))) +\n    geom_point() + \n    guides(color = \"none\") +\n    facet_wrap(~ set) +\n    labs(title = \"Note: The same 10 points (in red) are in each plot.\")"},{"path":"straight-line-models.html","id":"the-spearman-rank-correlation","chapter":"11 Straight Line Models","heading":"11.6 The Spearman Rank Correlation","text":"Spearman rank correlation coefficient rank-based measure statistical dependence assesses well relationship X Y can described using monotone function even relationship linear.monotone function preserves order, , Y must either strictly increasing X increases, strictly decreasing X increases.Spearman correlation 1.0 indicates simply X increases, Y always increases.Like Pearson correlation, Spearman correlation dimension-free, falls -1 +1.positive Spearman correlation corresponds increasing (necessarily linear) association X Y, negative Spearman correlation corresponds decreasing (necessarily linear) association.","code":""},{"path":"straight-line-models.html","id":"spearman-formula","chapter":"11 Straight Line Models","heading":"11.6.1 Spearman Formula","text":"calculate Spearman rank correlation, take ranks X Y data, apply usual Pearson correlation. find ranks, sort X Y ascending order, number 1 (smallest) n (largest). event tie, assign average rank tied subjects.","code":""},{"path":"straight-line-models.html","id":"comparing-pearson-and-spearman-correlations","chapter":"11 Straight Line Models","heading":"11.6.2 Comparing Pearson and Spearman Correlations","text":"Let’s look nnyfs data .Spearman Pearson correlations especially different case.","code":"\nnnyfs %$% cor(fat, protein)[1] 0.6671209\nnnyfs %$% cor(fat, protein, method = \"spearman\")[1] 0.6577489"},{"path":"straight-line-models.html","id":"spearman-vs.-pearson-example-1","chapter":"11 Straight Line Models","heading":"11.6.3 Spearman vs. Pearson Example 1","text":"next plots describe relationships anticipate Pearson Spearman correlations might differ conclusions.Example 1 shows function Pearson correlation 0.925 (strong perfect linear relation), Spearman correlation 1 relationship monotone, even though perfectly linear., positive Spearman correlation corresponds increasing (necessarily linear) association x y.","code":"\nspear1 <- read_csv(\"data/spear1.csv\")Rows: 22 Columns: 2-- Column specification ------------------------------------\nDelimiter: \",\"\ndbl (2): x, y\ni Use `spec()` to retrieve the full column specification for this data.\ni Specify the column types or set `show_col_types = FALSE` to quiet this message.\nspear2 <- read_csv(\"data/spear2.csv\")Rows: 90 Columns: 2-- Column specification ------------------------------------\nDelimiter: \",\"\ndbl (2): x, y\ni Use `spec()` to retrieve the full column specification for this data.\ni Specify the column types or set `show_col_types = FALSE` to quiet this message.\nspear3 <- read_csv(\"data/spear3.csv\")Rows: 55 Columns: 2-- Column specification ------------------------------------\nDelimiter: \",\"\ndbl (2): x, y\ni Use `spec()` to retrieve the full column specification for this data.\ni Specify the column types or set `show_col_types = FALSE` to quiet this message.\nspear4 <- read_csv(\"data/spear4.csv\")Rows: 15 Columns: 2-- Column specification ------------------------------------\nDelimiter: \",\"\ndbl (2): x, y\ni Use `spec()` to retrieve the full column specification for this data.\ni Specify the column types or set `show_col_types = FALSE` to quiet this message.\n# these are just toy examples with\n# two columns per data set and no row numbering\nggplot(spear1, aes(x = x, y = y)) + \n    geom_point() +\n    labs(title = \"Spearman vs. Pearson, Example 1\") +\n    annotate(\"text\", x = -10, y = 20, \n             label = paste(\"Pearson r = \", \n                 signif(cor(spear1$x, spear1$y),2),\n                 \", Spearman r = \", \n                 signif(cor(spear1$x, spear1$y, method = \"spearman\"),2)))"},{"path":"straight-line-models.html","id":"spearman-vs.-pearson-example-2","chapter":"11 Straight Line Models","heading":"11.6.4 Spearman vs. Pearson Example 2","text":"Example 2 shows negative Spearman correlation corresponds decreasing (, , necessarily linear) association x y.","code":"\nggplot(spear2, aes(x = x, y = y)) + \n    geom_point(col = \"purple\") +\n    geom_smooth(method = \"loess\", formula = y ~ x, se = FALSE) +\n    labs(title = \"Spearman vs. Pearson, Example 2\") +\n    annotate(\"text\", x = 10, y = 20, col = \"purple\",\n             label = paste(\"Pearson r = \", \n                    signif(cor(spear2$x, spear2$y),2),\n                    \", Spearman r = \", \n                    signif(cor(spear2$x, spear2$y, method = \"spearman\"),2)))"},{"path":"straight-line-models.html","id":"spearman-vs.-pearson-example-3","chapter":"11 Straight Line Models","heading":"11.6.5 Spearman vs. Pearson Example 3","text":"Spearman correlation less sensitive Pearson correlation strong outliers unusual either X Y axis, . Spearman rank coefficient limits outlier value rank.Example 3, instance, Spearman correlation reacts much less outliers around X = 12 Pearson correlation.","code":"\nggplot(spear3, aes(x = x, y = y)) + \n    geom_point(col = \"blue\") +\n    labs(title = \"Spearman vs. Pearson, Example 3\") +\n    annotate(\"text\", x = 5, y = -15, col = \"blue\",\n             label = paste(\"Pearson r = \", \n                signif(cor(spear3$x, spear3$y),2),\n                \", Spearman r = \", \n                signif(cor(spear3$x, spear3$y, method = \"spearman\"),2)))"},{"path":"straight-line-models.html","id":"spearman-vs.-pearson-example-4","chapter":"11 Straight Line Models","heading":"11.6.6 Spearman vs. Pearson Example 4","text":"use Spearman correlation substitute looking data. non-monotone data like see Example 4, neither Spearman Pearson correlation alone provides much guidance, just (essentially) telling thing, doesn’t mean ’re telling helpful.","code":"\nggplot(spear4, aes(x = x, y = y)) +\n    geom_point(col = \"purple\") +\n    geom_smooth(method = \"loess\", formula = y ~ x, se = FALSE) +\n    labs(title = \"Spearman vs. Pearson, Example 4\") +\n    annotate(\"text\", x = 10, y = 20, col = \"purple\",\n             label = paste(\"Pearson r = \", \n                 signif(cor(spear4$x, spear4$y),2),\n                 \", Spearman r = \", \n                 signif(cor(spear4$x, spear4$y, method = \"spearman\"),2)))"},{"path":"linearizing-transformations.html","id":"linearizing-transformations","chapter":"12 Linearizing Transformations","heading":"12 Linearizing Transformations","text":"","code":""},{"path":"linearizing-transformations.html","id":"linearize-the-association-between-quantitative-variables","chapter":"12 Linearizing Transformations","heading":"12.1 “Linearize” The Association between Quantitative Variables","text":"Confronted scatterplot describing monotone association two quantitative variables, may decide data well approximated straight line, thus, least squares regression may sufficiently useful. circumstances, least two options, mutually exclusive:Let data may, summarize scatterplot using tools like loess curves, polynomial functions, cubic splines model relationship.Consider re-expressing data (often start re-expressions outcome data [Y variable]) using transformation transformed data may modeled effectively using straight line.","code":""},{"path":"linearizing-transformations.html","id":"the-box-cox-plot","chapter":"12 Linearizing Transformations","heading":"12.2 The Box-Cox Plot","text":", Tukey’s ladder power transformations can guide exploration.Box-Cox plot, boxCox function car package, sifts ladder options suggest transformation (Y) best linearize outcome-predictor(s) relationship.","code":""},{"path":"linearizing-transformations.html","id":"a-few-caveats","chapter":"12 Linearizing Transformations","heading":"12.2.1 A Few Caveats","text":"methods work well monotone data, smooth function Y either strictly increasing, strictly decreasing, X increases.transformations require data positive. can rescale Y data adding constant every observation data set without changing shape.can use natural logarithm (log R), base 10 logarithm (log10) even sometimes base 2 logarithm (log2) good effect Tukey’s ladder. affect association’s shape way, ’ll stick log (base e).re-expressions don’t lead easily interpretable results. many things make sense original units also make sense inverse square roots. times won’t care, often, .primary interest making predictions, ’ll generally interested getting good predictions back original scale, can back-transform point interval estimates accomplish .","code":""},{"path":"linearizing-transformations.html","id":"a-simulated-example","chapter":"12 Linearizing Transformations","heading":"12.3 A Simulated Example","text":"simulated data produces curved scatterplot, now use Box-Cox plot lead choice appropriate power transformation Y order “linearize” association Y X.Box-Cox plot peaks value \\(\\lambda\\) = 0.44, pretty close \\(\\lambda\\) = 0.5. Now, 0.44 isn’t Tukey’s ladder, 0.5 .use \\(\\lambda\\) = 0.5, Tukey’s ladder power transformations, suggests look relationship square root Y X, shown next.eye, think square root plot better matches linear fit.","code":"\nset.seed(999); x.rand <- rbeta(80, 2, 5) * 20 + 3\nset.seed(1000); y.rand <- abs(50 + 0.75*x.rand^(3) - 0.65*x.rand + rnorm(80, 0, 200))\nscatter1 <- data_frame(x = x.rand, y = y.rand) Warning: `data_frame()` was deprecated in tibble 1.1.0.\nPlease use `tibble()` instead.\nThis warning is displayed once every 8 hours.\nCall `lifecycle::last_warnings()` to see where this warning was generated.\nrm(x.rand, y.rand)\n\nggplot(scatter1, aes(x = x, y = y)) +\n    geom_point(shape = 1, size = 3) +\n    ## add loess smooth\n    geom_smooth(method = \"loess\", se = FALSE, \n                col = \"dodgerblue\", formula = y ~ x) +\n    ## then add linear fit\n    geom_smooth(method = \"lm\", se = FALSE, \n                col = \"red\", formula = y ~ x, linetype = \"dashed\") +\n    labs(title = \"Simulated scatter1 example: Y vs. X\")\nlibrary(car)\nboxCox(scatter1$y ~ scatter1$x) \npowerTransform(scatter1$y ~ scatter1$x)Estimated transformation parameter \n       Y1 \n0.4368753 \np1 <- ggplot(scatter1, aes(x = x, y = y)) +\n    geom_point(size = 2) +\n    geom_smooth(method = \"loess\", se = FALSE, \n                formula = y ~ x, col = \"dodgerblue\") +\n    geom_smooth(method = \"lm\", se = FALSE, \n                formula = y ~ x, col = \"red\", linetype = \"dashed\") +\n    labs(title = \"scatter1: Y vs. X\")\n\np2 <- ggplot(scatter1, aes(x = x, y = sqrt(y))) +\n    geom_point(size = 2) +\n    geom_smooth(method = \"loess\", se = FALSE, \n                formula = y ~ x, col = \"dodgerblue\") +\n    geom_smooth(method = \"lm\", se = FALSE, \n                formula = y ~ x, col = \"red\", linetype = \"dashed\") +\n    labs(title = \"scatter1: Square Root of Y vs. X\")\n\np1 + p2"},{"path":"linearizing-transformations.html","id":"checking-on-a-transformation-or-re-expression","chapter":"12 Linearizing Transformations","heading":"12.4 Checking on a Transformation or Re-Expression","text":"can three things check transformation.can calculate correlation original re-expressed associations.can use testTransform function car library R perform statistical test comparing optimal choice power (\\(\\lambda\\) = 0.44) various transformations.can go ahead fit regression models using approach compare plots studentized residuals fitted values data see re-expression reduces curve residual plot, well.Option 3 far important practice, ’s one ’ll focus going forward, ’ll demonstrate three .","code":""},{"path":"linearizing-transformations.html","id":"checking-the-correlation-coefficients","chapter":"12 Linearizing Transformations","heading":"12.4.1 Checking the Correlation Coefficients","text":", calculate correlation original re-expressed associations.Pearson correlation little stronger transformation. ’d expect.","code":"\ncor(scatter1$y, scatter1$x)[1] 0.891198\ncor(sqrt(scatter1$y), scatter1$x)[1] 0.9144307"},{"path":"linearizing-transformations.html","id":"using-the-testtransform-function","chapter":"12 Linearizing Transformations","heading":"12.4.2 Using the testTransform function","text":", use testTransform function (also car package) compare optimal choice determined powerTransform function (\\(\\lambda\\) = 0.44) \\(\\lambda\\) = 0 (logarithm), 0.5 (square root) 1 (transformation).looks like square root (\\(\\lambda\\) = 0.5) three options significantly worse log-likelihood criterion applied optimal choice.’s ’s one p value larger usual standard statistical significance, 0.05.","code":"\ntestTransform(powerTransform(scatter1$y ~ scatter1$x), 0)                           LRT df      pval\nLR test, lambda = (0) 46.17947  1 1.079e-11\ntestTransform(powerTransform(scatter1$y ~ scatter1$x), 0.5)                             LRT df    pval\nLR test, lambda = (0.5) 1.024888  1 0.31136\ntestTransform(powerTransform(scatter1$y ~ scatter1$x), 1)                           LRT df       pval\nLR test, lambda = (1) 63.75953  1 1.4433e-15"},{"path":"linearizing-transformations.html","id":"comparing-the-residual-plots","chapter":"12 Linearizing Transformations","heading":"12.4.3 Comparing the Residual Plots","text":"can fit regression models, obtain plots residuals fitted values, compare see one less indication curve residuals.’re looking plot absence curve, among things, want see “fuzzy football” shapes.compared original residual plot, square root version, modest improvement regard. look bit less curved, bit like random cluster points, ’s nice. Usually, can little better real data, shown next example NNYFS data introduced Chapter 9.","code":"\nmodel.orig <- lm(scatter1$y ~ scatter1$x)\nmodel.sqrt <- lm(sqrt(scatter1$y) ~ scatter1$x)\n\np1 <- augment(model.orig) %>%\n    ggplot(., aes(x = scatter1$x, y = .resid)) + \n    geom_point() +\n    geom_smooth(method = \"loess\", formula = y ~ x, se = FALSE) +\n    geom_smooth(method = \"lm\", formula = y ~ x, se = FALSE, col = \"red\") +\n    labs(title = \"Y vs X Residual Plot\")\n\np2 <- augment(model.sqrt) %>%\n    ggplot(., aes(x = scatter1$x, y = .resid)) + \n    geom_point() +\n    geom_smooth(method = \"loess\", formula = y ~ x, se = FALSE) +\n    geom_smooth(method = \"lm\", formula = y ~ x, se = FALSE, col = \"red\") +\n    labs(title = \"Square Root Model Residuals\")\n\np1 + p2"},{"path":"linearizing-transformations.html","id":"an-example-from-the-nnyfs-data","chapter":"12 Linearizing Transformations","heading":"12.5 An Example from the NNYFS data","text":"Using subjects nnyfs data complete data two variables interest, let’s look relationship arm circumference (outcome, shown Y axis) arm length (predictor, shown X axis.)","code":"\nnnyfs <- read_rds(\"data/nnyfs.Rds\")\nnnyfs_c <- nnyfs %>% \n    filter(complete.cases(arm_circ, arm_length)) %>%\n    select(SEQN, arm_circ, arm_length)"},{"path":"linearizing-transformations.html","id":"pearson-correlation-and-scatterplot","chapter":"12 Linearizing Transformations","heading":"12.5.1 Pearson correlation and scatterplot","text":"Pearson correlation two variables. Note use %$% pipe magrittr package help tell cor function data process.’s resulting scatterplot.Pearson correlation still quite strong, note loess smooth (shown blue) bends straight line model (shown red) low high end arm length.Note also use alpha = 0.2 show points greater transparency shown normally (default setting transparency alpha = 1.)","code":"\nnnyfs_c %$% cor(arm_length, arm_circ)[1] 0.8120242\nggplot(nnyfs_c, aes(x = arm_length, y = arm_circ)) +\n    geom_point(alpha = 0.2) +\n    geom_smooth(method = \"loess\", formula = y ~ x, \n                se = FALSE, color = \"blue\") +\n    geom_smooth(method = \"lm\", formula = y ~ x, \n                se = FALSE, color = \"red\")"},{"path":"linearizing-transformations.html","id":"plotting-the-residuals","chapter":"12 Linearizing Transformations","heading":"12.5.2 Plotting the Residuals","text":"Now, let’s build plot residuals straight line model plotted arm length. can obtain residuals using augment() function broom package.OK. residuals now stored .resid variable. can create residual plot, follows.","code":"\nm1 <- lm(arm_circ ~ arm_length, data = nnyfs_c)\n\nnnyfs_c_aug1 <- augment(m1, data = nnyfs_c)\n\nnnyfs_c_aug1# A tibble: 1,511 x 9\n    SEQN arm_circ arm_length .fitted .resid     .hat .sigma\n   <dbl>    <dbl>      <dbl>   <dbl>  <dbl>    <dbl>  <dbl>\n 1 71918     25.4       27.7    21.9  3.51  0.000695   3.21\n 2 71919     26         38.4    30.4 -4.38  0.00253    3.21\n 3 71920     37.9       35.9    28.4  9.50  0.00167    3.20\n 4 71921     15.1       18.3    14.4  0.669 0.00304    3.21\n 5 71922     29.5       34.2    27.0  2.45  0.00124    3.21\n 6 71923     27.9       33      26.1  1.80  0.00100    3.21\n 7 71924     17.6       26.5    20.9 -3.34  0.000788   3.21\n 8 71925     17.7       24.2    19.1 -1.41  0.00113    3.21\n 9 71926     19.9       26      20.5 -0.642 0.000844   3.21\n10 71927     17.3       20      15.8  1.52  0.00234    3.21\n# ... with 1,501 more rows, and 2 more variables:\n#   .cooksd <dbl>, .std.resid <dbl>\nggplot(nnyfs_c_aug1, aes(x = arm_length, y = .resid)) +\n    geom_point(alpha = 0.2) +\n    geom_smooth(method = \"loess\", col = \"purple\",\n                formula = y ~ x, se = FALSE) +\n    labs(title = \"Residuals show a curve.\")"},{"path":"linearizing-transformations.html","id":"using-the-box-cox-approach-to-identify-a-transformation","chapter":"12 Linearizing Transformations","heading":"12.5.3 Using the Box-Cox approach to identify a transformation","text":"suggests transform arm_circ data taking inverse (power = -1.) Let’s take look result.","code":"\nlibrary(car)\nboxCox(nnyfs_c$arm_circ ~ nnyfs_c$arm_length) \npowerTransform(nnyfs_c$arm_circ ~ nnyfs_c$arm_length)Estimated transformation parameter \n        Y1 \n-0.9783135 "},{"path":"linearizing-transformations.html","id":"plots-after-inverse-transformation","chapter":"12 Linearizing Transformations","heading":"12.5.4 Plots after Inverse Transformation","text":"Let’s build (left) revised scatterplot (right) revised residual plot transforming outcome (arm_circ) taking inverse.","code":"\nnnyfs_c <- nnyfs_c %>%\n    mutate(inv_arm_circ = 1/arm_circ)\n\np1 <- ggplot(nnyfs_c, aes(x = arm_length, y = inv_arm_circ)) +\n    geom_point(alpha = 0.2) +\n    geom_smooth(method = \"loess\", formula = y ~ x, \n                se = FALSE, color = \"blue\") +\n    geom_smooth(method = \"lm\", formula = y ~ x, \n                se = FALSE, color = \"red\") +\n    labs(title = \"Transformation reduces curve\")\n\nm2 <- lm(inv_arm_circ ~ arm_length, data = nnyfs_c)\n\nnnyfs_c_aug2 <- augment(m2, data = nnyfs_c)\n\np2 <- ggplot(nnyfs_c_aug2, aes(x = arm_length, y = .resid)) +\n    geom_point(alpha = 0.2) +\n    geom_smooth(method = \"loess\", col = \"purple\",\n                formula = y ~ x, se = FALSE) +\n    labs(title = \"Residuals much improved\")\n\np1 + p2 + \n    plot_annotation(title = \"Evaluating the Inverse Transformation\")"},{"path":"studying-crab-claws-crabs.html","id":"studying-crab-claws-crabs","chapter":"13 Studying Crab Claws (crabs)","heading":"13 Studying Crab Claws (crabs)","text":"next example, ’ll consider study zoology, specifically carcinology - study crustaceans. source data Chapter 7 Fred L. Ramsey Daniel W. Schafer30 drew data figure SB Yamada EG Boulding.31The available data mean closing forces (Newtons) propodus heights (mm) claws 38 crabs came three different species. propodus segment crab’s clawed leg immovable finger palm.\n(#fig:c13_crab1-fig)Source: http://txmarspecies.tamug.edu/crustglossary.cfm\npart study effects predatory intertidal crab species populations snails. three crab species study :14 Hemigraspus nudus, also called purple shore crab (14 crabs)12 Lophopanopeus bellus, also called black-clawed pebble crab, and12 Cancer productus, one several species red rock crabs (12)species information stored character variable. many different crabs talking species?turns , ’re going want treat species information factor three levels, rather character variable.’s quick summary data. Take care note useless results first two variables. least function flags * variables thinks non-numeric.Actually, ’re interested results grouping species.","code":"\ncrabs <- read_csv(\"data/crabs.csv\") Rows: 38 Columns: 4-- Column specification ------------------------------------\nDelimiter: \",\"\nchr (1): species\ndbl (3): crab, force, height\ni Use `spec()` to retrieve the full column specification for this data.\ni Specify the column types or set `show_col_types = FALSE` to quiet this message.\ncrabs# A tibble: 38 x 4\n    crab species              force height\n   <dbl> <chr>                <dbl>  <dbl>\n 1     1 Hemigraspus nudus      4      8  \n 2     2 Lophopanopeus bellus  15.1    7.9\n 3     3 Cancer productus       5      6.7\n 4     4 Lophopanopeus bellus   2.9    6.6\n 5     5 Hemigraspus nudus      3.2    5  \n 6     6 Hemigraspus nudus      9.5    7.9\n 7     7 Cancer productus      22.5    9.4\n 8     8 Hemigraspus nudus      7.4    8.3\n 9     9 Cancer productus      14.6   11.2\n10    10 Lophopanopeus bellus   8.7    8.6\n# ... with 28 more rows\ncrabs %>% tabyl(species)              species  n   percent\n     Cancer productus 12 0.3157895\n    Hemigraspus nudus 14 0.3684211\n Lophopanopeus bellus 12 0.3157895\ncrabs <- crabs %>%\n    mutate(species = factor(species))\npsych::describe(crabs)         vars  n  mean    sd median trimmed   mad min  max\ncrab        1 38 19.50 11.11  19.50   19.50 14.08   1 38.0\nspecies*    2 38  2.00  0.81   2.00    2.00  1.48   1  3.0\nforce       3 38 12.13  8.98   8.70   11.53  9.04   2 29.4\nheight      4 38  8.81  2.23   8.25    8.78  2.52   5 13.1\n         range skew kurtosis   se\ncrab      37.0 0.00    -1.30 1.80\nspecies*   2.0 0.00    -1.50 0.13\nforce     27.4 0.47    -1.25 1.46\nheight     8.1 0.19    -1.14 0.36\ncrabs %>%\n    group_by(species) %>%\n    summarise(n = n(), median(force), median(height))# A tibble: 3 x 4\n  species                  n `median(force)` `median(height)`\n  <fct>                <int>           <dbl>            <dbl>\n1 Cancer productus        12            19.7            11.0 \n2 Hemigraspus nudus       14             3.7             7.9 \n3 Lophopanopeus bellus    12            14.8             8.15"},{"path":"studying-crab-claws-crabs.html","id":"association-of-size-and-force","chapter":"13 Studying Crab Claws (crabs)","heading":"13.1 Association of Size and Force","text":"Suppose want describe force basis height, across 38 crabs. ’ll add titles identify three species crab, using shape color.faceted plot species really highlights difference force Hemigraspus nudus two species crab.","code":"\nggplot(crabs, aes(x = height, y = force, color = species, shape = species)) +\n    geom_point(size = 3) +\n    labs(title = \"Crab Claw Force by Size\", \n         x = \"Claw's propodus height (mm)\", y = \"Mean closing force (N)\") +\n    theme_bw()\nggplot(crabs, aes(x = height, y = force, color = species)) +\n    geom_point(size = 3) +\n    facet_wrap(~ species) +\n    guides(color = \"none\") +\n    labs(title = \"Crab Claw Force by Size\", \n         x = \"Claw's propodus height (mm)\", y = \"Mean closing force (N)\") +\n    theme_bw()"},{"path":"studying-crab-claws-crabs.html","id":"loess_smooth","chapter":"13 Studying Crab Claws (crabs)","heading":"13.2 The loess smooth","text":"can obtain smoothed curve (using several different approaches) summarize pattern presented data scatterplot. instance, might build plot complete set 38 crabs, adding non-linear smooth function (called loess smooth.)discussed previously, loess smooth fits curve data tracking (point x) points within neighborhood point x, emphasis given points near x. can adjusted tweaking span degree parameters.addition curve, smoothing procedures can also provide confidence intervals around main fitted line. Consider following plot crabs information, adjusts span (default 0.75) also adds confidence intervals.reducing size span, resulting picture shows much less smooth function generated previously.","code":"\nggplot(crabs, aes(x = height, y = force)) +\n    geom_point() +\n    geom_smooth(method = \"loess\", se = FALSE, formula = y ~ x) +\n    labs(title = \"Crab Claw Force by Size\", \n         x = \"Claw's propodus height (mm)\", y = \"Mean closing force (N)\")\nggplot(crabs, aes(x = height, y = force)) +\n    geom_point() +\n    geom_smooth(method = \"loess\", formula = y ~ x, span = 0.5, se = TRUE) +\n    labs(title = \"Crab Claw Force by Size\", \n         x = \"Claw's propodus height (mm)\", y = \"Mean closing force (N)\")"},{"path":"studying-crab-claws-crabs.html","id":"smoothing-within-species","chapter":"13 Studying Crab Claws (crabs)","heading":"13.2.1 Smoothing within Species","text":"can, course, produce plot separate smooths three species crab.want add confidence intervals (’ll show 90% rather default 95%) plot faceted. Note default, displayed se = TRUE 95% prediction intervals - level function stat_smooth [can used place geom_smooth] used change coverage percentage 95% 90%.confidence intervals later, especially part B.","code":"\nggplot(crabs, aes(x = height, y = force, group = species, color = species)) +\n    geom_point(size = 3) +\n    geom_smooth(method = \"loess\", formula = y ~ x, se = FALSE) +\n    labs(title = \"Crab Claw Force by Size\", \n         x = \"Claw's propodus height (mm)\", y = \"Mean closing force (N)\")\nggplot(crabs, aes(x = height, y = force, group = species, color = species)) +\n    geom_point() +\n    stat_smooth(method = \"loess\", formula = y ~ x, level = 0.90, se = TRUE) +\n    guides(color = \"none\") +\n    labs(title = \"Crab Claw Force by Size\", \n         caption = \"with loess smooths and 90% confidence intervals\",\n         x = \"Claw's propodus height (mm)\", y = \"Mean closing force (N)\") +\n    facet_wrap(~ species)"},{"path":"studying-crab-claws-crabs.html","id":"fitting-a-linear-regression-model","chapter":"13 Studying Crab Claws (crabs)","heading":"13.3 Fitting a Linear Regression Model","text":"Suppose plan use simple (least squares) linear regression model describe force function height. least squares model likely effective choice ?plot shows regression line predicting closing force function propodus height. annotate plot show actual fitted regression line, required fitting lm statement prior developing graph.lm function, , specifies linear model fit predict force using height. ’s summary., key things realize :outcome variable model force, predictor variable height.straight line model data fitted least squares force = -11.1 + 2.63 height.slope height positive, indicates height increases, expect force also increase. Specifically, expect every additional mm height, force increase 2.63 Newtons.multiple R-squared (squared correlation coefficient) 0.427, implies 42.7% variation force explained using linear model height. also implies Pearson correlation force height square root 0.427, 0.653.","code":"\nmod <- lm(force ~ height, data = crabs)\n\nggplot(crabs, aes(x = height, y = force)) +\n    geom_point() +\n    geom_smooth(method = \"lm\", formula = y ~ x,  color = \"red\") +\n    labs(title = \"Crab Claw Force by Size with Linear Regression Model\", \n         x = \"Claw's propodus height (mm)\", y = \"Mean closing force (N)\") +\n    annotate(\"text\", x = 11, y = 0, color = \"red\", fontface = \"italic\",\n             label = paste( \"Force - \", signif(coef(mod)[1],3), \" + \", \n                            signif(coef(mod)[2],3), \" Height\" ))\nrm(mod)\nsummary(lm(force ~ height, data = crabs))\nCall:\nlm(formula = force ~ height, data = crabs)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-16.7945  -3.8113  -0.2394   4.1444  16.8814 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -11.0869     4.6224  -2.399   0.0218 *  \nheight        2.6348     0.5089   5.177 8.73e-06 ***\n---\nSignif. codes:  \n0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.892 on 36 degrees of freedom\nMultiple R-squared:  0.4268,    Adjusted R-squared:  0.4109 \nF-statistic:  26.8 on 1 and 36 DF,  p-value: 8.73e-06"},{"path":"studying-crab-claws-crabs.html","id":"is-a-linear-model-appropriate","chapter":"13 Studying Crab Claws (crabs)","heading":"13.4 Is a Linear Model Appropriate?","text":"zoology (least described Ramsey Schafer32) suggests actual nature relationship represented log-log relationship, log force predicted log height.log-log model appropriate model think percentage increases X (height, ) lead constant percentage increases Y (, force).see log-log model action, plot log force log height. use either base 10 (log10 R) natural (log R) logarithms.correlations raw force height logarithms turn quite similar, log transformation monotone data, ’s actually change Spearman correlations.","code":"\nggplot(crabs, aes(x = log(height), y = log(force))) +\n    geom_point() +\n    geom_smooth(method = \"lm\", formula = y ~ x) + \n    labs(title = \"Log-Log Model for Crabs data\")"},{"path":"studying-crab-claws-crabs.html","id":"the-log-log-model","chapter":"13 Studying Crab Claws (crabs)","heading":"13.4.1 The log-log model","text":"regression equation log(force) = -2.71 + 2.27 log(height)., example, found crab propodus height = 10 mm, prediction crab’s claw force (Newtons) based log-log model …log(force) = -2.71 + 2.27 log(10)log(force) = -2.71 + 2.27 x 2.3025851log(force) = 2.5190953and predicted force = exp(2.5190953) = 12.4173582 Newtons, , naturally, round 12.4 Newtons match data set’s level precision.","code":"\ncrab_loglog <- lm(log(force) ~ log(height), data = crabs)\n\nsummary(crab_loglog)\nCall:\nlm(formula = log(force) ~ log(height), data = crabs)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.5657 -0.4450  0.1884  0.4798  1.2422 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  -2.7104     0.9251  -2.930  0.00585 ** \nlog(height)   2.2711     0.4284   5.302 5.96e-06 ***\n---\nSignif. codes:  \n0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.6748 on 36 degrees of freedom\nMultiple R-squared:  0.4384,    Adjusted R-squared:  0.4228 \nF-statistic: 28.11 on 1 and 36 DF,  p-value: 5.96e-06"},{"path":"studying-crab-claws-crabs.html","id":"how-does-this-compare-to-our-original-linear-model","chapter":"13 Studying Crab Claws (crabs)","heading":"13.4.2 How does this compare to our original linear model?","text":"linear regression equation force = -11.1 + 2.63 height., example, found crab propodus height = 10 mm, prediction crab’s claw force (Newtons) based linear model …force = -11.0869025 + 2.6348232 x 10force = -11.0869025 + 26.3482321so predicted force = 15.2613297, round 15.3 Newtons., looks like two models give meaningfully different predictions.","code":"\ncrab_linear <- lm(force ~ height, data = crabs)\n\nsummary(crab_linear)\nCall:\nlm(formula = force ~ height, data = crabs)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-16.7945  -3.8113  -0.2394   4.1444  16.8814 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -11.0869     4.6224  -2.399   0.0218 *  \nheight        2.6348     0.5089   5.177 8.73e-06 ***\n---\nSignif. codes:  \n0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.892 on 36 degrees of freedom\nMultiple R-squared:  0.4268,    Adjusted R-squared:  0.4109 \nF-statistic:  26.8 on 1 and 36 DF,  p-value: 8.73e-06"},{"path":"studying-crab-claws-crabs.html","id":"making-predictions-with-a-model","chapter":"13 Studying Crab Claws (crabs)","heading":"13.5 Making Predictions with a Model","text":"broom package’s augment function provides us consistent method obtaining predictions (also called fitted values) new crab original data. Suppose want predict force level two new crabs: one height = 10 mm, another height = 12 mm.want obtain prediction interval, can use predict function:’d interpret result saying linear model’s predicted force associated single new crab claw propodus height 10 mm 15.3 Newtons, 95% prediction interval true value force claw 1.0 29.5 Newtons. prediction intervals later.","code":"\nnewcrab <- tibble(crab = c(\"Crab_A\", \"Crab_B\"), height = c(10, 12))\n\naugment(crab_linear, newdata = newcrab)# A tibble: 2 x 3\n  crab   height .fitted\n  <chr>   <dbl>   <dbl>\n1 Crab_A     10    15.3\n2 Crab_B     12    20.5\npredict(crab_linear, newdata = newcrab, interval = \"prediction\", level = 0.95)       fit      lwr      upr\n1 15.26133 1.048691 29.47397\n2 20.53098 5.994208 35.06774"},{"path":"studying-crab-claws-crabs.html","id":"predictions-after-a-transformation","chapter":"13 Studying Crab Claws (crabs)","heading":"13.5.1 Predictions After a Transformation","text":"can also get predictions log-log model. default choice 95% prediction interval.course, predictions describe log(force) crab claw. get prediction terms simple force, ’d need back logarithm, exponentiating point estimate prediction interval endpoints.’d interpret result saying, first new crab, log-log model’s predicted force associated single new crab claw propodus height 10 mm 12.4 Newtons, 95% prediction interval true value force claw 3.1 50.0 Newtons.","code":"\npredict(crab_loglog, newdata = newcrab, interval = \"prediction\")       fit      lwr      upr\n1 2.519095 1.125900 3.912291\n2 2.933174 1.515548 4.350800\nexp(predict(crab_loglog, newdata = newcrab, interval = \"prediction\"))       fit      lwr      upr\n1 12.41736 3.082989 50.01341\n2 18.78716 4.551916 77.54044"},{"path":"studying-crab-claws-crabs.html","id":"comparing-model-predictions","chapter":"13 Studying Crab Claws (crabs)","heading":"13.5.2 Comparing Model Predictions","text":"Suppose wish build plot force vs height straight line linear model’s predictions, new curve log-log model’s predictions, can compare contrast implications two models common scale. predict function, given new data frame, use existing predictor values crabs data. predictions often called fitted values.put two sets predictions scale despite differing outcomes two models, ’ll exponentiate results log-log model, build little data frame containing heights predicted forces model.cleaner way might use augment function directly broom:Now, ’re ready use geom_smooth approach plot linear fit, geom_line (also fits curves) display log-log fit.Based 38 crabs, see modest differences predictions two models, log-log model predicting generally lower closing force given propodus height predicted linear model.","code":"\nloglogdat <- tibble(height = crabs$height, force = exp(predict(crab_loglog)))\naugment(crab_loglog)# A tibble: 38 x 7\n   `log(force)` `log(height)` .fitted   .hat .sigma  .cooksd\n          <dbl>         <dbl>   <dbl>  <dbl>  <dbl>    <dbl>\n 1         1.39          2.08   2.01  0.0280  0.676 1.28e- 2\n 2         2.71          2.07   1.98  0.0287  0.673 1.79e- 2\n 3         1.61          1.90   1.61  0.0499  0.684 8.06e-10\n 4         1.06          1.89   1.58  0.0530  0.679 1.69e- 2\n 5         1.16          1.61   0.945 0.142   0.683 1.01e- 2\n 6         2.25          2.07   1.98  0.0287  0.683 2.39e- 3\n 7         3.11          2.24   2.38  0.0301  0.673 1.90e- 2\n 8         2.00          2.12   2.10  0.0266  0.684 2.75e- 4\n 9         2.68          2.42   2.78  0.0561  0.684 6.30e- 4\n10         2.16          2.15   2.18  0.0263  0.684 5.34e- 6\n# ... with 28 more rows, and 1 more variable:\n#   .std.resid <dbl>\nggplot(crabs, aes(x = height, y = force)) +\n    geom_point() +\n    geom_smooth(method = \"lm\", se = FALSE, \n                formula = y ~ x, col=\"blue\", linetype = 2) +\n    geom_line(data = loglogdat, col = \"red\", linetype = 2, size = 1) +\n    annotate(\"text\", 7, 12, label = \"Linear Model\", col = \"blue\") +\n    annotate(\"text\", 10, 8, label = \"Log-Log Model\", col = \"red\") +\n    labs(title = \"Comparing the Linear and Log-Log Models for Crab Claw data\")"},{"path":"Hydrate-Study.html","id":"Hydrate-Study","chapter":"14 Dehydration Recovery","heading":"14 Dehydration Recovery","text":"hydrate data describe degree recovery takes place 90 minutes following treatment moderate severe dehydration, 36 children diagnosed hospital’s main pediatric clinic.Upon diagnosis study entry, patients treated electrolytic solution one seven dose levels (0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0 mEq/l) frozen, flavored, ice popsicle. degree rehydration determined using subjective scale based physical examination parental input, converted 0 100 point scale, representing percent recovery (recov.score). child’s age (years) weight (pounds) also available.First, ’ll check ranges (missing data) hydrate file.missing values, ranges make sense. especially egregious problems report.","code":"\nhydrate <- read_csv(\"data/hydrate.csv\")\n\nsummary(hydrate)       id         recov.score          dose      \n Min.   : 1.00   Min.   : 44.00   Min.   :0.000  \n 1st Qu.: 9.75   1st Qu.: 61.50   1st Qu.:1.000  \n Median :18.50   Median : 71.50   Median :1.500  \n Mean   :18.50   Mean   : 71.56   Mean   :1.569  \n 3rd Qu.:27.25   3rd Qu.: 80.00   3rd Qu.:2.500  \n Max.   :36.00   Max.   :100.00   Max.   :3.000  \n      age             weight     \n Min.   : 3.000   Min.   :22.00  \n 1st Qu.: 5.000   1st Qu.:34.50  \n Median : 6.500   Median :47.50  \n Mean   : 6.667   Mean   :46.89  \n 3rd Qu.: 8.000   3rd Qu.:57.25  \n Max.   :11.000   Max.   :76.00  "},{"path":"Hydrate-Study.html","id":"a-scatterplot-matrix","chapter":"14 Dehydration Recovery","heading":"14.1 A Scatterplot Matrix","text":"Next, ’ll use scatterplot matrix summarize relationships outcome recov.score key predictor dose well ancillary predictors age weight, less interest, expected related outcome. one uses ggpairs function GGally package, introduced Part Notes. place outcome bottom row, key predictor immediately , age weight top rows, using select function within `ggpairs call.can conclude ?looks like recov.score moderately strong negative relationship age weight (correlations case around -0.5), positive relationship dose (correlation = 0.36).distribution recov.score looks pretty close Normal. potential predictors (age, weight dose) show substantial non-Normality.age weight, ’d expect, show strong positive linear relationship, r = 0.94Neither age weight shows meaningful relationship dose. (r = 0.16)","code":"\nGGally::ggpairs(dplyr::select(hydrate, age, weight, dose, recov.score), \n                title = \"Scatterplot Matrix for hydrate data\")Registered S3 method overwritten by 'GGally':\n  method from   \n  +.gg   ggplot2"},{"path":"Hydrate-Study.html","id":"are-the-recovery-scores-well-described-by-a-normal-model","chapter":"14 Dehydration Recovery","heading":"14.2 Are the recovery scores well described by a Normal model?","text":"Next, ’ll thorough graphical summary outcome, recovery score.see serious problems assuming Normality recovery scores. outcome variable doesn’t way need follow Normal distribution, ’s nice , summaries involving means standard deviations make sense.","code":"\np1 <- ggplot(hydrate, aes(sample = recov.score)) +\n  geom_qq(col = '#440154') + geom_qq_line(col = \"red\") + \n  theme(aspect.ratio = 1) + \n  labs(title = \"Normal Q-Q plot: hydrate\")\n\np2 <- ggplot(hydrate, aes(x = recov.score)) +\n  geom_histogram(aes(y = stat(density)), \n                 bins = 10, fill = '#440154', col = '#FDE725') +\n  stat_function(fun = dnorm, \n                args = list(mean = mean(hydrate$recov.score), \n                            sd = sd(hydrate$recov.score)),\n                col = \"red\", lwd = 1.5) +\n  labs(title = \"Density Function: hydrate\")\n\np3 <- ggplot(hydrate, aes(x = recov.score, y = \"\")) +\n  geom_boxplot(fill = '#440154', outlier.color = '#440154') + \n  labs(title = \"Boxplot: hydrate\", y = \"\")\n\np1 + (p2 / p3 + plot_layout(heights = c(4,1)))\nmosaic::favstats(~ recov.score, data = hydrate) %>% kable(digits = 1)"},{"path":"Hydrate-Study.html","id":"simple-regression-using-dose-to-predict-recovery","chapter":"14 Dehydration Recovery","heading":"14.3 Simple Regression: Using Dose to predict Recovery","text":"start, consider simple (one predictor) regression model using dose alone predict % Recovery (recov.score). Ignoring age weight covariates, can conclude relationship?","code":""},{"path":"Hydrate-Study.html","id":"the-scatterplot-with-fitted-linear-model","chapter":"14 Dehydration Recovery","heading":"14.4 The Scatterplot, with fitted Linear Model","text":"","code":"\nggplot(hydrate, aes(x = dose, y = recov.score)) +\n    geom_point(size = 2) +\n    geom_smooth(method = \"lm\", formula = y ~ x, col = \"red\") +\n    labs(title = \"Simple Regression model for the hydrate data\",\n         x = \"Dose (mEq/l)\", y = \"Recovery Score (points)\")"},{"path":"Hydrate-Study.html","id":"the-fitted-linear-model","chapter":"14 Dehydration Recovery","heading":"14.5 The Fitted Linear Model","text":"obtain fitted linear regression model, use lm function:, fitted regression model (prediction model) recov.score = 63.9 + 4.88 dose.","code":"\nm1 <- lm(recov.score ~ dose, data = hydrate)\n\ntidy(m1) %>% kable(digits = 2)"},{"path":"Hydrate-Study.html","id":"confidence-intervals","chapter":"14 Dehydration Recovery","heading":"14.5.1 Confidence Intervals","text":"can obtain confidence intervals around coefficients fitted model tidy, ., 90% confidence interval slope dose ranges 1.21 8.55.","code":"\ntidy(m1, conf.int = TRUE, conf.level = 0.90) %>% kable(digits = 2)"},{"path":"Hydrate-Study.html","id":"coefficient-plots","chapter":"14 Dehydration Recovery","heading":"14.6 Coefficient Plots","text":"tidy method makes easy construct coefficient plots using ggplot2.Another option use geom_errorbarh setting, perhaps different color scheme…","code":"\ntd <- tidy(m1, conf.int = TRUE, conf.level = 0.90)\nggplot(td, aes(x = estimate, y = term, col = term)) +\n  geom_point() +\n  geom_crossbarh(aes(xmin = conf.low, xmax = conf.high)) +\n  geom_vline(xintercept = 0) +\n  guides(col = \"none\") +\n  labs(title = \"Estimates with 90% confidence intervals from m1 in hydrate\")\ntd <- tidy(m1, conf.int = TRUE, conf.level = 0.90)\nggplot(td, aes(x = estimate, y = term, col = term)) +\n  geom_point() +\n  geom_errorbarh(aes(xmin = conf.low, xmax = conf.high)) +\n  geom_vline(xintercept = 0) +\n  scale_color_viridis_d(end = 0.5) +\n  guides(col = \"none\") +\n  labs(title = \"Estimates with 90% confidence intervals from m1 in hydrate\")"},{"path":"Hydrate-Study.html","id":"the-summary-output","chapter":"14 Dehydration Recovery","heading":"14.7 The Summary Output","text":"get complete understanding fitted model, ’ll summarize .","code":"\nsummary(lm(recov.score ~ dose, data = hydrate))\nCall:\nlm(formula = recov.score ~ dose, data = hydrate)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-22.3360  -7.2763   0.0632   8.4233  23.9028 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   63.896      3.970  16.093   <2e-16 ***\ndose           4.881      2.172   2.247   0.0313 *  \n---\nSignif. codes:  \n0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 12.21 on 34 degrees of freedom\nMultiple R-squared:  0.1293,    Adjusted R-squared:  0.1037 \nF-statistic: 5.047 on 1 and 34 DF,  p-value: 0.03127"},{"path":"Hydrate-Study.html","id":"model-specification","chapter":"14 Dehydration Recovery","heading":"14.7.1 Model Specification","text":"first part output specifies model fit.\n, simple regression model predicts recov.score basis dose.\nNotice ’re treating dose quantitative variable. wanted dose treated factor, ’d specified model.\n, simple regression model predicts recov.score basis dose.Notice ’re treating dose quantitative variable. wanted dose treated factor, ’d specified model.","code":""},{"path":"Hydrate-Study.html","id":"residual-summary","chapter":"14 Dehydration Recovery","heading":"14.7.2 Residual Summary","text":"second part output summarizes regression residuals across subjects involved fitting model.\nresidual defined Actual value outcome minus predicted value outcome fitted model.\ncase, residual given child actual recov.score minus predicted recov.score according model, child.\nresidual summary gives us sense “incorrect” predictions hydrate observations.\npositive residual means observed value higher predicted value linear regression model, prediction low.\nnegative residual means observed value lower predicted value linear regression model, prediction high.\nresiduals center near 0 (ordinary least squares model fitting process designed mean residuals always zero)\nhope see median residuals also near zero, generally. case, median prediction 0.06 point low.\nminimum maximum show us largest prediction errors, made subjects used fit model.\n, predicted recovery score 22.3 points high one patient, another predicted recovery scores 23.9 points low.\nmiddle half predictions 8.4 points low 7.3 points high.\n\nresidual defined Actual value outcome minus predicted value outcome fitted model.case, residual given child actual recov.score minus predicted recov.score according model, child.residual summary gives us sense “incorrect” predictions hydrate observations.\npositive residual means observed value higher predicted value linear regression model, prediction low.\nnegative residual means observed value lower predicted value linear regression model, prediction high.\nresiduals center near 0 (ordinary least squares model fitting process designed mean residuals always zero)\nhope see median residuals also near zero, generally. case, median prediction 0.06 point low.\nminimum maximum show us largest prediction errors, made subjects used fit model.\n, predicted recovery score 22.3 points high one patient, another predicted recovery scores 23.9 points low.\nmiddle half predictions 8.4 points low 7.3 points high.\npositive residual means observed value higher predicted value linear regression model, prediction low.negative residual means observed value lower predicted value linear regression model, prediction high.residuals center near 0 (ordinary least squares model fitting process designed mean residuals always zero)hope see median residuals also near zero, generally. case, median prediction 0.06 point low.minimum maximum show us largest prediction errors, made subjects used fit model., predicted recovery score 22.3 points high one patient, another predicted recovery scores 23.9 points low.middle half predictions 8.4 points low 7.3 points high.","code":""},{"path":"Hydrate-Study.html","id":"coefficients-output","chapter":"14 Dehydration Recovery","heading":"14.7.3 Coefficients Output","text":"Coefficients output begins table estimated coefficients regression equation.\nGenerally, write simple regression model \\(y = \\beta_0 + \\beta_1 x\\).\nhydrate model, recov.score = \\(\\beta_0\\) + \\(\\beta_1\\) dose.\nfirst column table gives estimated \\(\\beta\\) coefficients model\nestimated intercept \\(\\hat{\\beta_0} = 63.9\\)\nestimated slope dose \\(\\hat{\\beta_1} = 4.88\\)\nThus, model recov.score= 63.9 + 4.88 dose\n\nGenerally, write simple regression model \\(y = \\beta_0 + \\beta_1 x\\).hydrate model, recov.score = \\(\\beta_0\\) + \\(\\beta_1\\) dose.first column table gives estimated \\(\\beta\\) coefficients model\nestimated intercept \\(\\hat{\\beta_0} = 63.9\\)\nestimated slope dose \\(\\hat{\\beta_1} = 4.88\\)\nThus, model recov.score= 63.9 + 4.88 dose\nestimated intercept \\(\\hat{\\beta_0} = 63.9\\)estimated slope dose \\(\\hat{\\beta_1} = 4.88\\)Thus, model recov.score= 63.9 + 4.88 doseWe interpret coefficients follows:intercept (63.9) predicted recov.score patient receiving dose 0 mEq/l electrolytic solution.slope (4.88) dose predicted change recov.score associated 1 mEq/l increase dose electrolytic solution.\nEssentially, two children like ones studied , give Roger popsicle dose X Sarah popsicle dose X + 1, model predicts Sarah recovery score 4.88 points higher Roger.\nconfidence interval output saw previously function confint(lm(recov.score ~ dose)), 95% confident true slope dose (0.47, 9.30) mEq/l. also 95% confident true intercept (55.8, 72.0).\nEssentially, two children like ones studied , give Roger popsicle dose X Sarah popsicle dose X + 1, model predicts Sarah recovery score 4.88 points higher Roger.confidence interval output saw previously function confint(lm(recov.score ~ dose)), 95% confident true slope dose (0.47, 9.30) mEq/l. also 95% confident true intercept (55.8, 72.0).","code":""},{"path":"Hydrate-Study.html","id":"correlation-and-slope","chapter":"14 Dehydration Recovery","heading":"14.7.4 Correlation and Slope","text":"like, can use cor function specify Pearson correlation recov.score dose, turns 0.36.\n- Note slope simple regression model follow sign Pearson correlation coefficient, case, positive.","code":"\nhydrate %$% cor(recov.score, dose)[1] 0.359528"},{"path":"Hydrate-Study.html","id":"coefficient-testing","chapter":"14 Dehydration Recovery","heading":"14.7.5 Coefficient Testing","text":"Next coefficient summary regression table estimated standard error, followed coefficient’s t value (coefficient value divided standard error), associated two-tailed p value test :H0: coefficient’s \\(\\beta\\) value = 0 vs. HA: coefficient’s \\(\\beta\\) value \\(\\neq\\) 0.slope coefficient, can interpret choice :H0: predictor adds predictive value model vs. HA: predictor adds predictive value model.hydrate simple regression model, running either tidy just confint function shown , can establish confidence interval estimated regression coefficients.slope dose fact zero, mean knowing dose information additional value predicting outcome just guessing mean recov.score every subject., since confidence interval slope dose include zero, appears least evidence model m1 effective model ignores dose information (simply predicts mean recov.score subject.) ’s saying much, actually.","code":"\nsummary(lm(recov.score ~ dose, data = hydrate))\nCall:\nlm(formula = recov.score ~ dose, data = hydrate)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-22.3360  -7.2763   0.0632   8.4233  23.9028 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   63.896      3.970  16.093   <2e-16 ***\ndose           4.881      2.172   2.247   0.0313 *  \n---\nSignif. codes:  \n0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 12.21 on 34 degrees of freedom\nMultiple R-squared:  0.1293,    Adjusted R-squared:  0.1037 \nF-statistic: 5.047 on 1 and 34 DF,  p-value: 0.03127\ntidy(m1, conf.int = TRUE, conf.level = 0.95) %>% kable(digits = 2)\nconfint(m1, level = .95)                2.5 %    97.5 %\n(Intercept) 55.826922 71.964589\ndose         0.465695  9.295466"},{"path":"Hydrate-Study.html","id":"summarizing-the-quality-of-fit","chapter":"14 Dehydration Recovery","heading":"14.7.6 Summarizing the Quality of Fit","text":"next part regression summary output summary fit quality.residual standard error estimates standard deviation prediction errors made model.assumptions hold, model produce residuals follow Normal distribution mean 0 standard deviation equal residual standard error.\n’d expect roughly 95% residuals fall -2(12.21) +2(12.21), roughly -24.4 +24.4 ’d see virtually residuals outside range -3(12.21) +3(12.21), roughly -36.6 +36.6.\noutput top summary tells us observed regression residuals, actually range -22 +24.\ncontext, ’s hard know whether happy . scale 0 100, rarely missing 24 seems OK , terrific.\n’d expect roughly 95% residuals fall -2(12.21) +2(12.21), roughly -24.4 +24.4 ’d see virtually residuals outside range -3(12.21) +3(12.21), roughly -36.6 +36.6.output top summary tells us observed regression residuals, actually range -22 +24.context, ’s hard know whether happy . scale 0 100, rarely missing 24 seems OK , terrific.degrees freedom denominator degrees freedom ANOVA follow. calculation \\(n - k\\), \\(n\\) = number observations \\(k\\) number coefficients estimated regression (including intercept slopes).\n, 36 observations model, fit k = 2 coefficients; slope intercept, simple regression model, df = 36 - 2 = 34.\n, 36 observations model, fit k = 2 coefficients; slope intercept, simple regression model, df = 36 - 2 = 34.multiple R-squared value usually just referred R-squared.interpreted proportion variation outcome variable accounted regression model.\n, ’ve accounted just 13% variation % Recovery using Dose.\n, ’ve accounted just 13% variation % Recovery using Dose.R multiple R-squared Pearson correlation recov.score dose, case 0.3595.\nSquaring value gives R-squared simple regression.\n(0.3595)^2 = 0.129\nSquaring value gives R-squared simple regression.(0.3595)^2 = 0.129R-squared greedy.R-squared always suggest make models big possible, often including variables dubious predictive value.result, various methods adjusting penalizing R-squared wind smaller models.adjusted R-squared often useful way compare multiple models response.\n\\(R^2_{adj} = 1 - \\frac{(1-R^2)(n - 1)}{n - k}\\), \\(n\\) = number observations \\(k\\) number coefficients estimated regression (including intercept slopes).\n, case, \\(R^2_{adj} = 1 - \\frac{(1 - 0.1293)(35)}{34} = 0.1037\\)\nadjusted R-squared value , technically, proportion anything, comparable across models outcome.\nadjusted R-squared always less (unadjusted) R-squared.\n\\(R^2_{adj} = 1 - \\frac{(1-R^2)(n - 1)}{n - k}\\), \\(n\\) = number observations \\(k\\) number coefficients estimated regression (including intercept slopes)., case, \\(R^2_{adj} = 1 - \\frac{(1 - 0.1293)(35)}{34} = 0.1037\\)adjusted R-squared value , technically, proportion anything, comparable across models outcome.adjusted R-squared always less (unadjusted) R-squared.","code":""},{"path":"Hydrate-Study.html","id":"anova-f-test","chapter":"14 Dehydration Recovery","heading":"14.7.7 ANOVA F test","text":"last part standard summary regression model overall ANOVA F test.hypotheses test :H0: coefficients model (intercept) \\(\\beta\\) = 0 vs.HA: least one regression slope \\(\\beta \\neq\\) 0Since simple regression just one predictor, ANOVA F test hypotheses exactly t test dose:H0: slope dose \\(\\beta\\) = 0 vs.HA: slope dose \\(\\beta \\neq\\) 0In case, F statistic 5.05 1 34 degrees freedom, yielding p = 0.03This provides evidence “something” model (, dose predictor) predicts outcome degree beyond easily attributed chance alone. actually surprising, especially interesting. confidence interval slope definitely interesting .simple regression (regression one predictor), t test slope (dose) always provides p value ANOVA F test.\nF test statistic simple regression always definition just square slope’s t test statistic.\n, F = 5.047, square t = 2.247 Coefficients output\nF test statistic simple regression always definition just square slope’s t test statistic., F = 5.047, square t = 2.247 Coefficients outputThis test basically just combination R-squared value (13%) sample size. don’t learn much ’s practically interesting useful.","code":""},{"path":"Hydrate-Study.html","id":"viewing-the-complete-anova-table","chapter":"14 Dehydration Recovery","heading":"14.8 Viewing the complete ANOVA table","text":"can obtain complete ANOVA table associated particular model, details behind F test using anova function:R-squared regression model equal \\(\\eta^2\\) ANOVA model.\ndivide SS(dose) = 752.2 total sum squares (752.2 + 5066.7), ’ll get multiple R-squared [0.1293]\ndivide SS(dose) = 752.2 total sum squares (752.2 + 5066.7), ’ll get multiple R-squared [0.1293]Note ANOVA model get treated dose factor seven levels, rather quantitative variable.","code":"\nanova(lm(recov.score ~ dose, data = hydrate))Analysis of Variance Table\n\nResponse: recov.score\n          Df Sum Sq Mean Sq F value  Pr(>F)  \ndose       1  752.2  752.15  5.0473 0.03127 *\nResiduals 34 5066.7  149.02                  \n---\nSignif. codes:  \n0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"},{"path":"Hydrate-Study.html","id":"using-glance-to-summarize-the-models-fit","chapter":"14 Dehydration Recovery","heading":"14.9 Using glance to summarize the model’s fit","text":"applied linear model, glance function broom package summarizes 12 characteristics model’s fit.Let’s look eight ’ve already addressed.’ve discussed R-square value, shown r.squared.’ve also discussed adjusted R-square value, adj.r.squaredsigma residual standard error.statistic ANOVA F statistic.p.value p value associated ANOVA F statistic.df numerator degrees freedom (, df associated dose) ANOVA test associated model.df.residual denominator degrees freedom (df associated residual) ANOVA test.Remember F-statistic bottom summary output provides last four statistics, well.nobs number observations (rows) used fit model.Now, let’s look remaining four summaries:logLik log-likelihood value model, commonly used model (like ordinary least squares model fit lm fit using method maximum likelihood). Thus, log-likelihood value maximized fit.AIC Akaike Information Criterion model. comparing models fitted maximum likelihood outcome variable (using transformation, example), smaller AIC, better fit.BIC Bayes Information Criterion model. comparing models fitted maximum likelihood outcome variable (using transformation, example), smaller BIC, better fit. BIC often prefers models fewer coefficients estimate AIC.\nAIC BIC can estimated using several different approaches R, ’ll need use one across multiple models ’re comparing results, concepts defined constant.\nAIC BIC can estimated using several different approaches R, ’ll need use one across multiple models ’re comparing results, concepts defined constant.deviance fitted model’s deviance, measure lack fit. generalization residual sum squares seen ANOVA table, takes value case simple linear regression model fit lm . generalized linear models, ’ll use hypothesis testing, just ANOVA table linear model case.","code":"\nglance(m1) %>% select(r.squared:df, df.residual, nobs) %>%\n  kable(digits = c(3, 3, 1, 2, 3, 0, 0, 0))\nglance(m1) %>% select(logLik:deviance) %>%\n  kable(digits = 1)"},{"path":"Hydrate-Study.html","id":"plotting-residuals-vs.-fitted-values","chapter":"14 Dehydration Recovery","heading":"14.10 Plotting Residuals vs. Fitted Values","text":"save residuals predicted (fitted) values simple regression model, can use resid fitted commands, respectively, can use augment function broom package obtain tidy data set containing objects others.can also obtain plot residuals vs. fitted values m1 using following code base R.hope plot see generally random scatter points, perhaps looking like “fuzzy football.” Since seven possible dose values, obtain seven distinct predicted values, explains seven vertical lines plot. , smooth red line indicates gentle curve, evidence strong curve, regular pattern residual plot.","code":"\naugment(m1) %>%\n    ggplot(., aes(x = .fitted, y = .resid)) +\n    geom_point() +\n    geom_smooth(method = \"loess\", formula = y ~ x, se = F) +\n    geom_smooth(method = \"lm\", formula = y ~ x, se = F, col = \"red\") +\n    labs(title = \"Residuals vs. Fitted values for Model m1\")\nplot(m1, which = 1)"},{"path":"WCGS-Study.html","id":"WCGS-Study","chapter":"15 The WCGS","heading":"15 The WCGS","text":"","code":""},{"path":"WCGS-Study.html","id":"the-western-collaborative-group-study-wcgs-data-set","chapter":"15 The WCGS","heading":"15.1 The Western Collaborative Group Study (wcgs) data set","text":"Vittinghoff et al.33 explore data Western Collaborative Group Study (WCGS) great detail34. ’ll touch lightly key issues Chapter.Western Collaborative Group Study (WCGS) designed test hypothesis -called Type behavior pattern (TABP) - “characterized particularly excessive drive, aggressiveness, ambition, frequently association relatively greater preoccupation competitive activity, vocational deadlines, similar pressures” - cause coronary heart disease (CHD). Two additional goals, developed later study, (1) investigate comparability formulas developed WCGS Framingham Study (FS) prediction CHD risk, (2) determine addition TABP existing multivariate prediction formula affects ability select subjects intervention programs.study enrolled 3,000 men ages 39-59 employed San Francisco Los Angeles, 1960 1961., 3154 rows (subjects) 22 columns (variables). importing data creating tibble read_csv, used mutate(across((.character), as_factor) convert variables containing character data factors.","code":"\nwcgs <- read_csv(\"data/wcgs.csv\") %>%\n    mutate(across(where(is.character), as_factor))\n\nwcgs# A tibble: 3,154 x 22\n      id   age agec  height weight lnwght wghtcat   bmi\n   <dbl> <dbl> <fct>  <dbl>  <dbl>  <dbl> <fct>   <dbl>\n 1  2343    50 46-50     67    200   5.30 170-200  31.3\n 2  3656    51 51-55     73    192   5.26 170-200  25.3\n 3  3526    59 56-60     70    200   5.30 170-200  28.7\n 4 22057    51 51-55     69    150   5.01 140-170  22.1\n 5 12927    44 41-45     71    160   5.08 140-170  22.3\n 6 16029    47 46-50     64    158   5.06 140-170  27.1\n 7  3894    40 35-40     70    162   5.09 140-170  23.2\n 8 11389    41 41-45     70    160   5.08 140-170  23.0\n 9 12681    50 46-50     71    195   5.27 170-200  27.2\n10 10005    43 41-45     68    187   5.23 170-200  28.4\n# ... with 3,144 more rows, and 14 more variables:\n#   sbp <dbl>, lnsbp <dbl>, dbp <dbl>, chol <dbl>,\n#   behpat <fct>, dibpat <fct>, smoke <fct>, ncigs <dbl>,\n#   arcus <dbl>, chd69 <fct>, typchd69 <dbl>,\n#   time169 <dbl>, t1 <dbl>, uni <dbl>"},{"path":"WCGS-Study.html","id":"structure-of-wcgs","chapter":"15 The WCGS","heading":"15.1.1 Structure of wcgs","text":"can specify (sometimes terrible) variable names, names function, can add elements structure, can identify elements particular interest.","code":"\nstr(wcgs)spec_tbl_df [3,154 x 22] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ id      : num [1:3154] 2343 3656 3526 22057 12927 ...\n $ age     : num [1:3154] 50 51 59 51 44 47 40 41 50 43 ...\n $ agec    : Factor w/ 5 levels \"46-50\",\"51-55\",..: 1 2 3 2 4 1 5 4 1 4 ...\n $ height  : num [1:3154] 67 73 70 69 71 64 70 70 71 68 ...\n $ weight  : num [1:3154] 200 192 200 150 160 158 162 160 195 187 ...\n $ lnwght  : num [1:3154] 5.3 5.26 5.3 5.01 5.08 ...\n $ wghtcat : Factor w/ 4 levels \"170-200\",\"140-170\",..: 1 1 1 2 2 2 2 2 1 1 ...\n $ bmi     : num [1:3154] 31.3 25.3 28.7 22.1 22.3 ...\n $ sbp     : num [1:3154] 132 120 158 126 126 116 122 130 112 120 ...\n $ lnsbp   : num [1:3154] 4.88 4.79 5.06 4.84 4.84 ...\n $ dbp     : num [1:3154] 90 74 94 80 80 76 78 84 70 80 ...\n $ chol    : num [1:3154] 249 194 258 173 214 206 190 212 130 233 ...\n $ behpat  : Factor w/ 4 levels \"A1\",\"A2\",\"B3\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ dibpat  : Factor w/ 2 levels \"Type A\",\"Type B\": 1 1 1 1 1 1 1 1 1 1 ...\n $ smoke   : Factor w/ 2 levels \"Yes\",\"No\": 1 1 2 2 2 1 2 1 2 1 ...\n $ ncigs   : num [1:3154] 25 25 0 0 0 80 0 25 0 25 ...\n $ arcus   : num [1:3154] 1 0 1 1 0 0 0 0 1 0 ...\n $ chd69   : Factor w/ 2 levels \"No\",\"Yes\": 1 1 1 1 1 1 1 1 1 1 ...\n $ typchd69: num [1:3154] 0 0 0 0 0 0 0 0 0 0 ...\n $ time169 : num [1:3154] 1367 2991 2960 3069 3081 ...\n $ t1      : num [1:3154] -1.63 -4.06 0.64 1.12 2.43 ...\n $ uni     : num [1:3154] 0.486 0.186 0.728 0.624 0.379 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   id = col_double(),\n  ..   age = col_double(),\n  ..   agec = col_character(),\n  ..   height = col_double(),\n  ..   weight = col_double(),\n  ..   lnwght = col_double(),\n  ..   wghtcat = col_character(),\n  ..   bmi = col_double(),\n  ..   sbp = col_double(),\n  ..   lnsbp = col_double(),\n  ..   dbp = col_double(),\n  ..   chol = col_double(),\n  ..   behpat = col_character(),\n  ..   dibpat = col_character(),\n  ..   smoke = col_character(),\n  ..   ncigs = col_double(),\n  ..   arcus = col_double(),\n  ..   chd69 = col_character(),\n  ..   typchd69 = col_double(),\n  ..   time169 = col_double(),\n  ..   t1 = col_double(),\n  ..   uni = col_double()\n  .. )\n - attr(*, \"problems\")=<externalptr> "},{"path":"WCGS-Study.html","id":"codebook-for-wcgs","chapter":"15 The WCGS","heading":"15.1.2 Codebook for wcgs","text":"table lovingly hand-crafted, involved lot typing. ’ll look better ways 432.","code":""},{"path":"WCGS-Study.html","id":"quick-summary","chapter":"15 The WCGS","heading":"15.1.3 Quick Summary","text":"detailed description, might consider Hmisc::describe, psych::describe, mosaic::favstats, etc.","code":"\nsummary(wcgs)       id             age           agec     \n Min.   : 2001   Min.   :39.00   46-50: 750  \n 1st Qu.: 3741   1st Qu.:42.00   51-55: 528  \n Median :11406   Median :45.00   56-60: 242  \n Mean   :10478   Mean   :46.28   41-45:1091  \n 3rd Qu.:13115   3rd Qu.:50.00   35-40: 543  \n Max.   :22101   Max.   :59.00               \n                                             \n     height          weight        lnwght     \n Min.   :60.00   Min.   : 78   Min.   :4.357  \n 1st Qu.:68.00   1st Qu.:155   1st Qu.:5.043  \n Median :70.00   Median :170   Median :5.136  \n Mean   :69.78   Mean   :170   Mean   :5.128  \n 3rd Qu.:72.00   3rd Qu.:182   3rd Qu.:5.204  \n Max.   :78.00   Max.   :320   Max.   :5.768  \n                                              \n    wghtcat          bmi             sbp       \n 170-200:1171   Min.   :11.19   Min.   : 98.0  \n 140-170:1538   1st Qu.:22.96   1st Qu.:120.0  \n > 200  : 213   Median :24.39   Median :126.0  \n < 140  : 232   Mean   :24.52   Mean   :128.6  \n                3rd Qu.:25.84   3rd Qu.:136.0  \n                Max.   :38.95   Max.   :230.0  \n                                               \n     lnsbp            dbp              chol       behpat   \n Min.   :4.585   Min.   : 58.00   Min.   :103.0   A1: 264  \n 1st Qu.:4.787   1st Qu.: 76.00   1st Qu.:197.2   A2:1325  \n Median :4.836   Median : 80.00   Median :223.0   B3:1216  \n Mean   :4.850   Mean   : 82.02   Mean   :226.4   B4: 349  \n 3rd Qu.:4.913   3rd Qu.: 86.00   3rd Qu.:253.0            \n Max.   :5.438   Max.   :150.00   Max.   :645.0            \n                                  NA's   :12               \n    dibpat     smoke          ncigs          arcus       \n Type A:1589   Yes:1502   Min.   : 0.0   Min.   :0.0000  \n Type B:1565   No :1652   1st Qu.: 0.0   1st Qu.:0.0000  \n                          Median : 0.0   Median :0.0000  \n                          Mean   :11.6   Mean   :0.2985  \n                          3rd Qu.:20.0   3rd Qu.:1.0000  \n                          Max.   :99.0   Max.   :1.0000  \n                                         NA's   :2       \n chd69         typchd69         time169    \n No :2897   Min.   :0.0000   Min.   :  18  \n Yes: 257   1st Qu.:0.0000   1st Qu.:2842  \n            Median :0.0000   Median :2942  \n            Mean   :0.1363   Mean   :2684  \n            3rd Qu.:0.0000   3rd Qu.:3037  \n            Max.   :3.0000   Max.   :3430  \n                                           \n       t1                 uni           \n Min.   :-47.43147   Min.   :0.0007097  \n 1st Qu.: -1.00337   1st Qu.:0.2573755  \n Median :  0.00748   Median :0.5157779  \n Mean   : -0.03336   Mean   :0.5052159  \n 3rd Qu.:  0.97575   3rd Qu.:0.7559902  \n Max.   : 47.01623   Max.   :0.9994496  \n NA's   :39                             "},{"path":"WCGS-Study.html","id":"are-the-sbps-normally-distributed","chapter":"15 The WCGS","heading":"15.2 Are the SBPs Normally Distributed?","text":"Consider question whether distribution systolic blood pressure results well-approximated Normal.Since data contain sbp lnsbp (natural logarithm), let’s compare . Note preparing graph, ’ll need change location text annotation.can also look Normal Q-Q plots, instance…’s best small improvement sbp lnsbp terms approximation Normal distribution.","code":"\nres <- mosaic::favstats(~ sbp, data = wcgs)\nbin_w <- 5 # specify binwidth\n\nggplot(wcgs, aes(x = sbp)) +\n    geom_histogram(binwidth = bin_w, \n                   fill = \"orchid\", \n                   col = \"blue\") +\n    stat_function(\n        fun = function(x) dnorm(x, mean = res$mean, \n                                sd = res$sd) * \n            res$n * bin_w,\n        col = \"navy\") +\n    labs(title = \"Systolic BP for `wcgs` subjects\",\n     x = \"Systolic BP (mm Hg)\", y = \"\",\n     caption = \"Superimposed Normal model\")\nres <- mosaic::favstats(~ lnsbp, data = wcgs)\nbin_w <- 0.05 # specify binwidth\n\nggplot(wcgs, aes(x = lnsbp)) +\n    geom_histogram(binwidth = bin_w, \n                   fill = \"orange\", \n                   col = \"blue\") +\n    stat_function(\n        fun = function(x) dnorm(x, mean = res$mean, \n                                sd = res$sd) * \n            res$n * bin_w,\n        col = \"navy\") +\n    labs(title = \"ln(Systolic BP) for `wcgs` subjects\",\n     x = \"ln(Systolic BP)\", y = \"\",\n     caption = \"Superimposed Normal model\")\np1 <- ggplot(wcgs, aes(sample = sbp)) +\n    geom_qq(color = \"orchid\") + \n    geom_qq_line(color = \"red\") +\n    labs(y = \"Ordered SBP\", title = \"sbp in wcgs\")\n\np2 <- ggplot(wcgs, aes(sample = lnsbp)) +\n    geom_qq(color = \"orange\") + \n    geom_qq_line(color = \"red\") +\n    labs(y = \"Ordered ln(SBP)\", title = \"ln(sbp) in wcgs\")\n\n## next step requires library(patchwork)\n\np1 + p2 + \n    plot_annotation(title = \"Normal Q-Q plots of SBP and ln(SBP) in wcgs\")"},{"path":"WCGS-Study.html","id":"identifying-and-describing-sbp-outliers","chapter":"15 The WCGS","heading":"15.3 Identifying and Describing SBP outliers","text":"looks like ’s outlier (series ) SBP data.maximum value 230, clearly extreme value data set. One way gauge describe observation’s Z score, number standard deviations away mean observation falls. , maximum value, 230 6.71 standard deviations mean, thus Z score 6.7.negative Z score indicate point mean, positive Z score indicates, ’ve seen, point mean. minimum systolic blood pressure, 98 2.03 standard deviations mean, Z score -2.Recall Empirical Rule suggests variable follows Normal distribution, approximately 95% observations falling inside Z score (-2, 2), 99.74% falling inside Z score range (-3, 3). systolic blood pressures appear Normally distributed?","code":"\nggplot(wcgs, aes(x = \"\", y = sbp)) +\n    geom_violin() +\n    geom_boxplot(width = 0.3, fill = \"royalblue\", \n                 outlier.color = \"royalblue\") +\n    labs(title = \"Boxplot with Violin of SBP in `wcgs` data\",\n         y = \"Systolic Blood Pressure (mm Hg)\", \n         x = \"\") +\n    coord_flip() \nwcgs %$% Hmisc::describe(sbp)sbp \n       n  missing distinct     Info     Mean      Gmd \n    3154        0       62    0.996    128.6    16.25 \n     .05      .10      .25      .50      .75      .90 \n     110      112      120      126      136      148 \n     .95 \n     156 \n\nlowest :  98 100 102 104 106, highest: 200 208 210 212 230"},{"path":"WCGS-Study.html","id":"does-weight-category-relate-to-sbp","chapter":"15 The WCGS","heading":"15.4 Does Weight Category Relate to SBP?","text":"data collected four groups based subject’s weight (pounds).","code":"\nggplot(wcgs, aes(x = wghtcat, y = sbp)) +\n    geom_violin() +\n    geom_boxplot(aes(fill = wghtcat), width = 0.3, notch = TRUE) +\n    scale_fill_viridis_d() +\n    guides(fill = \"none\") + \n    labs(title = \"Boxplot of Systolic BP by Weight Category in WCGS\", \n         x = \"Weight Category\", y = \"Systolic Blood Pressure\")"},{"path":"WCGS-Study.html","id":"re-leveling-a-factor","chapter":"15 The WCGS","heading":"15.5 Re-Leveling a Factor","text":"Well, ’s good. really want weight categories (levels) ordered sensibly.Like factor variables R, categories specified levels. want change order levels new version factor variable make sense. multiple ways , prefer fct_relevel function forcats package (part tidyverse.) order appropriate?’ll add new variable wcgs data called weight_f relevels wghtcat data.forcats package, check Grolemund Wickham,35 especially Section Factors.","code":"\nwcgs %>% tabyl(wghtcat) wghtcat    n    percent\n 170-200 1171 0.37127457\n 140-170 1538 0.48763475\n   > 200  213 0.06753329\n   < 140  232 0.07355739\nwcgs <- wcgs %>%\n    mutate(weight_f = fct_relevel(wghtcat, \"< 140\", \"140-170\", \"170-200\", \"> 200\"))\n\nwcgs %>% tabyl(weight_f) weight_f    n    percent\n    < 140  232 0.07355739\n  140-170 1538 0.48763475\n  170-200 1171 0.37127457\n    > 200  213 0.06753329"},{"path":"WCGS-Study.html","id":"sbp-by-weight-category","chapter":"15 The WCGS","heading":"15.5.1 SBP by Weight Category","text":"might see details well ridgeline plot, .plots suggest, patients heavier groups generally higher systolic blood pressures.","code":"\nggplot(wcgs, aes(x = weight_f, y = sbp, fill = weight_f)) +\n    geom_boxplot(notch = TRUE) +\n    scale_fill_viridis_d() +\n    guides(fill = \"none\") +\n    labs(title = \"Systolic Blood Pressure by Reordered Weight Category in WCGS\", \n         x = \"Weight Category\", y = \"Systolic Blood Pressure\")\nwcgs %>%\n    ggplot(aes(x = sbp, y = weight_f, fill = weight_f, height = ..density..)) +\n    ggridges::geom_density_ridges(scale = 2) +\n    scale_fill_viridis_d() +\n    guides(fill = \"none\") +\n    labs(title = \"SBP by Weight Category (wcgs)\",\n         x = \"Systolic Blood Pressure\",\n         y = \"Weight Category\") Picking joint bandwidth of 3.74\nmosaic::favstats(sbp ~ weight_f, data = wcgs)  weight_f min  Q1 median  Q3 max     mean       sd    n\n1    < 140  98 112    120 130 196 123.1379 14.73394  232\n2  140-170 100 118    124 134 192 126.2939 13.65294 1538\n3  170-200 100 120    130 140 230 131.1136 15.57024 1171\n4    > 200 110 126    132 150 212 137.8685 16.75522  213\n  missing\n1       0\n2       0\n3       0\n4       0"},{"path":"WCGS-Study.html","id":"are-weight-and-sbp-linked","chapter":"15 The WCGS","heading":"15.6 Are Weight and SBP Linked?","text":"Let’s build scatter plot SBP (Outcome) Weight (Predictor), rather breaking categories.mass data hidden us - showing 3154 points one plot can produce little blur lots points top .least squares regression line (red), loess scatterplot smoother, (blue) can help.relationship systolic blood pressure weight appears close linear, course considerable scatter around generally linear relationship. turns Pearson correlation two variables 0.253.","code":"\nggplot(wcgs, aes(x = weight, y = sbp)) +\n    geom_point(size=3, shape=1, color=\"forestgreen\") + ## default size = 2\n    stat_smooth(method=lm, color=\"red\") + ## add se=FALSE to hide conf. interval\n    stat_smooth(method=loess, se=FALSE, color=\"blue\") +\n    ggtitle(\"SBP vs. Weight in 3,154 WCGS Subjects\") "},{"path":"WCGS-Study.html","id":"sbp-and-weight-by-arcus-senilis-groups","chapter":"15 The WCGS","heading":"15.7 SBP and Weight by Arcus Senilis groups?","text":"issue interest us assess whether SBP-Weight relationship see similar among subjects arcus senilis .Arcus senilis old age syndrome white, grey, blue opaque ring corneal margin (peripheral corneal opacity), white ring front periphery iris. present birth fades; however, quite commonly present elderly. can also appear earlier life result hypercholesterolemia.Wikipedia article Arcus Senilis, retrieved 2017-08-15Let’s start quick look arcus data.2 missing values, probably want something plotting data, may also want create factor variable meaningful labels 1 (means yes, arcus senilis present) 0 (means , isn’t.)Let’s build version wcgs data eliminates missing data variables immediate interest, plot SBP-weight relationship groups patients without arcus senilis.","code":"\nwcgs %>% tabyl(arcus) arcus    n      percent valid_percent\n     0 2211 0.7010145847     0.7014594\n     1  941 0.2983512999     0.2985406\n    NA    2 0.0006341154            NA\nwcgs <- wcgs %>%\n    mutate(arcus_f = fct_recode(factor(arcus),\n                                \"Arcus senilis\" = \"1\",\n                                \"No arcus senilis\" = \"0\"),\n           arcus_f = fct_relevel(arcus_f, \"Arcus senilis\"))\n\nwcgs %>% tabyl(arcus_f, arcus)          arcus_f    0   1 NA_\n    Arcus senilis    0 941   0\n No arcus senilis 2211   0   0\n             <NA>    0   0   2\nwcgs %>%\n    filter(complete.cases(arcus_f, sbp, weight)) %>%\n    ggplot(aes(x = weight, y = sbp, group = arcus_f)) +\n    geom_point(shape = 1) + \n    stat_smooth(method=lm, color=\"red\") +\n    stat_smooth(method=loess, se=FALSE, color=\"blue\") +\n    labs(title = \"SBP vs. Weight by Arcus Senilis status\",\n         caption = \"3,152 Western Collaborative Group Study subjects with known arcus senilis status\") + \n    facet_wrap(~ arcus_f) "},{"path":"WCGS-Study.html","id":"linear-model-for-sbp-weight-relationship-subjects-without-arcus-senilis","chapter":"15 The WCGS","heading":"15.8 Linear Model for SBP-Weight Relationship: subjects without Arcus Senilis","text":"linear model 2211 patients without Arcus Senilis R-squared = 6.87%.regression equation 95.92 - 0.19 weight, patients without Arcus Senilis.","code":"\nmodel.noarcus <- \n    lm(sbp ~ weight, data = filter(wcgs, arcus == 0))\n\ntidy(model.noarcus) %>% kable(digits = 2)\nglance(model.noarcus) %>% select(r.squared:p.value, AIC) %>% kable(digits = 3)\nsummary(model.noarcus)\nCall:\nlm(formula = sbp ~ weight, data = filter(wcgs, arcus == 0))\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-29.011 -10.251  -2.447   7.553  99.848 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  95.9219     2.5552   37.54   <2e-16 ***\nweight        0.1902     0.0149   12.77   <2e-16 ***\n---\nSignif. codes:  \n0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 14.8 on 2209 degrees of freedom\nMultiple R-squared:  0.0687,    Adjusted R-squared:  0.06828 \nF-statistic:   163 on 1 and 2209 DF,  p-value: < 2.2e-16"},{"path":"WCGS-Study.html","id":"linear-model-for-sbp-weight-relationship-subjects-with-arcus-senilis","chapter":"15 The WCGS","heading":"15.9 Linear Model for SBP-Weight Relationship: subjects with Arcus Senilis","text":"linear model 941 patients Arcus Senilis R-squared = 5.49%.regression equation 101.88 - 0.163 weight, patients Arcus Senilis.","code":"\nmodel.witharcus <- \n    lm(sbp ~ weight, data = filter(wcgs, arcus == 1))\n\ntidy(model.witharcus) %>% kable(digits = 2)\nglance(model.witharcus) %>% select(r.squared:p.value, AIC) %>% kable(digits = 3)\nsummary(model.witharcus)\nCall:\nlm(formula = sbp ~ weight, data = filter(wcgs, arcus == 1))\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-30.335  -9.636  -1.961   7.973  76.738 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 101.87847    3.75572  27.126  < 2e-16 ***\nweight        0.16261    0.02201   7.388 3.29e-13 ***\n---\nSignif. codes:  \n0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 14.19 on 939 degrees of freedom\nMultiple R-squared:  0.05494,   Adjusted R-squared:  0.05393 \nF-statistic: 54.58 on 1 and 939 DF,  p-value: 3.29e-13"},{"path":"WCGS-Study.html","id":"including-arcus-status-in-the-model","chapter":"15 The WCGS","heading":"15.10 Including Arcus Status in the model","text":"actual regression equation setting includes weight, indicator variable (1 = yes, 0 = ) arcus senilis status, product term combining weight 1/0 indicator. 432, ’ll spend substantial time energy discussing product terms, ’ll much 431.Note use product term weight*arcus setup model allow slope weight intercept term model change depending arcus senilis status.\npatient arcus, regression equation SBP = 95.92 + 0.19 weight + 5.96 (1) - 0.028 weight (1) = 101.88 + 0.162 weight.\npatient without arcus senilis, regression equation SBP = 95.92 + 0.19 weight + 5.96 (0) - 0.028 weight (0) = 95.92 + 0.19 weight.\npatient arcus, regression equation SBP = 95.92 + 0.19 weight + 5.96 (1) - 0.028 weight (1) = 101.88 + 0.162 weight.patient without arcus senilis, regression equation SBP = 95.92 + 0.19 weight + 5.96 (0) - 0.028 weight (0) = 95.92 + 0.19 weight.linear model including interaction weight arcus predict sbp 3152 patients known Arcus Senilis status R-squared = 6.6%. , ’ll discuss interaction substantially 432.","code":"\nmodel3 <- lm(sbp ~ weight * arcus, data = filter(wcgs, !is.na(arcus)))\n\ntidy(model3) %>% kable(digits = 2)\nglance(model3) %>% select(r.squared:p.value, AIC) %>% kable(digits = 3)\nsummary(model3)\nCall:\nlm(formula = sbp ~ weight * arcus, data = filter(wcgs, !is.na(arcus)))\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-30.335 -10.152  -2.349   7.669  99.848 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  95.92190    2.52440  37.998   <2e-16 ***\nweight        0.19017    0.01472  12.921   <2e-16 ***\narcus         5.95657    4.61972   1.289    0.197    \nweight:arcus -0.02756    0.02703  -1.019    0.308    \n---\nSignif. codes:  \n0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 14.62 on 3148 degrees of freedom\nMultiple R-squared:  0.06595,   Adjusted R-squared:  0.06506 \nF-statistic: 74.09 on 3 and 3148 DF,  p-value: < 2.2e-16"},{"path":"WCGS-Study.html","id":"predictions-from-these-linear-models","chapter":"15 The WCGS","heading":"15.11 Predictions from these Linear Models","text":"predicted SBP subject weighing 175 pounds?change subject weighs 200 pounds?Recall thatWithout Arcus Senilis, linear model SBP = 95.9 + 0.19 x weightWith Arcus Senilis, linear model SBP = 101.9 + 0.16 x weightSo predictions 175 pound subject :95.9 + 0.19 x 175 = 129 mm Hg without Arcus Senilis, and95.9 + 0.19 x 175 = 129 mm Hg without Arcus Senilis, and101.9 + 0.16 x 175 = 130 mm Hg Arcus Senilis.101.9 + 0.16 x 175 = 130 mm Hg Arcus Senilis.thus, predictions 200 pound subject :95.9 + 0.19 x 200 = 134 mm Hg without Arcus Senilis, and95.9 + 0.19 x 200 = 134 mm Hg without Arcus Senilis, and101.9 + 0.16 x 200 = 134.4 mm Hg Arcus Senilis.101.9 + 0.16 x 200 = 134.4 mm Hg Arcus Senilis.","code":""},{"path":"WCGS-Study.html","id":"scatterplots-with-facets-across-a-categorical-variable","chapter":"15 The WCGS","heading":"15.12 Scatterplots with Facets Across a Categorical Variable","text":"can use facets ggplot2 show scatterplots across levels categorical variable, like behpat.","code":"\nggplot(wcgs, aes(x = weight, y = sbp, col = behpat)) +\n    geom_point() +\n    facet_wrap(~ behpat) +\n    geom_smooth(method = \"lm\", se = FALSE, \n                formula = y ~ x, col = \"black\") +\n    guides(color = \"none\") +\n    theme(strip.text = element_text(face=\"bold\", size=rel(1.25), color=\"white\"),\n          strip.background = element_rect(fill=\"royalblue\")) +\n    labs(title = \"Scatterplots of SBP vs. Weight within Behavior Pattern\")"},{"path":"WCGS-Study.html","id":"scatterplot-and-correlation-matrices","chapter":"15 The WCGS","heading":"15.13 Scatterplot and Correlation Matrices","text":"scatterplot matrix can helpful understanding relationships multiple variables simultaneously. several ways build thing, including pairs function…","code":"\npairs (~ sbp + age + weight + height, data=wcgs, main=\"Simple Scatterplot Matrix\")"},{"path":"WCGS-Study.html","id":"displaying-a-correlation-matrix","chapter":"15 The WCGS","heading":"15.13.1 Displaying a Correlation Matrix","text":"","code":"\nwcgs %>%\n    dplyr::select(sbp, age, weight, height) %>%\n    cor() %>% # obtain correlation coefficients for this subgroup\n    signif(., 3) # round them off to three significant figures before printing          sbp     age  weight  height\nsbp    1.0000  0.1660  0.2530  0.0184\nage    0.1660  1.0000 -0.0344 -0.0954\nweight 0.2530 -0.0344  1.0000  0.5330\nheight 0.0184 -0.0954  0.5330  1.0000"},{"path":"WCGS-Study.html","id":"using-the-ggally-package","chapter":"15 The WCGS","heading":"15.13.2 Using the GGally package","text":"ggplot2 system doesn’t built-scatterplot system. nice add-ins world, though. One option sort like GGally package, can produce correlation matrices scatterplot matrices.ggpairs function provides density plot diagonal, Pearson correlations upper right scatterplots lower left matrix.","code":"\nGGally::ggpairs(wcgs %>% select(sbp, age, weight, height), \n                title = \"Scatterplot Matrix via ggpairs\")"},{"path":"some-r-tips.html","id":"some-r-tips","chapter":"Some R Tips","heading":"Some R Tips","text":"","code":""},{"path":"some-r-tips.html","id":"using-data-from-an-r-package","chapter":"Some R Tips","heading":"Using data from an R package","text":"use data R package, instance, bechdel data fivethirtyeight package, can simply load relevant package library data frame available","code":"\nlibrary(fivethirtyeight)\n\nbechdel# A tibble: 1,794 x 15\n    year imdb  title test  clean_test binary budget domgross\n   <int> <chr> <chr> <chr> <ord>      <chr>   <int>    <dbl>\n 1  2013 tt17~ 21 &~ nota~ notalk     FAIL   1.3 e7 25682380\n 2  2012 tt13~ Dred~ ok-d~ ok         PASS   4.5 e7 13414714\n 3  2013 tt20~ 12 Y~ nota~ notalk     FAIL   2   e7 53107035\n 4  2013 tt12~ 2 Gu~ nota~ notalk     FAIL   6.1 e7 75612460\n 5  2013 tt04~ 42    men   men        FAIL   4   e7 95020213\n 6  2013 tt13~ 47 R~ men   men        FAIL   2.25e8 38362475\n 7  2013 tt16~ A Go~ nota~ notalk     FAIL   9.2 e7 67349198\n 8  2013 tt21~ Abou~ ok-d~ ok         PASS   1.2 e7 15323921\n 9  2013 tt18~ Admi~ ok    ok         PASS   1.3 e7 18007317\n10  2013 tt18~ Afte~ nota~ notalk     FAIL   1.3 e8 60522097\n# ... with 1,784 more rows, and 7 more variables:\n#   intgross <dbl>, code <chr>, budget_2013 <int>,\n#   domgross_2013 <dbl>, intgross_2013 <dbl>,\n#   period_code <int>, decade_code <int>"},{"path":"some-r-tips.html","id":"using-read_rds-to-read-in-an-r-data-set","chapter":"Some R Tips","heading":"Using read_rds to read in an R data set","text":"provided nnyfs.Rds data file course data page.Suppose downloaded data file directory computer called data sub-directory directory plan work, perhaps called 431-nnyfs.Open RStudio create new project 431-nnyfs directory computer. see data subdirectory Files window RStudio project created.Now, read nnyfs.Rds file new tibble R called nnyfs_new following command:results…","code":"\nnnyfs_new <- read_rds(\"data/nnyfs.Rds\")\nnnyfs_new# A tibble: 1,518 x 45\n    SEQN sex    age_child race_eth       educ_child language\n   <dbl> <fct>      <dbl> <fct>               <dbl> <fct>   \n 1 71917 Female        15 3_Black Non-H~          9 English \n 2 71918 Female         8 3_Black Non-H~          2 English \n 3 71919 Female        14 2_White Non-H~          8 English \n 4 71920 Female        15 2_White Non-H~          8 English \n 5 71921 Male           3 2_White Non-H~         NA English \n 6 71922 Male          12 1_Hispanic              6 English \n 7 71923 Male          12 2_White Non-H~          5 English \n 8 71924 Female         8 4_Other Race/~          2 English \n 9 71925 Male           7 1_Hispanic              0 English \n10 71926 Male           8 3_Black Non-H~          2 English \n# ... with 1,508 more rows, and 39 more variables:\n#   sampling_wt <dbl>, income_pov <dbl>, age_adult <dbl>,\n#   educ_adult <fct>, respondent <fct>, salt_used <fct>,\n#   energy <dbl>, protein <dbl>, sugar <dbl>, fat <dbl>,\n#   diet_yesterday <fct>, water <dbl>, plank_time <dbl>,\n#   height <dbl>, weight <dbl>, bmi <dbl>, bmi_cat <fct>,\n#   arm_length <dbl>, waist <dbl>, arm_circ <dbl>, ..."},{"path":"some-r-tips.html","id":"using-read_csv-to-read-in-a-comma-separated-version-of-a-data-file","chapter":"Some R Tips","heading":"Using read_csv to read in a comma-separated version of a data file","text":"provided nnyfs.csv data file course data page.Suppose downloaded data file directory computer called data sub-directory directory plan work, perhaps called 431-nnyfs.Open RStudio create new project 431-nnyfs directory computer. see data subdirectory Files window RStudio project created.Now, read nnyfs.csv file new tibble R called nnyfs_new2 following command:also want convert character variables factors, often want analyzing results, instead use:Note , example, sex race_eth now listed factor (fctr) variables. One place distinction character factor variables matters summarize data.","code":"\nnnyfs_new2 <- read_csv(\"data/nnyfs.csv\")Rows: 1518 Columns: 45-- Column specification ------------------------------------\nDelimiter: \",\"\nchr (18): sex, race_eth, language, educ_adult, responden...\ndbl (27): SEQN, age_child, educ_child, sampling_wt, inco...\ni Use `spec()` to retrieve the full column specification for this data.\ni Specify the column types or set `show_col_types = FALSE` to quiet this message.\nnnyfs_new2# A tibble: 1,518 x 45\n    SEQN sex    age_child race_eth       educ_child language\n   <dbl> <chr>      <dbl> <chr>               <dbl> <chr>   \n 1 71917 Female        15 3_Black Non-H~          9 English \n 2 71918 Female         8 3_Black Non-H~          2 English \n 3 71919 Female        14 2_White Non-H~          8 English \n 4 71920 Female        15 2_White Non-H~          8 English \n 5 71921 Male           3 2_White Non-H~         NA English \n 6 71922 Male          12 1_Hispanic              6 English \n 7 71923 Male          12 2_White Non-H~          5 English \n 8 71924 Female         8 4_Other Race/~          2 English \n 9 71925 Male           7 1_Hispanic              0 English \n10 71926 Male           8 3_Black Non-H~          2 English \n# ... with 1,508 more rows, and 39 more variables:\n#   sampling_wt <dbl>, income_pov <dbl>, age_adult <dbl>,\n#   educ_adult <chr>, respondent <chr>, salt_used <chr>,\n#   energy <dbl>, protein <dbl>, sugar <dbl>, fat <dbl>,\n#   diet_yesterday <chr>, water <dbl>, plank_time <dbl>,\n#   height <dbl>, weight <dbl>, bmi <dbl>, bmi_cat <chr>,\n#   arm_length <dbl>, waist <dbl>, arm_circ <dbl>, ...\nnnyfs_new3 <- read_csv(\"data/nnyfs.csv\") %>%\n    mutate(across(where(is.character), as_factor))Rows: 1518 Columns: 45-- Column specification ------------------------------------\nDelimiter: \",\"\nchr (18): sex, race_eth, language, educ_adult, responden...\ndbl (27): SEQN, age_child, educ_child, sampling_wt, inco...\ni Use `spec()` to retrieve the full column specification for this data.\ni Specify the column types or set `show_col_types = FALSE` to quiet this message.\nnnyfs_new3# A tibble: 1,518 x 45\n    SEQN sex    age_child race_eth       educ_child language\n   <dbl> <fct>      <dbl> <fct>               <dbl> <fct>   \n 1 71917 Female        15 3_Black Non-H~          9 English \n 2 71918 Female         8 3_Black Non-H~          2 English \n 3 71919 Female        14 2_White Non-H~          8 English \n 4 71920 Female        15 2_White Non-H~          8 English \n 5 71921 Male           3 2_White Non-H~         NA English \n 6 71922 Male          12 1_Hispanic              6 English \n 7 71923 Male          12 2_White Non-H~          5 English \n 8 71924 Female         8 4_Other Race/~          2 English \n 9 71925 Male           7 1_Hispanic              0 English \n10 71926 Male           8 3_Black Non-H~          2 English \n# ... with 1,508 more rows, and 39 more variables:\n#   sampling_wt <dbl>, income_pov <dbl>, age_adult <dbl>,\n#   educ_adult <fct>, respondent <fct>, salt_used <fct>,\n#   energy <dbl>, protein <dbl>, sugar <dbl>, fat <dbl>,\n#   diet_yesterday <fct>, water <dbl>, plank_time <dbl>,\n#   height <dbl>, weight <dbl>, bmi <dbl>, bmi_cat <fct>,\n#   arm_length <dbl>, waist <dbl>, arm_circ <dbl>, ...\nsummary(nnyfs_new2$race_eth)   Length     Class      Mode \n     1518 character character \nsummary(nnyfs_new3$race_eth)  3_Black Non-Hispanic   2_White Non-Hispanic \n                   338                    610 \n            1_Hispanic 4_Other Race/Ethnicity \n                   450                    120 "},{"path":"some-r-tips.html","id":"converting-character-variables-into-factors","chapter":"Some R Tips","heading":"Converting Character Variables into Factors","text":"command want create newdata olddata :factors, visit https://r4ds..co.nz/factors.html","code":"newdata <- olddata %>%\n    mutate(across(where(is.character), as_factor))"},{"path":"some-r-tips.html","id":"converting-data-frames-to-tibbles","chapter":"Some R Tips","heading":"Converting Data Frames to Tibbles","text":"Use as_tibble() simply tibble() assign attributes tibble data frame. Note read_rds read_csv automatically create tibbles.tibbles, visit https://r4ds..co.nz/tibbles.html.","code":""},{"path":"some-r-tips.html","id":"for-more-advice","chapter":"Some R Tips","heading":"For more advice","text":"Consider visiting software tutorials page R Data heading main web site.","code":""},{"path":"references.html","id":"references","chapter":"References","heading":"References","text":"","code":""}]
